[
{
	"uri": "https://gloo.solo.io/0.7/user_guides/basic_routing/",
	"title": "Basic Routing",
	"tags": [],
	"description": "",
	"content": " Gateway Routing API Gateways can route incoming traffic to backend services. Gloo can automatically discover backend services based on plugins that it uses that know intimate details about the platform or environment on which it\u0026rsquo;s running. In this tutorial we look at Gloo\u0026rsquo;s basic upstream discovery and routing capabilities. For more advanced function routing, take a look at the function routing tutorial.\nWhat you\u0026rsquo;ll need  kubectl Kubernetes v1.11.3+ deployed somewhere. Minikube is a great way to get a cluster up quickly.  Steps  The Gloo Gateway installed and running on Kubernetes.\n Next, deploy the Pet Store app to kubernetes:\nkubectl apply \\ -f https://raw.githubusercontent.com/solo-io/gloo/master/example/petstore/petstore.yaml  The discovery services should have already created an Upstream for the petstore service. Let\u0026rsquo;s verify this:\nglooctl get upstreams +--------------------------------+------------+----------+------------------------------+ | UPSTREAM | TYPE | STATUS | DETAILS | +--------------------------------+------------+----------+------------------------------+ | default-kubernetes-443 | Kubernetes | Pending | svc name: kubernetes | | | | | svc namespace: default | | | | | port: 8443 | | | | | | | default-petstore-8080 | Kubernetes | Accepted | svc name: petstore | | | | | svc namespace: default | | | | | port: 8080 | | | | | REST service: | | | | | functions: | | | | | - addPet | | | | | - deletePet | | | | | - findPetById | | | | | - findPets | | | | | | | gloo-system-gateway-proxy-8080 | Kubernetes | Accepted | svc name: gateway-proxy | | | | | svc namespace: gloo-system | | | | | port: 8080 | | | | | | | gloo-system-gloo-9977 | Kubernetes | Accepted | svc name: gloo | | | | | svc namespace: gloo-system | | | | | port: 9977 | | | | | | +--------------------------------+------------+----------+------------------------------+  The upstream we want to see is default-petstore-8080. Digging a little deeper, we can verify that Gloo\u0026rsquo;s function discovery populated our upstream with the available rest endpoints it implements. Note: the upstream was created in the gloo-system namespace rather than default because it was created by a discovery service. Upstreams and virtualservices do not need to live in the gloo-system namespace to be processed by Gloo.\n\n Let\u0026rsquo;s take a closer look at the functions that are available on this upstream:\nglooctl get upstream default-petstore-8080 -o yaml --- discoveryMetadata: {} metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {\u0026quot;apiVersion\u0026quot;:\u0026quot;v1\u0026quot;,\u0026quot;kind\u0026quot;:\u0026quot;Service\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;annotations\u0026quot;:{},\u0026quot;labels\u0026quot;:{\u0026quot;service\u0026quot;:\u0026quot;petstore\u0026quot;},\u0026quot;name\u0026quot;:\u0026quot;petstore\u0026quot;,\u0026quot;namespace\u0026quot;:\u0026quot;default\u0026quot;},\u0026quot;spec\u0026quot;:{\u0026quot;ports\u0026quot;:[{\u0026quot;port\u0026quot;:8080,\u0026quot;protocol\u0026quot;:\u0026quot;TCP\u0026quot;}],\u0026quot;selector\u0026quot;:{\u0026quot;app\u0026quot;:\u0026quot;petstore\u0026quot;}}} labels: discovered_by: kubernetesplugin service: petstore name: default-petstore-8080 namespace: gloo-system resourceVersion: \u0026quot;31590\u0026quot; status: reportedBy: gloo state: Accepted upstreamSpec: kube: selector: app: petstore serviceName: petstore serviceNamespace: default servicePort: 8080 serviceSpec: rest: swaggerInfo: url: http://petstore.default.svc.cluster.local:8080/swagger.json transformations: addPet: body: text: '{\u0026quot;id\u0026quot;: {{ default(id, \u0026quot;\u0026quot;) }},\u0026quot;name\u0026quot;: \u0026quot;{{ default(name, \u0026quot;\u0026quot;)}}\u0026quot;,\u0026quot;tag\u0026quot;: \u0026quot;{{ default(tag, \u0026quot;\u0026quot;)}}\u0026quot;}' headers: :method: text: POST :path: text: /api/pets content-type: text: application/json deletePet: headers: :method: text: DELETE :path: text: /api/pets/{{ default(id, \u0026quot;\u0026quot;) }} content-type: text: application/json findPetById: body: {} headers: :method: text: GET :path: text: /api/pets/{{ default(id, \u0026quot;\u0026quot;) }} content-length: text: \u0026quot;0\u0026quot; content-type: {} transfer-encoding: {} findPets: body: {} headers: :method: text: GET :path: text: /api/pets?tags={{default(tags, \u0026quot;\u0026quot;)}}\u0026amp;limit={{default(limit, \u0026quot;\u0026quot;)}} content-length: text: \u0026quot;0\u0026quot; content-type: {} transfer-encoding: {}  The details of this application were discovered by Gloo\u0026rsquo;s Function Discovery (fds) service. Because the petstore application implements OpenAPI (specifically discovering a Swagger JSON document on petstore-svc/swagger.json). Because some functions were discovered for us, we can practice some function in the next tutorial.\n Let\u0026rsquo;s now use glooctl to create a basic route for this upstream.\nglooctl add route \\ --path-exact /sample-route-1 \\ --dest-name default-petstore-8080 \\ --prefix-rewrite /api/pets  We use the --prefix-rewrite to rewrite path on incoming requests to match the paths our petstore expects.\nNote that we have omitted the --name flag for selecting a virtual service. Routes are always associated with a Virtual Service in Gloo, which groups routes by their domain. Since we skipped creating a virtual service for this route, my-virtual-service will be created automatically for us.\nWith glooctl, we can see that a virtual service was created with our route:\nglooctl get virtualservice -o yaml --- metadata: name: default namespace: gloo-system resourceVersion: \u0026quot;32940\u0026quot; status: reportedBy: gateway state: Accepted subresourceStatuses: '*v1.Proxy gloo-system gateway-proxy': reportedBy: gloo state: Accepted virtualHost: domains: - '*' name: gloo-system.default routes: - matcher: exact: /sample-route-1 routeAction: single: upstream: name: default-petstore-8080 namespace: gloo-system routePlugins: prefixRewrite: prefixRewrite: /api/pets  Note that you can add routes interactively using glooctl add route -i. This is a great way to explore Gloo\u0026rsquo;s configuration options from the CLI.\n Let\u0026rsquo;s test the route /sample-route-1 using curl:\nexport GATEWAY_URL=$(glooctl proxy url) curl ${GATEWAY_URL}/sample-route-1 [{\u0026quot;id\u0026quot;:1,\u0026quot;name\u0026quot;:\u0026quot;Dog\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;available\u0026quot;},{\u0026quot;id\u0026quot;:2,\u0026quot;name\u0026quot;:\u0026quot;Cat\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;pending\u0026quot;}]   Great! our gateway is up and running. Let\u0026rsquo;s make things a bit more sophisticated in the next section with Function Routing.\n"
},
{
	"uri": "https://gloo.solo.io/0.8/user_guides/basic_routing/",
	"title": "Basic Routing",
	"tags": [],
	"description": "",
	"content": " Gateway Routing API Gateways can route incoming traffic to backend services. Gloo can automatically discover backend services based on plugins that it uses that know intimate details about the platform or environment on which it\u0026rsquo;s running. In this tutorial we look at Gloo\u0026rsquo;s basic upstream discovery and routing capabilities. For more advanced function routing, take a look at the function routing tutorial.\nWhat you\u0026rsquo;ll need  kubectl Kubernetes v1.11.3+ deployed somewhere. Minikube is a great way to get a cluster up quickly.  Steps  The Gloo Gateway installed and running on Kubernetes.\n Next, deploy the Pet Store app to kubernetes:\nkubectl apply \\ -f https://raw.githubusercontent.com/solo-io/gloo/master/example/petstore/petstore.yaml  The discovery services should have already created an Upstream for the petstore service. Let\u0026rsquo;s verify this:\nglooctl get upstreams +--------------------------------+------------+----------+------------------------------+ | UPSTREAM | TYPE | STATUS | DETAILS | +--------------------------------+------------+----------+------------------------------+ | default-kubernetes-443 | Kubernetes | Pending | svc name: kubernetes | | | | | svc namespace: default | | | | | port: 8443 | | | | | | | default-petstore-8080 | Kubernetes | Accepted | svc name: petstore | | | | | svc namespace: default | | | | | port: 8080 | | | | | REST service: | | | | | functions: | | | | | - addPet | | | | | - deletePet | | | | | - findPetById | | | | | - findPets | | | | | | | gloo-system-gateway-proxy-8080 | Kubernetes | Accepted | svc name: gateway-proxy | | | | | svc namespace: gloo-system | | | | | port: 8080 | | | | | | | gloo-system-gloo-9977 | Kubernetes | Accepted | svc name: gloo | | | | | svc namespace: gloo-system | | | | | port: 9977 | | | | | | +--------------------------------+------------+----------+------------------------------+  The upstream we want to see is default-petstore-8080. Digging a little deeper, we can verify that Gloo\u0026rsquo;s function discovery populated our upstream with the available rest endpoints it implements. Note: the upstream was created in the gloo-system namespace rather than default because it was created by a discovery service. Upstreams and virtualservices do not need to live in the gloo-system namespace to be processed by Gloo.\n\n Let\u0026rsquo;s take a closer look at the functions that are available on this upstream:\nglooctl get upstream default-petstore-8080 -o yaml --- discoveryMetadata: {} metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {\u0026quot;apiVersion\u0026quot;:\u0026quot;v1\u0026quot;,\u0026quot;kind\u0026quot;:\u0026quot;Service\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;annotations\u0026quot;:{},\u0026quot;labels\u0026quot;:{\u0026quot;service\u0026quot;:\u0026quot;petstore\u0026quot;},\u0026quot;name\u0026quot;:\u0026quot;petstore\u0026quot;,\u0026quot;namespace\u0026quot;:\u0026quot;default\u0026quot;},\u0026quot;spec\u0026quot;:{\u0026quot;ports\u0026quot;:[{\u0026quot;port\u0026quot;:8080,\u0026quot;protocol\u0026quot;:\u0026quot;TCP\u0026quot;}],\u0026quot;selector\u0026quot;:{\u0026quot;app\u0026quot;:\u0026quot;petstore\u0026quot;}}} labels: discovered_by: kubernetesplugin service: petstore name: default-petstore-8080 namespace: gloo-system resourceVersion: \u0026quot;31590\u0026quot; status: reportedBy: gloo state: Accepted upstreamSpec: kube: selector: app: petstore serviceName: petstore serviceNamespace: default servicePort: 8080 serviceSpec: rest: swaggerInfo: url: http://petstore.default.svc.cluster.local:8080/swagger.json transformations: addPet: body: text: '{\u0026quot;id\u0026quot;: {{ default(id, \u0026quot;\u0026quot;) }},\u0026quot;name\u0026quot;: \u0026quot;{{ default(name, \u0026quot;\u0026quot;)}}\u0026quot;,\u0026quot;tag\u0026quot;: \u0026quot;{{ default(tag, \u0026quot;\u0026quot;)}}\u0026quot;}' headers: :method: text: POST :path: text: /api/pets content-type: text: application/json deletePet: headers: :method: text: DELETE :path: text: /api/pets/{{ default(id, \u0026quot;\u0026quot;) }} content-type: text: application/json findPetById: body: {} headers: :method: text: GET :path: text: /api/pets/{{ default(id, \u0026quot;\u0026quot;) }} content-length: text: \u0026quot;0\u0026quot; content-type: {} transfer-encoding: {} findPets: body: {} headers: :method: text: GET :path: text: /api/pets?tags={{default(tags, \u0026quot;\u0026quot;)}}\u0026amp;limit={{default(limit, \u0026quot;\u0026quot;)}} content-length: text: \u0026quot;0\u0026quot; content-type: {} transfer-encoding: {}  The details of this application were discovered by Gloo\u0026rsquo;s Function Discovery (fds) service. Because the petstore application implements OpenAPI (specifically discovering a Swagger JSON document on petstore-svc/swagger.json). Because some functions were discovered for us, we can practice some function in the next tutorial.\n Let\u0026rsquo;s now use glooctl to create a basic route for this upstream.\nglooctl add route \\ --path-exact /sample-route-1 \\ --dest-name default-petstore-8080 \\ --prefix-rewrite /api/pets  We use the --prefix-rewrite to rewrite path on incoming requests to match the paths our petstore expects.\nNote that we have omitted the --name flag for selecting a virtual service. Routes are always associated with a Virtual Service in Gloo, which groups routes by their domain. Since we skipped creating a virtual service for this route, my-virtual-service will be created automatically for us.\nWith glooctl, we can see that a virtual service was created with our route:\nglooctl get virtualservice -o yaml --- metadata: name: default namespace: gloo-system resourceVersion: \u0026quot;32940\u0026quot; status: reportedBy: gateway state: Accepted subresourceStatuses: '*v1.Proxy gloo-system gateway-proxy': reportedBy: gloo state: Accepted virtualHost: domains: - '*' name: gloo-system.default routes: - matcher: exact: /sample-route-1 routeAction: single: upstream: name: default-petstore-8080 namespace: gloo-system routePlugins: prefixRewrite: prefixRewrite: /api/pets  Note that you can add routes interactively using glooctl add route -i. This is a great way to explore Gloo\u0026rsquo;s configuration options from the CLI.\n Let\u0026rsquo;s test the route /sample-route-1 using curl:\nexport GATEWAY_URL=$(glooctl proxy url) curl ${GATEWAY_URL}/sample-route-1 [{\u0026quot;id\u0026quot;:1,\u0026quot;name\u0026quot;:\u0026quot;Dog\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;available\u0026quot;},{\u0026quot;id\u0026quot;:2,\u0026quot;name\u0026quot;:\u0026quot;Cat\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;pending\u0026quot;}]   Great! our gateway is up and running. Let\u0026rsquo;s make things a bit more sophisticated in the next section with Function Routing.\n"
},
{
	"uri": "https://gloo.solo.io/0.7/dev/example-proxy-controller/",
	"title": "Building a Proxy Controller for Gloo",
	"tags": [],
	"description": "",
	"content": " In this tutorial, we\u0026rsquo;re going to show how to use Gloo\u0026rsquo;s Proxy API to build a router which automatically creates routes for every existing kubernetes service,\nWriting the Code You can view the complete code written in this section here: example-proxy-controller.go.\nInitial code First, we\u0026rsquo;ll start with a main.go. We\u0026rsquo;ll use the main function to connect to Kubernetes and start an event loop. Start by creating a new main.go file in a new directory:\npackage main // all the import's we'll need for this controller import ( \u0026quot;context\u0026quot; \u0026quot;log\u0026quot; \u0026quot;os\u0026quot; \u0026quot;time\u0026quot; \u0026quot;github.com/solo-io/gloo/projects/gloo/pkg/api/v1\u0026quot; \u0026quot;github.com/solo-io/go-utils/kubeutils\u0026quot; \u0026quot;github.com/solo-io/solo-kit/pkg/api/v1/clients\u0026quot; \u0026quot;github.com/solo-io/solo-kit/pkg/api/v1/clients/factory\u0026quot; \u0026quot;github.com/solo-io/solo-kit/pkg/api/v1/clients/kube\u0026quot; \u0026quot;github.com/solo-io/solo-kit/pkg/api/v1/resources/core\u0026quot; // import for GKE _ \u0026quot;k8s.io/client-go/plugin/pkg/client/auth/gcp\u0026quot; ) func main() {} // make our lives easy func must(err error) { if err != nil { panic(err) } }  Gloo API Clients Then we\u0026rsquo;ll want to use Gloo\u0026rsquo;s libraries to initialize a client for Proxies and Upstreams. Add the following function to your code:\nfunc initGlooClients(ctx context.Context) (v1.UpstreamClient, v1.ProxyClient) { // root rest config restConfig, err := kubeutils.GetConfig( os.Getenv(\u0026quot;KUBERNETES_MASTER_URL\u0026quot;), os.Getenv(\u0026quot;KUBECONFIG\u0026quot;)) must(err) // wrapper for kubernetes shared informer factory cache := kube.NewKubeCache(ctx) // initialize the CRD client for Gloo Upstreams upstreamClient, err := v1.NewUpstreamClient(\u0026amp;factory.KubeResourceClientFactory{ Crd: v1.UpstreamCrd, Cfg: restConfig, SharedCache: cache, }) must(err) // registering the client registers the type with the client cache err = upstreamClient.Register() must(err) // initialize the CRD client for Gloo Proxies proxyClient, err := v1.NewProxyClient(\u0026amp;factory.KubeResourceClientFactory{ Crd: v1.ProxyCrd, Cfg: restConfig, SharedCache: cache, }) must(err) // registering the client registers the type with the client cache err = proxyClient.Register() must(err) return upstreamClient, proxyClient }  This function will initialize clients for interacting with Gloo\u0026rsquo;s Upstream and Proxy APIs.\nProxy Configuration Next, we\u0026rsquo;ll define the algorithm for generating Proxy CRDs from a given list of upstreams. In this example, our proxy will serve traffic to every service in our cluster.\nPaste the following function into your code. Feel free to modify if you want to get experimental, here\u0026rsquo;s where the \u0026ldquo;opinionated\u0026rdquo; piece of our controller is defined:\n// in this function we'll generate an opinionated // proxy object with a routes for each of our upstreams func makeDesiredProxy(upstreams v1.UpstreamList) *v1.Proxy { // each virtual host represents the table of routes for a given // domain or set of domains. // in this example, we'll create one virtual host // for each upstream. var virtualHosts []*v1.VirtualHost for _, upstream := range upstreams { // create a virtual host for each upstream vHostForUpstream := \u0026amp;v1.VirtualHost{ // logical name of the virtual host, should be unique across vhosts Name: upstream.Metadata.Name, // the domain will be our \u0026quot;matcher\u0026quot;. // requests with the Host header equal to the upstream name // will be routed to this upstream Domains: []string{upstream.Metadata.Name}, // we'll create just one route designed to match any request // and send it to the upstream for this domain Routes: []*v1.Route{{ // use a basic catch-all matcher Matcher: \u0026amp;v1.Matcher{ PathSpecifier: \u0026amp;v1.Matcher_Prefix{ Prefix: \u0026quot;/\u0026quot;, }, }, // tell Gloo where to send the requests Action: \u0026amp;v1.Route_RouteAction{ RouteAction: \u0026amp;v1.RouteAction{ Destination: \u0026amp;v1.RouteAction_Single{ // single destination Single: \u0026amp;v1.Destination{ // a \u0026quot;reference\u0026quot; to the upstream, which is a Namespace/Name tuple Upstream: upstream.Metadata.Ref(), }, }, }, }, }}, } virtualHosts = append(virtualHosts, vHostForUpstream) } desiredProxy := \u0026amp;v1.Proxy{ // metadata will be translated to Kubernetes ObjectMeta Metadata: core.Metadata{Namespace: \u0026quot;gloo-system\u0026quot;, Name: \u0026quot;my-cool-proxy\u0026quot;}, // we have the option of creating multiple listeners, // but for the purpose of this example we'll just use one Listeners: []*v1.Listener{{ // logical name for the listener Name: \u0026quot;my-amazing-listener\u0026quot;, // instruct envoy to bind to all interfaces on port 8080 BindAddress: \u0026quot;::\u0026quot;, BindPort: 8080, // at this point you determine what type of listener // to use. here we'll be using the HTTP Listener // other listener types are currently unsupported, // but future ListenerType: \u0026amp;v1.Listener_HttpListener{ HttpListener: \u0026amp;v1.HttpListener{ // insert our list of virtual hosts here VirtualHosts: virtualHosts, }, }}, }, } return desiredProxy }  Event Loop Now we\u0026rsquo;ll define a resync function to be called whenever we receive a new list of upstreams:\n// we received a new list of upstreams! regenerate the desired proxy // and write it as a CRD to Kubernetes func resync(ctx context.Context, upstreams v1.UpstreamList, client v1.ProxyClient) { desiredProxy := makeDesiredProxy(upstreams) // see if the proxy exists. if yes, update; if no, create existingProxy, err := client.Read( desiredProxy.Metadata.Namespace, desiredProxy.Metadata.Name, clients.ReadOpts{Ctx: ctx}) // proxy exists! this is an update, not a create if err == nil { // sleep for 1s as Gloo may be re-validating our proxy, which can cause resource version to change time.Sleep(time.Second) // ensure resource version is the latest existingProxy, err = client.Read( desiredProxy.Metadata.Namespace, desiredProxy.Metadata.Name, clients.ReadOpts{Ctx: ctx}) must(err) // update the resource version on our desired proxy desiredProxy.Metadata.ResourceVersion = existingProxy.Metadata.ResourceVersion } // write! written, err := client.Write(desiredProxy, clients.WriteOpts{Ctx: ctx, OverwriteExisting: true}) must(err) log.Printf(\u0026quot;wrote proxy object: %+v\\n\u0026quot;, written) }  Main Function Now that we have our clients and a function defining the proxies we\u0026rsquo;ll want to create, all we need to do is tie it all together.\nLet\u0026rsquo;s set up a loop to watch Upstreams in our main function. Add the following to your main() func:\nfunc main() { // root context for the whole thing ctx := context.Background() // initialize Gloo API clients upstreamClient, proxyClient := initGlooClients(ctx) // start a watch on upstreams. we'll use this as our trigger // whenever upstreams are modified, we'll trigger our sync function upstreamWatch, watchErrors, initError := upstreamClient.Watch(\u0026quot;gloo-system\u0026quot;, clients.WatchOpts{Ctx: ctx}) must(initError) // our \u0026quot;event loop\u0026quot;. an event occurs whenever the list of upstreams has been updated for { select { // if we error during watch, just exit case err := \u0026lt;-watchErrors: must(err) // process a new upstream list case newUpstreamList := \u0026lt;-upstreamWatch: // we received a new list of upstreams from our watch, resync(ctx, newUpstreamList, proxyClient) } } }  Finished Code Great! Here\u0026rsquo;s what our completed main file should look like:\npackage main import ( \u0026quot;context\u0026quot; \u0026quot;log\u0026quot; \u0026quot;os\u0026quot; \u0026quot;time\u0026quot; \u0026quot;github.com/solo-io/gloo/projects/gloo/pkg/api/v1\u0026quot; \u0026quot;github.com/solo-io/go-utils/kubeutils\u0026quot; \u0026quot;github.com/solo-io/solo-kit/pkg/api/v1/clients\u0026quot; \u0026quot;github.com/solo-io/solo-kit/pkg/api/v1/clients/factory\u0026quot; \u0026quot;github.com/solo-io/solo-kit/pkg/api/v1/clients/kube\u0026quot; \u0026quot;github.com/solo-io/solo-kit/pkg/api/v1/resources/core\u0026quot; // import for GKE _ \u0026quot;k8s.io/client-go/plugin/pkg/client/auth/gcp\u0026quot; ) func main() { // root context for the whole thing ctx := context.Background() // initialize Gloo API clients, built on top of CRDs upstreamClient, proxyClient := initGlooClients(ctx) // start a watch on upstreams. we'll use this as our trigger // whenever upstreams are modified, we'll trigger our sync function upstreamWatch, watchErrors, initError := upstreamClient.Watch(\u0026quot;gloo-system\u0026quot;, clients.WatchOpts{Ctx: ctx}) must(initError) // our \u0026quot;event loop\u0026quot;. an event occurs whenever the list of upstreams has been updated for { select { // if we error during watch, just exit case err := \u0026lt;-watchErrors: must(err) // process a new upstream list case newUpstreamList := \u0026lt;-upstreamWatch: resync(ctx, newUpstreamList, proxyClient) } } } func initGlooClients(ctx context.Context) (v1.UpstreamClient, v1.ProxyClient) { // root rest config restConfig, err := kubeutils.GetConfig( os.Getenv(\u0026quot;KUBERNETES_MASTER_URL\u0026quot;), os.Getenv(\u0026quot;KUBECONFIG\u0026quot;)) must(err) // wrapper for kubernetes shared informer factory cache := kube.NewKubeCache(ctx) // initialize the CRD client for Gloo Upstreams upstreamClient, err := v1.NewUpstreamClient(\u0026amp;factory.KubeResourceClientFactory{ Crd: v1.UpstreamCrd, Cfg: restConfig, SharedCache: cache, }) must(err) // registering the client registers the type with the client cache err = upstreamClient.Register() must(err) // initialize the CRD client for Gloo Proxies proxyClient, err := v1.NewProxyClient(\u0026amp;factory.KubeResourceClientFactory{ Crd: v1.ProxyCrd, Cfg: restConfig, SharedCache: cache, }) must(err) // registering the client registers the type with the client cache err = proxyClient.Register() must(err) return upstreamClient, proxyClient } // we received a new list of upstreams! regenerate the desired proxy // and write it as a CRD to Kubernetes func resync(ctx context.Context, upstreams v1.UpstreamList, client v1.ProxyClient) { desiredProxy := makeDesiredProxy(upstreams) // see if the proxy exists. if yes, update; if no, create existingProxy, err := client.Read( desiredProxy.Metadata.Namespace, desiredProxy.Metadata.Name, clients.ReadOpts{Ctx: ctx}) // proxy exists! this is an update, not a create if err == nil { // sleep for 1s as Gloo may be re-validating our proxy, which can cause resource version to change time.Sleep(time.Second) // ensure resource version is the latest existingProxy, err = client.Read( desiredProxy.Metadata.Namespace, desiredProxy.Metadata.Name, clients.ReadOpts{Ctx: ctx}) must(err) // update the resource version on our desired proxy desiredProxy.Metadata.ResourceVersion = existingProxy.Metadata.ResourceVersion } // write! written, err := client.Write(desiredProxy, clients.WriteOpts{Ctx: ctx, OverwriteExisting: true}) must(err) log.Printf(\u0026quot;wrote proxy object: %+v\\n\u0026quot;, written) } // in this function we'll generate an opinionated // proxy object with a routes for each of our upstreams func makeDesiredProxy(upstreams v1.UpstreamList) *v1.Proxy { // each virtual host represents the table of routes for a given // domain or set of domains. // in this example, we'll create one virtual host // for each upstream. var virtualHosts []*v1.VirtualHost for _, upstream := range upstreams { // create a virtual host for each upstream vHostForUpstream := \u0026amp;v1.VirtualHost{ // logical name of the virtual host, should be unique across vhosts Name: upstream.Metadata.Name, // the domain will be our \u0026quot;matcher\u0026quot;. // requests with the Host header equal to the upstream name // will be routed to this upstream Domains: []string{upstream.Metadata.Name}, // we'll create just one route designed to match any request // and send it to the upstream for this domain Routes: []*v1.Route{{ // use a basic catch-all matcher Matcher: \u0026amp;v1.Matcher{ PathSpecifier: \u0026amp;v1.Matcher_Prefix{ Prefix: \u0026quot;/\u0026quot;, }, }, // tell Gloo where to send the requests Action: \u0026amp;v1.Route_RouteAction{ RouteAction: \u0026amp;v1.RouteAction{ Destination: \u0026amp;v1.RouteAction_Single{ // single destination Single: \u0026amp;v1.Destination{ // a \u0026quot;reference\u0026quot; to the upstream, which is a Namespace/Name tuple Upstream: upstream.Metadata.Ref(), }, }, }, }, }}, } virtualHosts = append(virtualHosts, vHostForUpstream) } desiredProxy := \u0026amp;v1.Proxy{ // metadata will be translated to Kubernetes ObjectMeta Metadata: core.Metadata{Namespace: \u0026quot;gloo-system\u0026quot;, Name: \u0026quot;my-cool-proxy\u0026quot;}, // we have the option of creating multiple listeners, // but for the purpose of this example we'll just use one Listeners: []*v1.Listener{{ // logical name for the listener Name: \u0026quot;my-amazing-listener\u0026quot;, // instruct envoy to bind to all interfaces on port 8080 BindAddress: \u0026quot;::\u0026quot;, BindPort: 8080, // at this point you determine what type of listener // to use. here we'll be using the HTTP Listener // other listener types are currently unsupported, // but future ListenerType: \u0026amp;v1.Listener_HttpListener{ HttpListener: \u0026amp;v1.HttpListener{ // insert our list of virtual hosts here VirtualHosts: virtualHosts, }, }}, }, } return desiredProxy } // make our lives easy func must(err error) { if err != nil { panic(err) } }  Run In order to run this file, you\u0026rsquo;ll need to pull the dependencies into your local workspace. go get -v ./... from your working dir, or dep init (if you\u0026rsquo;re comfortable using dep) should work fine.\ndep init -v # or go get -v ./..  While it\u0026rsquo;s possible to package this application in a Docker container and deploy it as a pod inside of Kubernetes, let\u0026rsquo;s just try running it locally. Make sure you have Gloo installed in your cluster so that Discovery will create some Upstreams for us.\nOnce that\u0026rsquo;s done, to see our code in action, simply run go run main.go !\ngo run main.go 2019/02/11 11:27:30 wrote proxy object: listeners:\u0026lt;name:\u0026quot;my-amazing-listener\u0026quot; bind_address:\u0026quot;::\u0026quot; bind_port:8080 http_listener:\u0026lt;virtual_hosts:\u0026lt;name:\u0026quot;default-kubernetes-443\u0026quot; domains:\u0026quot;default-kubernetes-443\u0026quot; routes:\u0026lt;matcher:\u0026lt;prefix:\u0026quot;/\u0026quot; \u0026gt; route_action:\u0026lt;single:\u0026lt;upstream:\u0026lt;name:\u0026quot;default-kubernetes-443\u0026quot; namespace:\u0026quot;gloo-system\u0026quot; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; virtual_hosts:\u0026lt;name:\u0026quot;gloo-system-gateway-proxy-8080\u0026quot; domains:\u0026quot;gloo-system-gateway-proxy-8080\u0026quot; routes:\u0026lt;matcher:\u0026lt;prefix:\u0026quot;/\u0026quot; \u0026gt; route_action:\u0026lt;single:\u0026lt;upstream:\u0026lt;name:\u0026quot;gloo-system-gateway-proxy-8080\u0026quot; namespace:\u0026quot;gloo-system\u0026quot; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; virtual_hosts:\u0026lt;name:\u0026quot;gloo-system-gloo-9977\u0026quot; domains:\u0026quot;gloo-system-gloo-9977\u0026quot; routes:\u0026lt;matcher:\u0026lt;prefix:\u0026quot;/\u0026quot; \u0026gt; route_action:\u0026lt;single:\u0026lt;upstream:\u0026lt;name:\u0026quot;gloo-system-gloo-9977\u0026quot; namespace:\u0026quot;gloo-system\u0026quot; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; virtual_hosts:\u0026lt;name:\u0026quot;kube-system-kube-dns-53\u0026quot; domains:\u0026quot;kube-system-kube-dns-53\u0026quot; routes:\u0026lt;matcher:\u0026lt;prefix:\u0026quot;/\u0026quot; \u0026gt; route_action:\u0026lt;single:\u0026lt;upstream:\u0026lt;name:\u0026quot;kube-system-kube-dns-53\u0026quot; namespace:\u0026quot;gloo-system\u0026quot; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; virtual_hosts:\u0026lt;name:\u0026quot;kube-system-tiller-deploy-44134\u0026quot; domains:\u0026quot;kube-system-tiller-deploy-44134\u0026quot; routes:\u0026lt;matcher:\u0026lt;prefix:\u0026quot;/\u0026quot; \u0026gt; route_action:\u0026lt;single:\u0026lt;upstream:\u0026lt;name:\u0026quot;kube-system-tiller-deploy-44134\u0026quot; namespace:\u0026quot;gloo-system\u0026quot; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; status:\u0026lt;\u0026gt; metadata:\u0026lt;name:\u0026quot;my-cool-proxy\u0026quot; namespace:\u0026quot;gloo-system\u0026quot; resource_version:\u0026quot;455073\u0026quot; \u0026gt;  Neat! Our proxy got created. We can view it with kubectl:\nkubectl get proxy -n gloo-system -o yaml apiVersion: v1 items: - apiVersion: gloo.solo.io/v1 kind: Proxy metadata: creationTimestamp: 2019-02-11T16:27:30Z generation: 1 name: my-cool-proxy namespace: gloo-system resourceVersion: \u0026quot;455074\u0026quot; selfLink: /apis/gloo.solo.io/v1/namespaces/gloo-system/proxies/my-cool-proxy uid: eda0ba6f-2e19-11e9-b401-c075ea19232f spec: listeners: - bindAddress: '::' bindPort: 8080 httpListener: virtualHosts: - domains: - default-kubernetes-443 name: default-kubernetes-443 routes: - matcher: prefix: / routeAction: single: upstream: name: default-kubernetes-443 namespace: gloo-system - domains: - gloo-system-gateway-proxy-8080 name: gloo-system-gateway-proxy-8080 routes: - matcher: prefix: / routeAction: single: upstream: name: gloo-system-gateway-proxy-8080 namespace: gloo-system - domains: - gloo-system-gloo-9977 name: gloo-system-gloo-9977 routes: - matcher: prefix: / routeAction: single: upstream: name: gloo-system-gloo-9977 namespace: gloo-system - domains: - kube-system-kube-dns-53 name: kube-system-kube-dns-53 routes: - matcher: prefix: / routeAction: single: upstream: name: kube-system-kube-dns-53 namespace: gloo-system - domains: - kube-system-tiller-deploy-44134 name: kube-system-tiller-deploy-44134 routes: - matcher: prefix: / routeAction: single: upstream: name: kube-system-tiller-deploy-44134 namespace: gloo-system name: my-amazing-listener status: reported_by: gloo state: 1 kind: List metadata: resourceVersion: \u0026quot;\u0026quot; selfLink: \u0026quot;\u0026quot;  Cool. Let\u0026rsquo;s leave our controller running and watch it dynamically respond when we add a service to our cluster:\nkubectl apply -f \\ https://raw.githubusercontent.com/solo-io/gloo/master/example/petstore/petstore.yaml  See the service and pod:\nkubectl get pod -n default \u0026amp;\u0026amp; kubectl get svc -n default NAME READY STATUS RESTARTS AGE petstore-6fd84bc9-zdskz 1/1 Running 0 5s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 6d petstore ClusterIP 10.109.34.250 \u0026lt;none\u0026gt; 8080/TCP 5s  The upstream that was created:\nkubectl get upstream NAME AGE default-kubernetes-443 2m default-petstore-8080 46s # \u0026lt;- this one's new gloo-system-gateway-proxy-8080 2m gloo-system-gloo-9977 2m kube-system-kube-dns-53 2m kube-system-tiller-deploy-44134 2m  And check that our proxy object was updated:\nkubectl get proxy -n gloo-system -o yaml apiVersion: v1 items: - apiVersion: gloo.solo.io/v1 kind: Proxy metadata: creationTimestamp: 2019-02-11T19:03:48Z generation: 1 name: my-cool-proxy namespace: gloo-system resourceVersion: \u0026quot;470446\u0026quot; selfLink: /apis/gloo.solo.io/v1/namespaces/gloo-system/proxies/my-cool-proxy uid: c2f058fb-2e2f-11e9-b401-c075ea19232f spec: listeners: - bindAddress: '::' bindPort: 8080 httpListener: virtualHosts: ... - domains: - default-petstore-8080 name: default-petstore-8080 routes: - matcher: prefix: / routeAction: single: upstream: name: default-petstore-8080 namespace: gloo-system ... name: my-amazing-listener status: reported_by: gloo state: 1 kind: List metadata: resourceVersion: \u0026quot;\u0026quot; selfLink: \u0026quot;\u0026quot;  The proxy should have been create with the default-petstore-8080 virtualHost.\nNow that we have a proxy called my-cool-proxy, Gloo will be serving xDS configuration that matches this proxy CRD. However, we don\u0026rsquo;t actually have an Envoy instance deployed that will receive this config. In the next section, we\u0026rsquo;ll walk through the steps to deploy an Envoy pod wired to receive config from Gloo, identifying itself as my-cool-proxy.\nDeploying Envoy to Kubernetes Gloo comes pre-installed with at least one proxy depending on your setup: the gateway-proxy. This proxy is configured by the gateway proxy controller. It\u0026rsquo;s not very different from the controller we just wrote!\nWe\u0026rsquo;ll need to deploy another proxy that will register to Gloo with it\u0026rsquo;s role configured to match the name of our proxy CRD, my-cool-proxy. Let\u0026rsquo;s do it!\nCreating the ConfigMap Envoy needs a ConfigMap which points it at Gloo as its configuration server. Run the following command to create the configmap you\u0026rsquo;ll need:\ncat \u0026lt;\u0026lt; EOF | kubectl apply -f - apiVersion: v1 kind: ConfigMap metadata: name: my-cool-envoy-config namespace: default data: envoy.yaml: | node: cluster: \u0026quot;1\u0026quot; id: \u0026quot;1\u0026quot; metadata: # this line is what connects this envoy instance to our Proxy crd role: \u0026quot;gloo-system~my-cool-proxy\u0026quot; static_resources: clusters: - name: xds_cluster connect_timeout: 5.000s load_assignment: cluster_name: xds_cluster endpoints: - lb_endpoints: - endpoint: address: socket_address: # here's where we provide the hostname of the gloo service address: gloo.gloo-system.svc.cluster.local port_value: 9977 http2_protocol_options: {} type: STRICT_DNS dynamic_resources: ads_config: api_type: GRPC grpc_services: - envoy_grpc: {cluster_name: xds_cluster} cds_config: ads: {} lds_config: ads: {} admin: access_log_path: /dev/null address: socket_address: address: 127.0.0.1 port_value: 19000 EOF  Note that this will create the configmap in the default namespace, but you can run it anywhere. Just make sure the proxy deployment and service all go to the same namespace.\nCreating the Service and Deployment We need to create a LoadBalancer service for our proxy so we can connect to it from the outside. Note that if you\u0026rsquo;re using a Kubernetes Cluster without an external load balancer (e.g. minikube), we\u0026rsquo;ll be using the service\u0026rsquo;s NodePort to connect.\nRun the following command to create the service:\ncat \u0026lt;\u0026lt; EOF | kubectl apply -f - apiVersion: v1 kind: Service metadata: labels: gloo: my-cool-proxy name: my-cool-proxy namespace: default spec: ports: - port: 8080 # \u0026lt;- this port should match the port for the HttpListener in our Proxy CRD protocol: TCP name: http selector: gloo: my-cool-proxy type: LoadBalancer EOF  Finally we\u0026rsquo;ll want to create the deployment itself which will launch a pod with Envoy running inside.\ncat \u0026lt;\u0026lt; EOF | kubectl apply -f - apiVersion: extensions/v1beta1 kind: Deployment metadata: labels: gloo: my-cool-proxy name: my-cool-proxy namespace: default spec: replicas: selector: matchLabels: gloo: my-cool-proxy template: metadata: labels: gloo: my-cool-proxy spec: containers: - args: [\u0026quot;--disable-hot-restart\u0026quot;] env: - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name image: soloio/gloo-envoy-wrapper:0.6.19 imagePullPolicy: Always name: my-cool-proxy ports: - containerPort: 8080 # \u0026lt;- this port should match the port for the HttpListener in our Proxy CRD name: http protocol: TCP volumeMounts: - mountPath: /etc/envoy name: envoy-config volumes: - configMap: name: my-cool-envoy-config name: envoy-config EOF  If all went well, we should see our pod starting successfully in default (or whichever namespace you picked):\nkubectl get pod -n default NAME READY STATUS RESTARTS AGE my-cool-proxy-7bcb58c87d-h4292 1/1 Running 0 3s petstore-6fd84bc9-zdskz 1/1 Running 0 48m  Testing the Proxy If you have glooctl installed, we can grab the HTTP endpoint of the proxy with the following command:\nglooctl proxy url -n default -p my-cool-proxy http://192.168.99.150:30751  Using curl, we can connect to any service in our cluster by using the correct Host header:\ncurl $(glooctl proxy url -n default -p my-cool-proxy)/api/pets -H \u0026quot;Host: default-petstore-8080\u0026quot; [{\u0026quot;id\u0026quot;:1,\u0026quot;name\u0026quot;:\u0026quot;Dog\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;available\u0026quot;},{\u0026quot;id\u0026quot;:2,\u0026quot;name\u0026quot;:\u0026quot;Cat\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;pending\u0026quot;}]  Try any Host header for any upstream name:\nkubectl get upstream NAME AGE default-kubernetes-443 55m default-my-cool-proxy-8080 5m default-petstore-8080 53m gloo-system-gateway-proxy-8080 55m gloo-system-gloo-9977 54m kube-system-kube-dns-53 54m kube-system-tiller-deploy-44134 54m  Sweet! You\u0026rsquo;re an official Gloo developer! You\u0026rsquo;ve just seen how easy it is to extend Gloo to service one of many potential use cases. Take a look at our API Reference Documentation to learn about the wide range of configuration options Proxies expose such as request transformation, SSL termination, serverless computing, and much more.\n"
},
{
	"uri": "https://gloo.solo.io/0.8/dev/example-proxy-controller/",
	"title": "Building a Proxy Controller for Gloo",
	"tags": [],
	"description": "",
	"content": " In this tutorial, we\u0026rsquo;re going to show how to use Gloo\u0026rsquo;s Proxy API to build a router which automatically creates routes for every existing kubernetes service,\nWriting the Code You can view the complete code written in this section here: example-proxy-controller.go.\nInitial code First, we\u0026rsquo;ll start with a main.go. We\u0026rsquo;ll use the main function to connect to Kubernetes and start an event loop. Start by creating a new main.go file in a new directory:\npackage main // all the import's we'll need for this controller import ( \u0026quot;context\u0026quot; \u0026quot;log\u0026quot; \u0026quot;os\u0026quot; \u0026quot;time\u0026quot; \u0026quot;github.com/solo-io/gloo/projects/gloo/pkg/api/v1\u0026quot; \u0026quot;github.com/solo-io/go-utils/kubeutils\u0026quot; \u0026quot;github.com/solo-io/solo-kit/pkg/api/v1/clients\u0026quot; \u0026quot;github.com/solo-io/solo-kit/pkg/api/v1/clients/factory\u0026quot; \u0026quot;github.com/solo-io/solo-kit/pkg/api/v1/clients/kube\u0026quot; \u0026quot;github.com/solo-io/solo-kit/pkg/api/v1/resources/core\u0026quot; // import for GKE _ \u0026quot;k8s.io/client-go/plugin/pkg/client/auth/gcp\u0026quot; ) func main() {} // make our lives easy func must(err error) { if err != nil { panic(err) } }  Gloo API Clients Then we\u0026rsquo;ll want to use Gloo\u0026rsquo;s libraries to initialize a client for Proxies and Upstreams. Add the following function to your code:\nfunc initGlooClients(ctx context.Context) (v1.UpstreamClient, v1.ProxyClient) { // root rest config restConfig, err := kubeutils.GetConfig( os.Getenv(\u0026quot;KUBERNETES_MASTER_URL\u0026quot;), os.Getenv(\u0026quot;KUBECONFIG\u0026quot;)) must(err) // wrapper for kubernetes shared informer factory cache := kube.NewKubeCache(ctx) // initialize the CRD client for Gloo Upstreams upstreamClient, err := v1.NewUpstreamClient(\u0026amp;factory.KubeResourceClientFactory{ Crd: v1.UpstreamCrd, Cfg: restConfig, SharedCache: cache, }) must(err) // registering the client registers the type with the client cache err = upstreamClient.Register() must(err) // initialize the CRD client for Gloo Proxies proxyClient, err := v1.NewProxyClient(\u0026amp;factory.KubeResourceClientFactory{ Crd: v1.ProxyCrd, Cfg: restConfig, SharedCache: cache, }) must(err) // registering the client registers the type with the client cache err = proxyClient.Register() must(err) return upstreamClient, proxyClient }  This function will initialize clients for interacting with Gloo\u0026rsquo;s Upstream and Proxy APIs.\nProxy Configuration Next, we\u0026rsquo;ll define the algorithm for generating Proxy CRDs from a given list of upstreams. In this example, our proxy will serve traffic to every service in our cluster.\nPaste the following function into your code. Feel free to modify if you want to get experimental, here\u0026rsquo;s where the \u0026ldquo;opinionated\u0026rdquo; piece of our controller is defined:\n// in this function we'll generate an opinionated // proxy object with a routes for each of our upstreams func makeDesiredProxy(upstreams v1.UpstreamList) *v1.Proxy { // each virtual host represents the table of routes for a given // domain or set of domains. // in this example, we'll create one virtual host // for each upstream. var virtualHosts []*v1.VirtualHost for _, upstream := range upstreams { // create a virtual host for each upstream vHostForUpstream := \u0026amp;v1.VirtualHost{ // logical name of the virtual host, should be unique across vhosts Name: upstream.Metadata.Name, // the domain will be our \u0026quot;matcher\u0026quot;. // requests with the Host header equal to the upstream name // will be routed to this upstream Domains: []string{upstream.Metadata.Name}, // we'll create just one route designed to match any request // and send it to the upstream for this domain Routes: []*v1.Route{{ // use a basic catch-all matcher Matcher: \u0026amp;v1.Matcher{ PathSpecifier: \u0026amp;v1.Matcher_Prefix{ Prefix: \u0026quot;/\u0026quot;, }, }, // tell Gloo where to send the requests Action: \u0026amp;v1.Route_RouteAction{ RouteAction: \u0026amp;v1.RouteAction{ Destination: \u0026amp;v1.RouteAction_Single{ // single destination Single: \u0026amp;v1.Destination{ // a \u0026quot;reference\u0026quot; to the upstream, which is a Namespace/Name tuple Upstream: upstream.Metadata.Ref(), }, }, }, }, }}, } virtualHosts = append(virtualHosts, vHostForUpstream) } desiredProxy := \u0026amp;v1.Proxy{ // metadata will be translated to Kubernetes ObjectMeta Metadata: core.Metadata{Namespace: \u0026quot;gloo-system\u0026quot;, Name: \u0026quot;my-cool-proxy\u0026quot;}, // we have the option of creating multiple listeners, // but for the purpose of this example we'll just use one Listeners: []*v1.Listener{{ // logical name for the listener Name: \u0026quot;my-amazing-listener\u0026quot;, // instruct envoy to bind to all interfaces on port 8080 BindAddress: \u0026quot;::\u0026quot;, BindPort: 8080, // at this point you determine what type of listener // to use. here we'll be using the HTTP Listener // other listener types are currently unsupported, // but future ListenerType: \u0026amp;v1.Listener_HttpListener{ HttpListener: \u0026amp;v1.HttpListener{ // insert our list of virtual hosts here VirtualHosts: virtualHosts, }, }}, }, } return desiredProxy }  Event Loop Now we\u0026rsquo;ll define a resync function to be called whenever we receive a new list of upstreams:\n// we received a new list of upstreams! regenerate the desired proxy // and write it as a CRD to Kubernetes func resync(ctx context.Context, upstreams v1.UpstreamList, client v1.ProxyClient) { desiredProxy := makeDesiredProxy(upstreams) // see if the proxy exists. if yes, update; if no, create existingProxy, err := client.Read( desiredProxy.Metadata.Namespace, desiredProxy.Metadata.Name, clients.ReadOpts{Ctx: ctx}) // proxy exists! this is an update, not a create if err == nil { // sleep for 1s as Gloo may be re-validating our proxy, which can cause resource version to change time.Sleep(time.Second) // ensure resource version is the latest existingProxy, err = client.Read( desiredProxy.Metadata.Namespace, desiredProxy.Metadata.Name, clients.ReadOpts{Ctx: ctx}) must(err) // update the resource version on our desired proxy desiredProxy.Metadata.ResourceVersion = existingProxy.Metadata.ResourceVersion } // write! written, err := client.Write(desiredProxy, clients.WriteOpts{Ctx: ctx, OverwriteExisting: true}) must(err) log.Printf(\u0026quot;wrote proxy object: %+v\\n\u0026quot;, written) }  Main Function Now that we have our clients and a function defining the proxies we\u0026rsquo;ll want to create, all we need to do is tie it all together.\nLet\u0026rsquo;s set up a loop to watch Upstreams in our main function. Add the following to your main() func:\nfunc main() { // root context for the whole thing ctx := context.Background() // initialize Gloo API clients upstreamClient, proxyClient := initGlooClients(ctx) // start a watch on upstreams. we'll use this as our trigger // whenever upstreams are modified, we'll trigger our sync function upstreamWatch, watchErrors, initError := upstreamClient.Watch(\u0026quot;gloo-system\u0026quot;, clients.WatchOpts{Ctx: ctx}) must(initError) // our \u0026quot;event loop\u0026quot;. an event occurs whenever the list of upstreams has been updated for { select { // if we error during watch, just exit case err := \u0026lt;-watchErrors: must(err) // process a new upstream list case newUpstreamList := \u0026lt;-upstreamWatch: // we received a new list of upstreams from our watch, resync(ctx, newUpstreamList, proxyClient) } } }  Finished Code Great! Here\u0026rsquo;s what our completed main file should look like:\npackage main import ( \u0026quot;context\u0026quot; \u0026quot;log\u0026quot; \u0026quot;os\u0026quot; \u0026quot;time\u0026quot; \u0026quot;github.com/solo-io/gloo/projects/gloo/pkg/api/v1\u0026quot; \u0026quot;github.com/solo-io/go-utils/kubeutils\u0026quot; \u0026quot;github.com/solo-io/solo-kit/pkg/api/v1/clients\u0026quot; \u0026quot;github.com/solo-io/solo-kit/pkg/api/v1/clients/factory\u0026quot; \u0026quot;github.com/solo-io/solo-kit/pkg/api/v1/clients/kube\u0026quot; \u0026quot;github.com/solo-io/solo-kit/pkg/api/v1/resources/core\u0026quot; // import for GKE _ \u0026quot;k8s.io/client-go/plugin/pkg/client/auth/gcp\u0026quot; ) func main() { // root context for the whole thing ctx := context.Background() // initialize Gloo API clients, built on top of CRDs upstreamClient, proxyClient := initGlooClients(ctx) // start a watch on upstreams. we'll use this as our trigger // whenever upstreams are modified, we'll trigger our sync function upstreamWatch, watchErrors, initError := upstreamClient.Watch(\u0026quot;gloo-system\u0026quot;, clients.WatchOpts{Ctx: ctx}) must(initError) // our \u0026quot;event loop\u0026quot;. an event occurs whenever the list of upstreams has been updated for { select { // if we error during watch, just exit case err := \u0026lt;-watchErrors: must(err) // process a new upstream list case newUpstreamList := \u0026lt;-upstreamWatch: resync(ctx, newUpstreamList, proxyClient) } } } func initGlooClients(ctx context.Context) (v1.UpstreamClient, v1.ProxyClient) { // root rest config restConfig, err := kubeutils.GetConfig( os.Getenv(\u0026quot;KUBERNETES_MASTER_URL\u0026quot;), os.Getenv(\u0026quot;KUBECONFIG\u0026quot;)) must(err) // wrapper for kubernetes shared informer factory cache := kube.NewKubeCache(ctx) // initialize the CRD client for Gloo Upstreams upstreamClient, err := v1.NewUpstreamClient(\u0026amp;factory.KubeResourceClientFactory{ Crd: v1.UpstreamCrd, Cfg: restConfig, SharedCache: cache, }) must(err) // registering the client registers the type with the client cache err = upstreamClient.Register() must(err) // initialize the CRD client for Gloo Proxies proxyClient, err := v1.NewProxyClient(\u0026amp;factory.KubeResourceClientFactory{ Crd: v1.ProxyCrd, Cfg: restConfig, SharedCache: cache, }) must(err) // registering the client registers the type with the client cache err = proxyClient.Register() must(err) return upstreamClient, proxyClient } // we received a new list of upstreams! regenerate the desired proxy // and write it as a CRD to Kubernetes func resync(ctx context.Context, upstreams v1.UpstreamList, client v1.ProxyClient) { desiredProxy := makeDesiredProxy(upstreams) // see if the proxy exists. if yes, update; if no, create existingProxy, err := client.Read( desiredProxy.Metadata.Namespace, desiredProxy.Metadata.Name, clients.ReadOpts{Ctx: ctx}) // proxy exists! this is an update, not a create if err == nil { // sleep for 1s as Gloo may be re-validating our proxy, which can cause resource version to change time.Sleep(time.Second) // ensure resource version is the latest existingProxy, err = client.Read( desiredProxy.Metadata.Namespace, desiredProxy.Metadata.Name, clients.ReadOpts{Ctx: ctx}) must(err) // update the resource version on our desired proxy desiredProxy.Metadata.ResourceVersion = existingProxy.Metadata.ResourceVersion } // write! written, err := client.Write(desiredProxy, clients.WriteOpts{Ctx: ctx, OverwriteExisting: true}) must(err) log.Printf(\u0026quot;wrote proxy object: %+v\\n\u0026quot;, written) } // in this function we'll generate an opinionated // proxy object with a routes for each of our upstreams func makeDesiredProxy(upstreams v1.UpstreamList) *v1.Proxy { // each virtual host represents the table of routes for a given // domain or set of domains. // in this example, we'll create one virtual host // for each upstream. var virtualHosts []*v1.VirtualHost for _, upstream := range upstreams { // create a virtual host for each upstream vHostForUpstream := \u0026amp;v1.VirtualHost{ // logical name of the virtual host, should be unique across vhosts Name: upstream.Metadata.Name, // the domain will be our \u0026quot;matcher\u0026quot;. // requests with the Host header equal to the upstream name // will be routed to this upstream Domains: []string{upstream.Metadata.Name}, // we'll create just one route designed to match any request // and send it to the upstream for this domain Routes: []*v1.Route{{ // use a basic catch-all matcher Matcher: \u0026amp;v1.Matcher{ PathSpecifier: \u0026amp;v1.Matcher_Prefix{ Prefix: \u0026quot;/\u0026quot;, }, }, // tell Gloo where to send the requests Action: \u0026amp;v1.Route_RouteAction{ RouteAction: \u0026amp;v1.RouteAction{ Destination: \u0026amp;v1.RouteAction_Single{ // single destination Single: \u0026amp;v1.Destination{ // a \u0026quot;reference\u0026quot; to the upstream, which is a Namespace/Name tuple Upstream: upstream.Metadata.Ref(), }, }, }, }, }}, } virtualHosts = append(virtualHosts, vHostForUpstream) } desiredProxy := \u0026amp;v1.Proxy{ // metadata will be translated to Kubernetes ObjectMeta Metadata: core.Metadata{Namespace: \u0026quot;gloo-system\u0026quot;, Name: \u0026quot;my-cool-proxy\u0026quot;}, // we have the option of creating multiple listeners, // but for the purpose of this example we'll just use one Listeners: []*v1.Listener{{ // logical name for the listener Name: \u0026quot;my-amazing-listener\u0026quot;, // instruct envoy to bind to all interfaces on port 8080 BindAddress: \u0026quot;::\u0026quot;, BindPort: 8080, // at this point you determine what type of listener // to use. here we'll be using the HTTP Listener // other listener types are currently unsupported, // but future ListenerType: \u0026amp;v1.Listener_HttpListener{ HttpListener: \u0026amp;v1.HttpListener{ // insert our list of virtual hosts here VirtualHosts: virtualHosts, }, }}, }, } return desiredProxy } // make our lives easy func must(err error) { if err != nil { panic(err) } }  Run In order to run this file, you\u0026rsquo;ll need to pull the dependencies into your local workspace. go get -v ./... from your working dir, or dep init (if you\u0026rsquo;re comfortable using dep) should work fine.\ndep init -v # or go get -v ./..  While it\u0026rsquo;s possible to package this application in a Docker container and deploy it as a pod inside of Kubernetes, let\u0026rsquo;s just try running it locally. Make sure you have Gloo installed in your cluster so that Discovery will create some Upstreams for us.\nOnce that\u0026rsquo;s done, to see our code in action, simply run go run main.go !\ngo run main.go 2019/02/11 11:27:30 wrote proxy object: listeners:\u0026lt;name:\u0026quot;my-amazing-listener\u0026quot; bind_address:\u0026quot;::\u0026quot; bind_port:8080 http_listener:\u0026lt;virtual_hosts:\u0026lt;name:\u0026quot;default-kubernetes-443\u0026quot; domains:\u0026quot;default-kubernetes-443\u0026quot; routes:\u0026lt;matcher:\u0026lt;prefix:\u0026quot;/\u0026quot; \u0026gt; route_action:\u0026lt;single:\u0026lt;upstream:\u0026lt;name:\u0026quot;default-kubernetes-443\u0026quot; namespace:\u0026quot;gloo-system\u0026quot; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; virtual_hosts:\u0026lt;name:\u0026quot;gloo-system-gateway-proxy-8080\u0026quot; domains:\u0026quot;gloo-system-gateway-proxy-8080\u0026quot; routes:\u0026lt;matcher:\u0026lt;prefix:\u0026quot;/\u0026quot; \u0026gt; route_action:\u0026lt;single:\u0026lt;upstream:\u0026lt;name:\u0026quot;gloo-system-gateway-proxy-8080\u0026quot; namespace:\u0026quot;gloo-system\u0026quot; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; virtual_hosts:\u0026lt;name:\u0026quot;gloo-system-gloo-9977\u0026quot; domains:\u0026quot;gloo-system-gloo-9977\u0026quot; routes:\u0026lt;matcher:\u0026lt;prefix:\u0026quot;/\u0026quot; \u0026gt; route_action:\u0026lt;single:\u0026lt;upstream:\u0026lt;name:\u0026quot;gloo-system-gloo-9977\u0026quot; namespace:\u0026quot;gloo-system\u0026quot; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; virtual_hosts:\u0026lt;name:\u0026quot;kube-system-kube-dns-53\u0026quot; domains:\u0026quot;kube-system-kube-dns-53\u0026quot; routes:\u0026lt;matcher:\u0026lt;prefix:\u0026quot;/\u0026quot; \u0026gt; route_action:\u0026lt;single:\u0026lt;upstream:\u0026lt;name:\u0026quot;kube-system-kube-dns-53\u0026quot; namespace:\u0026quot;gloo-system\u0026quot; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; virtual_hosts:\u0026lt;name:\u0026quot;kube-system-tiller-deploy-44134\u0026quot; domains:\u0026quot;kube-system-tiller-deploy-44134\u0026quot; routes:\u0026lt;matcher:\u0026lt;prefix:\u0026quot;/\u0026quot; \u0026gt; route_action:\u0026lt;single:\u0026lt;upstream:\u0026lt;name:\u0026quot;kube-system-tiller-deploy-44134\u0026quot; namespace:\u0026quot;gloo-system\u0026quot; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; \u0026gt; status:\u0026lt;\u0026gt; metadata:\u0026lt;name:\u0026quot;my-cool-proxy\u0026quot; namespace:\u0026quot;gloo-system\u0026quot; resource_version:\u0026quot;455073\u0026quot; \u0026gt;  Neat! Our proxy got created. We can view it with kubectl:\nkubectl get proxy -n gloo-system -o yaml apiVersion: v1 items: - apiVersion: gloo.solo.io/v1 kind: Proxy metadata: creationTimestamp: 2019-02-11T16:27:30Z generation: 1 name: my-cool-proxy namespace: gloo-system resourceVersion: \u0026quot;455074\u0026quot; selfLink: /apis/gloo.solo.io/v1/namespaces/gloo-system/proxies/my-cool-proxy uid: eda0ba6f-2e19-11e9-b401-c075ea19232f spec: listeners: - bindAddress: '::' bindPort: 8080 httpListener: virtualHosts: - domains: - default-kubernetes-443 name: default-kubernetes-443 routes: - matcher: prefix: / routeAction: single: upstream: name: default-kubernetes-443 namespace: gloo-system - domains: - gloo-system-gateway-proxy-8080 name: gloo-system-gateway-proxy-8080 routes: - matcher: prefix: / routeAction: single: upstream: name: gloo-system-gateway-proxy-8080 namespace: gloo-system - domains: - gloo-system-gloo-9977 name: gloo-system-gloo-9977 routes: - matcher: prefix: / routeAction: single: upstream: name: gloo-system-gloo-9977 namespace: gloo-system - domains: - kube-system-kube-dns-53 name: kube-system-kube-dns-53 routes: - matcher: prefix: / routeAction: single: upstream: name: kube-system-kube-dns-53 namespace: gloo-system - domains: - kube-system-tiller-deploy-44134 name: kube-system-tiller-deploy-44134 routes: - matcher: prefix: / routeAction: single: upstream: name: kube-system-tiller-deploy-44134 namespace: gloo-system name: my-amazing-listener status: reported_by: gloo state: 1 kind: List metadata: resourceVersion: \u0026quot;\u0026quot; selfLink: \u0026quot;\u0026quot;  Cool. Let\u0026rsquo;s leave our controller running and watch it dynamically respond when we add a service to our cluster:\nkubectl apply -f \\ https://raw.githubusercontent.com/solo-io/gloo/master/example/petstore/petstore.yaml  See the service and pod:\nkubectl get pod -n default \u0026amp;\u0026amp; kubectl get svc -n default NAME READY STATUS RESTARTS AGE petstore-6fd84bc9-zdskz 1/1 Running 0 5s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 6d petstore ClusterIP 10.109.34.250 \u0026lt;none\u0026gt; 8080/TCP 5s  The upstream that was created:\nkubectl get upstream NAME AGE default-kubernetes-443 2m default-petstore-8080 46s # \u0026lt;- this one's new gloo-system-gateway-proxy-8080 2m gloo-system-gloo-9977 2m kube-system-kube-dns-53 2m kube-system-tiller-deploy-44134 2m  And check that our proxy object was updated:\nkubectl get proxy -n gloo-system -o yaml apiVersion: v1 items: - apiVersion: gloo.solo.io/v1 kind: Proxy metadata: creationTimestamp: 2019-02-11T19:03:48Z generation: 1 name: my-cool-proxy namespace: gloo-system resourceVersion: \u0026quot;470446\u0026quot; selfLink: /apis/gloo.solo.io/v1/namespaces/gloo-system/proxies/my-cool-proxy uid: c2f058fb-2e2f-11e9-b401-c075ea19232f spec: listeners: - bindAddress: '::' bindPort: 8080 httpListener: virtualHosts: ... - domains: - default-petstore-8080 name: default-petstore-8080 routes: - matcher: prefix: / routeAction: single: upstream: name: default-petstore-8080 namespace: gloo-system ... name: my-amazing-listener status: reported_by: gloo state: 1 kind: List metadata: resourceVersion: \u0026quot;\u0026quot; selfLink: \u0026quot;\u0026quot;  The proxy should have been create with the default-petstore-8080 virtualHost.\nNow that we have a proxy called my-cool-proxy, Gloo will be serving xDS configuration that matches this proxy CRD. However, we don\u0026rsquo;t actually have an Envoy instance deployed that will receive this config. In the next section, we\u0026rsquo;ll walk through the steps to deploy an Envoy pod wired to receive config from Gloo, identifying itself as my-cool-proxy.\nDeploying Envoy to Kubernetes Gloo comes pre-installed with at least one proxy depending on your setup: the gateway-proxy. This proxy is configured by the gateway proxy controller. It\u0026rsquo;s not very different from the controller we just wrote!\nWe\u0026rsquo;ll need to deploy another proxy that will register to Gloo with it\u0026rsquo;s role configured to match the name of our proxy CRD, my-cool-proxy. Let\u0026rsquo;s do it!\nCreating the ConfigMap Envoy needs a ConfigMap which points it at Gloo as its configuration server. Run the following command to create the configmap you\u0026rsquo;ll need:\ncat \u0026lt;\u0026lt; EOF | kubectl apply -f - apiVersion: v1 kind: ConfigMap metadata: name: my-cool-envoy-config namespace: default data: envoy.yaml: | node: cluster: \u0026quot;1\u0026quot; id: \u0026quot;1\u0026quot; metadata: # this line is what connects this envoy instance to our Proxy crd role: \u0026quot;gloo-system~my-cool-proxy\u0026quot; static_resources: clusters: - name: xds_cluster connect_timeout: 5.000s load_assignment: cluster_name: xds_cluster endpoints: - lb_endpoints: - endpoint: address: socket_address: # here's where we provide the hostname of the gloo service address: gloo.gloo-system.svc.cluster.local port_value: 9977 http2_protocol_options: {} type: STRICT_DNS dynamic_resources: ads_config: api_type: GRPC grpc_services: - envoy_grpc: {cluster_name: xds_cluster} cds_config: ads: {} lds_config: ads: {} admin: access_log_path: /dev/null address: socket_address: address: 127.0.0.1 port_value: 19000 EOF  Note that this will create the configmap in the default namespace, but you can run it anywhere. Just make sure the proxy deployment and service all go to the same namespace.\nCreating the Service and Deployment We need to create a LoadBalancer service for our proxy so we can connect to it from the outside. Note that if you\u0026rsquo;re using a Kubernetes Cluster without an external load balancer (e.g. minikube), we\u0026rsquo;ll be using the service\u0026rsquo;s NodePort to connect.\nRun the following command to create the service:\ncat \u0026lt;\u0026lt; EOF | kubectl apply -f - apiVersion: v1 kind: Service metadata: labels: gloo: my-cool-proxy name: my-cool-proxy namespace: default spec: ports: - port: 8080 # \u0026lt;- this port should match the port for the HttpListener in our Proxy CRD protocol: TCP name: http selector: gloo: my-cool-proxy type: LoadBalancer EOF  Finally we\u0026rsquo;ll want to create the deployment itself which will launch a pod with Envoy running inside.\ncat \u0026lt;\u0026lt; EOF | kubectl apply -f - apiVersion: extensions/v1beta1 kind: Deployment metadata: labels: gloo: my-cool-proxy name: my-cool-proxy namespace: default spec: replicas: selector: matchLabels: gloo: my-cool-proxy template: metadata: labels: gloo: my-cool-proxy spec: containers: - args: [\u0026quot;--disable-hot-restart\u0026quot;] env: - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name image: soloio/gloo-envoy-wrapper:0.6.19 imagePullPolicy: Always name: my-cool-proxy ports: - containerPort: 8080 # \u0026lt;- this port should match the port for the HttpListener in our Proxy CRD name: http protocol: TCP volumeMounts: - mountPath: /etc/envoy name: envoy-config volumes: - configMap: name: my-cool-envoy-config name: envoy-config EOF  If all went well, we should see our pod starting successfully in default (or whichever namespace you picked):\nkubectl get pod -n default NAME READY STATUS RESTARTS AGE my-cool-proxy-7bcb58c87d-h4292 1/1 Running 0 3s petstore-6fd84bc9-zdskz 1/1 Running 0 48m  Testing the Proxy If you have glooctl installed, we can grab the HTTP endpoint of the proxy with the following command:\nglooctl proxy url -n default -p my-cool-proxy http://192.168.99.150:30751  Using curl, we can connect to any service in our cluster by using the correct Host header:\ncurl $(glooctl proxy url -n default -p my-cool-proxy)/api/pets -H \u0026quot;Host: default-petstore-8080\u0026quot; [{\u0026quot;id\u0026quot;:1,\u0026quot;name\u0026quot;:\u0026quot;Dog\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;available\u0026quot;},{\u0026quot;id\u0026quot;:2,\u0026quot;name\u0026quot;:\u0026quot;Cat\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;pending\u0026quot;}]  Try any Host header for any upstream name:\nkubectl get upstream NAME AGE default-kubernetes-443 55m default-my-cool-proxy-8080 5m default-petstore-8080 53m gloo-system-gateway-proxy-8080 55m gloo-system-gloo-9977 54m kube-system-kube-dns-53 54m kube-system-tiller-deploy-44134 54m  Sweet! You\u0026rsquo;re an official Gloo developer! You\u0026rsquo;ve just seen how easy it is to extend Gloo to service one of many potential use cases. Take a look at our API Reference Documentation to learn about the wide range of configuration options Proxies expose such as request transformation, SSL termination, serverless computing, and much more.\n"
},
{
	"uri": "https://gloo.solo.io/0.7/installation/install_with_helm/",
	"title": "Installing Gloo with Helm",
	"tags": [],
	"description": "",
	"content": " This document outlines instructions for the setup and configuration of Gloo using Helm. This is the recommended install method for installing Gloo to your production environment as it offers rich customization to the Gloo control plane and the proxies Gloo manages.\nInstallation To install with Helm:\n Add the Gloo Helm repository:\nhelm repo add gloo https://storage.googleapis.com/solo-public-helm  (Optional) Customize the Gloo installation with a value-overrides.yaml file:\n# example value-overrides.yaml namespace: create: false settings: integrations: knative: enabled: true watchNamespaces: [] writeNamespace: mycustomnamespace  See customizing Helm options for the full list of values and their purpose.\n Install Gloo from the Helm Repository:\nhelm install gloo/gloo  If you\u0026rsquo;re using custom overrides:\nhelm install gloo/gloo --values value-overrides.yaml   \nCustomizing Helm Options    option type description     namespace.create bool create the installation namespace   rbac.create bool create rbac rules for the gloo-system service account   settings.watchNamespaces []string whitelist of namespaces for gloo to watch for services and CRDs. leave empty to use all namespaces   settings.writeNamespace string namespace where intermediary CRDs will be written to, e.g. Upstreams written by Gloo Discovery.   settings.integrations.knative.enabled bool enable Gloo to serve as a cluster ingress controller for Knative Serving   settings.integrations.knative.proxy.image.repository string image name (registry/repository) for the knative proxy container. This proxy is configured automatically by Knative as the Knative Cluster Ingress.   settings.integrations.knative.proxy.image.tag string tag for the knative proxy container   settings.integrations.knative.proxy.image.pullPolicy string image pull policy for the knative proxy container   settings.integrations.knative.proxy.httpPort string HTTP port for the proxy   settings.integrations.knative.proxy.httpsPort string HTTPS port for the proxy   settings.integrations.knative.proxy.replicas int number of proxy instances to deploy   settings.create bool create a Settings CRD which configures Gloo controllers at boot time   gloo.deployment.image.repository string image name (registry/repository) for the gloo container. this container is the core controller of the system which watches CRDs and serves Envoy configuration over xDS   gloo.deployment.image.tag string tag for the gloo container   gloo.deployment.image.pullPolicy string image pull policy for gloo container   gloo.deployment.xdsPort string port where gloo serves xDS API to Envoy   gloo.deployment.replicas int number of gloo xds server instances to deploy   gloo.deployment.stats bool expose pod level stats   discovery.deployment.image.repository string image name (registry/repository) for the discovery container. this container adds service discovery and function discovery to Gloo   discovery.deployment.image.tag string tag for the discovery container   discovery.deployment.image.pullPolicy string image pull policy for discovery container   discovery.deployment.stats bool expose pod level stats   gateway.enabled bool enable Gloo API Gateway features   gateway.deployment.image.repository string image name (registry/repository) for the gateway controller container. this container translates Gloo\u0026rsquo;s VirtualService CRDs to the intermediary representation used by the gloo controller   gateway.deployment.image.tag string tag for the gateway controller container   gateway.deployment.image.pullPolicy string image pull policy for the gateway controller container   gateway.deployment.stats bool expose pod level stats   gatewayProxy.deployment.image.repository string image name (registry/repository) for the gateway proxy container. this proxy receives configuration created via VirtualService CRDs   gatewayProxy.deployment.image.tag string tag for the gateway proxy container   gatewayProxy.deployment.image.pullPolicy string image pull policy for the gateway proxy container   gatewayProxy.deployment.httpPort string HTTP port for the proxy   gatewayProxy.deployment.replicas int number of gateway proxy instances to deploy   ingress.enabled bool enable Gloo to function as a standard Kubernetes Ingress Controller (i.e. configure via Kubernetes Ingress objects)   ingress.deployment.image.repository string image name (registry/repository) for the ingress controller container. this container translates Kubernetes Ingress objects to the intermediary representation used by the gloo controller   ingress.deployment.image.tag string tag for the ingress controller container   ingress.deployment.image.pullPolicy string image pull policy for the ingress controller container   ingressProxy.deployment.image.tag string tag for the ingress proxy container   ingressProxy.deployment.image.repository string image name (registry/repository) for the ingress proxy container. this proxy receives configuration created via Kubernetes Ingress objects   ingressProxy.deployment.image.pullPolicy string image pull policy for the ingress proxy container   ingressProxy.deployment.httpPort string HTTP port for the proxy   ingressProxy.deployment.httpsPort string HTTPS port for the proxy   ingressProxy.deployment.replicas int number of ingress proxy instances to deploy    "
},
{
	"uri": "https://gloo.solo.io/0.8/installation/install_with_helm/",
	"title": "Installing Gloo with Helm",
	"tags": [],
	"description": "",
	"content": " This document outlines instructions for the setup and configuration of Gloo using Helm. This is the recommended install method for installing Gloo to your production environment as it offers rich customization to the Gloo control plane and the proxies Gloo manages.\nInstallation To install with Helm:\n Add the Gloo Helm repository:\nhelm repo add gloo https://storage.googleapis.com/solo-public-helm  (Optional) Customize the Gloo installation with a value-overrides.yaml file:\n# example value-overrides.yaml namespace: create: false settings: integrations: knative: enabled: true watchNamespaces: [] writeNamespace: mycustomnamespace  See customizing Helm options for the full list of values and their purpose.\n Install Gloo from the Helm Repository:\nhelm install gloo/gloo  If you\u0026rsquo;re using custom overrides:\nhelm install gloo/gloo --values value-overrides.yaml   \nCustomizing Helm Options    option type description     namespace.create bool create the installation namespace   rbac.create bool create rbac rules for the gloo-system service account   settings.watchNamespaces []string whitelist of namespaces for gloo to watch for services and CRDs. leave empty to use all namespaces   settings.writeNamespace string namespace where intermediary CRDs will be written to, e.g. Upstreams written by Gloo Discovery.   settings.integrations.knative.enabled bool enable Gloo to serve as a cluster ingress controller for Knative Serving   settings.integrations.knative.proxy.image.repository string image name (registry/repository) for the knative proxy container. This proxy is configured automatically by Knative as the Knative Cluster Ingress.   settings.integrations.knative.proxy.image.tag string tag for the knative proxy container   settings.integrations.knative.proxy.image.pullPolicy string image pull policy for the knative proxy container   settings.integrations.knative.proxy.httpPort string HTTP port for the proxy   settings.integrations.knative.proxy.httpsPort string HTTPS port for the proxy   settings.integrations.knative.proxy.replicas int number of proxy instances to deploy   settings.create bool create a Settings CRD which configures Gloo controllers at boot time   gloo.deployment.image.repository string image name (registry/repository) for the gloo container. this container is the core controller of the system which watches CRDs and serves Envoy configuration over xDS   gloo.deployment.image.tag string tag for the gloo container   gloo.deployment.image.pullPolicy string image pull policy for gloo container   gloo.deployment.xdsPort string port where gloo serves xDS API to Envoy   gloo.deployment.replicas int number of gloo xds server instances to deploy   gloo.deployment.stats bool expose pod level stats   discovery.deployment.image.repository string image name (registry/repository) for the discovery container. this container adds service discovery and function discovery to Gloo   discovery.deployment.image.tag string tag for the discovery container   discovery.deployment.image.pullPolicy string image pull policy for discovery container   discovery.deployment.stats bool expose pod level stats   gateway.enabled bool enable Gloo API Gateway features   gateway.deployment.image.repository string image name (registry/repository) for the gateway controller container. this container translates Gloo\u0026rsquo;s VirtualService CRDs to the intermediary representation used by the gloo controller   gateway.deployment.image.tag string tag for the gateway controller container   gateway.deployment.image.pullPolicy string image pull policy for the gateway controller container   gateway.deployment.stats bool expose pod level stats   gatewayProxy.deployment.image.repository string image name (registry/repository) for the gateway proxy container. this proxy receives configuration created via VirtualService CRDs   gatewayProxy.deployment.image.tag string tag for the gateway proxy container   gatewayProxy.deployment.image.pullPolicy string image pull policy for the gateway proxy container   gatewayProxy.deployment.httpPort string HTTP port for the proxy   gatewayProxy.deployment.replicas int number of gateway proxy instances to deploy   ingress.enabled bool enable Gloo to function as a standard Kubernetes Ingress Controller (i.e. configure via Kubernetes Ingress objects)   ingress.deployment.image.repository string image name (registry/repository) for the ingress controller container. this container translates Kubernetes Ingress objects to the intermediary representation used by the gloo controller   ingress.deployment.image.tag string tag for the ingress controller container   ingress.deployment.image.pullPolicy string image pull policy for the ingress controller container   ingressProxy.deployment.image.tag string tag for the ingress proxy container   ingressProxy.deployment.image.repository string image name (registry/repository) for the ingress proxy container. this proxy receives configuration created via Kubernetes Ingress objects   ingressProxy.deployment.image.pullPolicy string image pull policy for the ingress proxy container   ingressProxy.deployment.httpPort string HTTP port for the proxy   ingressProxy.deployment.httpsPort string HTTPS port for the proxy   ingressProxy.deployment.replicas int number of ingress proxy instances to deploy    "
},
{
	"uri": "https://gloo.solo.io/0.7/introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": " Using Gloo  Kubernetes ingress controller: Gloo can function as a feature-rich ingress controller, built on top of the Envoy Proxy. Next-generation API gateway : Gloo provides a long list of API gateway features, including rate limiting, circuit breaking, retries, caching, external authentication and authorization, transformation, service-mesh integration, and security. Hybrid apps: Gloo creates applications that route to backends implemented as microservices, serverless functions, and legacy apps. This feature can help users to gradually migrate from their legacy code to microservices and serverless; can let users add new functionalities using cloud-native technologies while maintaining their legacy codebase; can be used in cases where different teams in an organization choose different architectures; and more. See here for more on the Hybrid App paradigm.  What makes Gloo unique  Function-level routing allows integration of legacy applications, microservices and serverless: Gloo can route requests directly to functions, which can be a serverless function call (e.g. Lambda, Google Cloud Function, OpenFaaS function, etc.), an API call on a microservice or a legacy service (e.g. a REST API call, OpenAPI operation, XML/SOAP request etc.), or publishing to a message queue (e.g. NATS, AMQP, etc.). This unique ability is what makes Gloo the only API gateway that supports hybrid apps, as well as the only one that does not tie the user to a specific paradigm. Gloo incorporates vetted open-source projects to provide broad functionality: Gloo support high-quality features by integrating with top open-source projects, including gRPC, GraphQL, OpenTracing, NATS and more. Gloo\u0026rsquo;s architecture allows rapid integration of future popular open-source projects as they emerge. Full automated discovery lets users move fast: Upon launch, Gloo creates a catalog of all available destinations, and continuously maintains it up to date. This takes the responsibility for \u0026lsquo;bookkeeping\u0026rsquo; away from the developers, and guarantees that new feature become available as soon as they are ready. Gloo discovers across IaaS, PaaS and FaaS providers, as well as Swagger, gRPC, and GraphQL. Gloo integrates intimately with the user\u0026rsquo;s environment: with Gloo, users are free to choose their favorite tools for scheduling (such as K8s, Nomad, OpenShift, etc), persistence (K8s, Consul, etcd, etc) and security (K8s, Vault).   Features Supported Platforms:\n Kubernetes\n HashiCorp Stack (Vault, Consul, Nomad)\n AWS Lambda\n Knative\n Microsoft Azure Functions\n Google Cloud Platform Functions\n  Routing Features:\n Dynamic Load Balancing: Load balance traffic across multiple upstream services.\n Health Checks: Active and passive monitoring of your upstream services.\n OpenTracing: Monitor requests using the well-supported OpenTracing standard\n Monitoring: Export HTTP metrics to Prometheus or Statsd\n SSL: Highly customizable options for adding SSL encryption to upstream services with full support for SNI.\n Transformations: Add, remove, or manipulate HTTP requests and responses.\n Automated API Translation: Automatically transform client requests to upstream API calls using Gloo’s Function Discovery\n CLI: Control your Gloo cluster from the command line.\n Declarative API: Gloo features a declarative YAML-based API; store your configuration as code and commit it with your projects.\n Failure Recovery: Gloo is completely stateless and will immediately return to the desired configuration at boot time.\n Scalability: Gloo acts as a control plane for Envoy, allowing Envoy instances and Gloo instances to be scaled independently. Both Gloo and Envoy are stateless.\n Performance: Gloo leverages Envoy for its high performance and low footprint.\n Plugins: Extendable architecture for adding functionality and integrations to Gloo.\n Tooling: Build and Deployment tool for customized builds and deployment options\n Events: Invoke APIs using CloudEvents.\n Pub/Sub: Publish HTTP requests to NATS\n JSON-to-gRPC transcoding: Connect JSON clients to gRPC services\n  "
},
{
	"uri": "https://gloo.solo.io/0.8/introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": " Using Gloo  Kubernetes ingress controller: Gloo can function as a feature-rich ingress controller, built on top of the Envoy Proxy. Next-generation API gateway : Gloo provides a long list of API gateway features, including rate limiting, circuit breaking, retries, caching, external authentication and authorization, transformation, service-mesh integration, and security. Hybrid apps: Gloo creates applications that route to backends implemented as microservices, serverless functions, and legacy apps. This feature can help users to gradually migrate from their legacy code to microservices and serverless; can let users add new functionalities using cloud-native technologies while maintaining their legacy codebase; can be used in cases where different teams in an organization choose different architectures; and more. See here for more on the Hybrid App paradigm.  What makes Gloo unique  Function-level routing allows integration of legacy applications, microservices and serverless: Gloo can route requests directly to functions, which can be a serverless function call (e.g. Lambda, Google Cloud Function, OpenFaaS function, etc.), an API call on a microservice or a legacy service (e.g. a REST API call, OpenAPI operation, XML/SOAP request etc.), or publishing to a message queue (e.g. NATS, AMQP, etc.). This unique ability is what makes Gloo the only API gateway that supports hybrid apps, as well as the only one that does not tie the user to a specific paradigm. Gloo incorporates vetted open-source projects to provide broad functionality: Gloo support high-quality features by integrating with top open-source projects, including gRPC, GraphQL, OpenTracing, NATS and more. Gloo\u0026rsquo;s architecture allows rapid integration of future popular open-source projects as they emerge. Full automated discovery lets users move fast: Upon launch, Gloo creates a catalog of all available destinations, and continuously maintains it up to date. This takes the responsibility for \u0026lsquo;bookkeeping\u0026rsquo; away from the developers, and guarantees that new feature become available as soon as they are ready. Gloo discovers across IaaS, PaaS and FaaS providers, as well as Swagger, gRPC, and GraphQL. Gloo integrates intimately with the user\u0026rsquo;s environment: with Gloo, users are free to choose their favorite tools for scheduling (such as K8s, Nomad, OpenShift, etc), persistence (K8s, Consul, etcd, etc) and security (K8s, Vault).   Features Supported Platforms:\n Kubernetes\n HashiCorp Stack (Vault, Consul, Nomad)\n AWS Lambda\n Knative\n Microsoft Azure Functions\n Google Cloud Platform Functions\n  Routing Features:\n Dynamic Load Balancing: Load balance traffic across multiple upstream services.\n Health Checks: Active and passive monitoring of your upstream services.\n OpenTracing: Monitor requests using the well-supported OpenTracing standard\n Monitoring: Export HTTP metrics to Prometheus or Statsd\n SSL: Highly customizable options for adding SSL encryption to upstream services with full support for SNI.\n Transformations: Add, remove, or manipulate HTTP requests and responses.\n Automated API Translation: Automatically transform client requests to upstream API calls using Gloo’s Function Discovery\n CLI: Control your Gloo cluster from the command line.\n Declarative API: Gloo features a declarative YAML-based API; store your configuration as code and commit it with your projects.\n Failure Recovery: Gloo is completely stateless and will immediately return to the desired configuration at boot time.\n Scalability: Gloo acts as a control plane for Envoy, allowing Envoy instances and Gloo instances to be scaled independently. Both Gloo and Envoy are stateless.\n Performance: Gloo leverages Envoy for its high performance and low footprint.\n Plugins: Extendable architecture for adding functionality and integrations to Gloo.\n Tooling: Build and Deployment tool for customized builds and deployment options\n Events: Invoke APIs using CloudEvents.\n Pub/Sub: Publish HTTP requests to NATS\n JSON-to-gRPC transcoding: Connect JSON clients to gRPC services\n  "
},
{
	"uri": "https://gloo.solo.io/0.7/operator_guide/understanding_gloo_configuration/",
	"title": "Understanding Gloo Configuration",
	"tags": [],
	"description": "",
	"content": " NOTE\nGloo currently requires a running Kubernetes cluster to use as data store. We are adding additional storage options in an upcoming release. For a quick test run of Gloo, you can deploy Gloo on minikube.\nTo be notified of the most recent updates, follow us on Twitter and join our community Slack channel.\nConfiguration storage By default, Gloo leverages Kubernetes to implement its declarative infrastructure model. The Gloo configuration consists of a set of YAML documents that are stored in Kubernetes as custom resources. Each of the Gloo configuration objects (virtual services, upstreams, etc.) is an instance of a Kubernetes Custom Resource Definition (CRD).\nStoring configuration as Kubernetes CRDs has several advantages: 1. All Gloo resources can be managed using standard Kubernetes APIs and tools. You can interact with them using kubectl just as you would with normal Kubernetes resources. Moreover, you can perform the same actions programmatically via the Kubernetes REST API and the provided Client Libraries built on top of it. 2. Your Gloo configuration lives close to the resources it applies to. You don\u0026rsquo;t need to run any additional software. Your services and the configurations that define how traffic is routed to them share the same infrastructure and APIs. Since Gloo resources are defined as their own resource class they are completely decoupled and isolated from one another. You don\u0026rsquo;t have to worry about changes in your Kubernetes resources affecting your Gloo CRDs. 3. You can leverage existing Kubernetes features to build additional functionality around Gloo. Want to limit write access to the Gloo configuration to sysadmins but give everyone else read access? Just use the Kubernetes RBAC API to define the correspondent roles and permissions, like you would with any other Kubernetes resource.\nLet\u0026rsquo;s look at some concrete examples that illustrate the relationship between Gloo resources and Kubernetes CRDs.\nList Gloo resources with kubectl In the Basic Routing chapter of the Getting Started guide we created a Virtual Service containing one route to the default-petstore-8080 Upstream by submitting the following command:\nglooctl add route \\ --path-exact /sample-route-1 \\ --dest-name default-petstore-8080 \\ --prefix-rewrite /api/pets  We can retrieve the Virtual Service specification by running:\nglooctl get virtualservices default -o yaml  metadata: name: default namespace: gloo-system resourceVersion: \u0026quot;1917\u0026quot; status: reportedBy: gateway state: Accepted subresourceStatuses: '*v1.Proxy gloo-system gateway-proxy': reportedBy: gloo state: Accepted virtualHost: domains: - '*' name: gloo-system.default routes: - matcher: exact: /sample-route-1 routeAction: single: upstream: name: default-petstore-8080 namespace: gloo-system routePlugins: prefixRewrite: prefixRewrite: /api/pets  The same information can be accessed via kubectl by running:\nkubectl get virtualservices.gateway.solo.io/default -n gloo-system -o yaml  apiVersion: gateway.solo.io/v1 kind: VirtualService metadata: creationTimestamp: 2019-02-11T20:44:07Z generation: 5 name: default namespace: gloo-system resourceVersion: \u0026quot;1917\u0026quot; selfLink: /apis/gateway.solo.io/v1/namespaces/gloo-system/virtualservices/default uid: c6f29633-2e3d-11e9-9ca8-080027dd6d38 spec: virtualHost: domains: - '*' name: gloo-system.default routes: - matcher: exact: /sample-route-1 routeAction: single: upstream: name: default-petstore-8080 namespace: gloo-system routePlugins: prefixRewrite: prefixRewrite: /api/pets status: reported_by: gateway state: 1 subresource_statuses: '*v1.Proxy gloo-system gateway-proxy': reported_by: gloo state: 1  Note how the above document is a superset of the one returned by glooctl.\nWe are able to access Virtual Services using kubectl because Gloo registered a VirtualService CRD with the Kubernetes API server. You can verify this by running kubectl get crds, which should return a list similar to this one:\nNAME CREATED AT gateways.gateway.solo.io 2019-02-11T20:37:04Z proxies.gloo.solo.io 2019-02-11T20:37:04Z settings.gloo.solo.io 2019-02-11T20:36:55Z upstreams.gloo.solo.io 2019-02-11T20:37:01Z virtualservices.gateway.solo.io 2019-02-11T20:37:04Z  You can use the short resource name instead of the fully qualified one in your commands (e.g. kubectl get virtualservice -n gloo-system or even kubectl get vs -n gloo-system instead of kubectl get virtualservices.gateway.solo.io/default -n gloo-system).\nTry to run kubectl describe crds/virtualservices.gateway.solo.io to see what a Custom Resource Definition for a Gloo resource looks like.\nWriting Gloo resources with kubectl Instead of using glooctl, the same Virtual Service could be created using kubectl. We first have to create a file ~/my-virtual-service.yaml with the following contents:\napiVersion: gateway.solo.io/v1 kind: VirtualService metadata: name: default namespace: gloo-system spec: virtualHost: domains: - '*' name: gloo-system.default routes: - matcher: exact: /sample-route-1 routeAction: single: upstream: name: default-petstore-8080 namespace: gloo-system routePlugins: prefixRewrite: prefixRewrite: /api/pets  We can then use kubectl apply to create the resource:\nkubectl apply -f ~/my-virtual-service.yaml  You can verify that the Virtual Service and its route have been created by running kubectl get vs/default -n gloo-system -o yaml:\napiVersion: gateway.solo.io/v1 kind: VirtualService metadata: creationTimestamp: 2019-02-11T20:44:07Z generation: 5 name: default namespace: gloo-system resourceVersion: \u0026quot;1917\u0026quot; selfLink: /apis/gateway.solo.io/v1/namespaces/gloo-system/virtualservices/default uid: c6f29633-2e3d-11e9-9ca8-080027dd6d38 spec: virtualHost: domains: - '*' name: gloo-system.default routes: - matcher: exact: /sample-route-1 routeAction: single: upstream: name: default-petstore-8080 namespace: gloo-system routePlugins: prefixRewrite: prefixRewrite: /api/pets status: reported_by: gateway state: 1 subresource_statuses: '*v1.Proxy gloo-system gateway-proxy': reported_by: gloo state: 1  Using RBAC to regulate access to Gloo resources Let\u0026rsquo;s say that we want to restrict access to Virtual Services. Only the user Alice should have write access, while users in the Developers group will be able to perform only read operations. Assuming we have the correct authenticator modules configured and enabled in our Kubernetes cluster, defining these access rules is as simple as kubectl applying the following YAML documents:\nkind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: namespace: default name: virtualservice-reader rules: - apiGroups: [\u0026quot;gateway.solo.io/v1\u0026quot;] resources: [\u0026quot;virtualservices\u0026quot;] verbs: [\u0026quot;get\u0026quot;, \u0026quot;watch\u0026quot;, \u0026quot;list\u0026quot;]  kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: read-virtualservices namespace: gloo-system subjects: - kind: Group name: Developers apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: virtualservice-reader apiGroup: rbac.authorization.k8s.io  kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: namespace: gloo-system name: virtualservice-admin rules: - apiGroups: [\u0026quot;gateway.solo.io/v1\u0026quot;] resources: [\u0026quot;virtualservices\u0026quot;] verbs: [\u0026quot;get\u0026quot;, \u0026quot;watch\u0026quot;, \u0026quot;list\u0026quot;, \u0026quot;create\u0026quot;, \u0026quot;update\u0026quot;, \u0026quot;patch\u0026quot;, \u0026quot;delete\u0026quot;]  kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: admin-virtualservices namespace: gloo-system subjects: - kind: User name: Alice apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: virtualservice-admin apiGroup: rbac.authorization.k8s.io  After these resources have been created, if Bob, who belongs to the Developers group, tries to create a virtual service by running\nkubectl apply -f ~/my-virtual-service.yaml  he will be presented with an error message:\nError from server (Forbidden): virtualservices is forbidden: User \u0026quot;Bob\u0026quot; cannot create virtualservices in the namespace \u0026quot;gloo-system\u0026quot;  Again, this works because Kubernetes treats CRDs as regular resources.\n"
},
{
	"uri": "https://gloo.solo.io/0.8/operator_guide/understanding_gloo_configuration/",
	"title": "Understanding Gloo Configuration",
	"tags": [],
	"description": "",
	"content": " NOTE\nGloo currently requires a running Kubernetes cluster to use as data store. We are adding additional storage options in an upcoming release. For a quick test run of Gloo, you can deploy Gloo on minikube.\nTo be notified of the most recent updates, follow us on Twitter and join our community Slack channel.\nConfiguration storage By default, Gloo leverages Kubernetes to implement its declarative infrastructure model. The Gloo configuration consists of a set of YAML documents that are stored in Kubernetes as custom resources. Each of the Gloo configuration objects (virtual services, upstreams, etc.) is an instance of a Kubernetes Custom Resource Definition (CRD).\nStoring configuration as Kubernetes CRDs has several advantages: 1. All Gloo resources can be managed using standard Kubernetes APIs and tools. You can interact with them using kubectl just as you would with normal Kubernetes resources. Moreover, you can perform the same actions programmatically via the Kubernetes REST API and the provided Client Libraries built on top of it. 2. Your Gloo configuration lives close to the resources it applies to. You don\u0026rsquo;t need to run any additional software. Your services and the configurations that define how traffic is routed to them share the same infrastructure and APIs. Since Gloo resources are defined as their own resource class they are completely decoupled and isolated from one another. You don\u0026rsquo;t have to worry about changes in your Kubernetes resources affecting your Gloo CRDs. 3. You can leverage existing Kubernetes features to build additional functionality around Gloo. Want to limit write access to the Gloo configuration to sysadmins but give everyone else read access? Just use the Kubernetes RBAC API to define the correspondent roles and permissions, like you would with any other Kubernetes resource.\nLet\u0026rsquo;s look at some concrete examples that illustrate the relationship between Gloo resources and Kubernetes CRDs.\nList Gloo resources with kubectl In the Basic Routing chapter of the Getting Started guide we created a Virtual Service containing one route to the default-petstore-8080 Upstream by submitting the following command:\nglooctl add route \\ --path-exact /sample-route-1 \\ --dest-name default-petstore-8080 \\ --prefix-rewrite /api/pets  We can retrieve the Virtual Service specification by running:\nglooctl get virtualservices default -o yaml  metadata: name: default namespace: gloo-system resourceVersion: \u0026quot;1917\u0026quot; status: reportedBy: gateway state: Accepted subresourceStatuses: '*v1.Proxy gloo-system gateway-proxy': reportedBy: gloo state: Accepted virtualHost: domains: - '*' name: gloo-system.default routes: - matcher: exact: /sample-route-1 routeAction: single: upstream: name: default-petstore-8080 namespace: gloo-system routePlugins: prefixRewrite: prefixRewrite: /api/pets  The same information can be accessed via kubectl by running:\nkubectl get virtualservices.gateway.solo.io/default -n gloo-system -o yaml  apiVersion: gateway.solo.io/v1 kind: VirtualService metadata: creationTimestamp: 2019-02-11T20:44:07Z generation: 5 name: default namespace: gloo-system resourceVersion: \u0026quot;1917\u0026quot; selfLink: /apis/gateway.solo.io/v1/namespaces/gloo-system/virtualservices/default uid: c6f29633-2e3d-11e9-9ca8-080027dd6d38 spec: virtualHost: domains: - '*' name: gloo-system.default routes: - matcher: exact: /sample-route-1 routeAction: single: upstream: name: default-petstore-8080 namespace: gloo-system routePlugins: prefixRewrite: prefixRewrite: /api/pets status: reported_by: gateway state: 1 subresource_statuses: '*v1.Proxy gloo-system gateway-proxy': reported_by: gloo state: 1  Note how the above document is a superset of the one returned by glooctl.\nWe are able to access Virtual Services using kubectl because Gloo registered a VirtualService CRD with the Kubernetes API server. You can verify this by running kubectl get crds, which should return a list similar to this one:\nNAME CREATED AT gateways.gateway.solo.io 2019-02-11T20:37:04Z proxies.gloo.solo.io 2019-02-11T20:37:04Z settings.gloo.solo.io 2019-02-11T20:36:55Z upstreams.gloo.solo.io 2019-02-11T20:37:01Z virtualservices.gateway.solo.io 2019-02-11T20:37:04Z  You can use the short resource name instead of the fully qualified one in your commands (e.g. kubectl get virtualservice -n gloo-system or even kubectl get vs -n gloo-system instead of kubectl get virtualservices.gateway.solo.io/default -n gloo-system).\nTry to run kubectl describe crds/virtualservices.gateway.solo.io to see what a Custom Resource Definition for a Gloo resource looks like.\nWriting Gloo resources with kubectl Instead of using glooctl, the same Virtual Service could be created using kubectl. We first have to create a file ~/my-virtual-service.yaml with the following contents:\napiVersion: gateway.solo.io/v1 kind: VirtualService metadata: name: default namespace: gloo-system spec: virtualHost: domains: - '*' name: gloo-system.default routes: - matcher: exact: /sample-route-1 routeAction: single: upstream: name: default-petstore-8080 namespace: gloo-system routePlugins: prefixRewrite: prefixRewrite: /api/pets  We can then use kubectl apply to create the resource:\nkubectl apply -f ~/my-virtual-service.yaml  You can verify that the Virtual Service and its route have been created by running kubectl get vs/default -n gloo-system -o yaml:\napiVersion: gateway.solo.io/v1 kind: VirtualService metadata: creationTimestamp: 2019-02-11T20:44:07Z generation: 5 name: default namespace: gloo-system resourceVersion: \u0026quot;1917\u0026quot; selfLink: /apis/gateway.solo.io/v1/namespaces/gloo-system/virtualservices/default uid: c6f29633-2e3d-11e9-9ca8-080027dd6d38 spec: virtualHost: domains: - '*' name: gloo-system.default routes: - matcher: exact: /sample-route-1 routeAction: single: upstream: name: default-petstore-8080 namespace: gloo-system routePlugins: prefixRewrite: prefixRewrite: /api/pets status: reported_by: gateway state: 1 subresource_statuses: '*v1.Proxy gloo-system gateway-proxy': reported_by: gloo state: 1  Using RBAC to regulate access to Gloo resources Let\u0026rsquo;s say that we want to restrict access to Virtual Services. Only the user Alice should have write access, while users in the Developers group will be able to perform only read operations. Assuming we have the correct authenticator modules configured and enabled in our Kubernetes cluster, defining these access rules is as simple as kubectl applying the following YAML documents:\nkind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: namespace: default name: virtualservice-reader rules: - apiGroups: [\u0026quot;gateway.solo.io/v1\u0026quot;] resources: [\u0026quot;virtualservices\u0026quot;] verbs: [\u0026quot;get\u0026quot;, \u0026quot;watch\u0026quot;, \u0026quot;list\u0026quot;]  kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: read-virtualservices namespace: gloo-system subjects: - kind: Group name: Developers apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: virtualservice-reader apiGroup: rbac.authorization.k8s.io  kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: namespace: gloo-system name: virtualservice-admin rules: - apiGroups: [\u0026quot;gateway.solo.io/v1\u0026quot;] resources: [\u0026quot;virtualservices\u0026quot;] verbs: [\u0026quot;get\u0026quot;, \u0026quot;watch\u0026quot;, \u0026quot;list\u0026quot;, \u0026quot;create\u0026quot;, \u0026quot;update\u0026quot;, \u0026quot;patch\u0026quot;, \u0026quot;delete\u0026quot;]  kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: admin-virtualservices namespace: gloo-system subjects: - kind: User name: Alice apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: virtualservice-admin apiGroup: rbac.authorization.k8s.io  After these resources have been created, if Bob, who belongs to the Developers group, tries to create a virtual service by running\nkubectl apply -f ~/my-virtual-service.yaml  he will be presented with an error message:\nError from server (Forbidden): virtualservices is forbidden: User \u0026quot;Bob\u0026quot; cannot create virtualservices in the namespace \u0026quot;gloo-system\u0026quot;  Again, this works because Kubernetes treats CRDs as regular resources.\n"
},
{
	"uri": "https://gloo.solo.io/0.7/introduction/architecture/",
	"title": "Architecture",
	"tags": [],
	"description": "",
	"content": "  Overview Component Architecture Discovery Architecture  \nOverview Gloo aggregates back end services and provides function-to-function translation for clients, allowing decoupling from back end APIs\nClients issue requests or emit events to routes defined on Gloo. These routes are mapped to functions on upstream services by Gloo\u0026rsquo;s configuration (provided by clients of Gloo\u0026rsquo;s API).\nClients connect to proxies managed by Gloo who then transform requests into function invocations for a variety of functional backends. Non-functional backends are supported via a traditional Gateway-to-Service routing model.\nGloo performs the necessary transformation between the routes defined by clients and the back end functions. Gloo is able to support various upstream functions through its extendable function plugin interface.\nGloo offers first-class API management features on all functions:\n Timeouts Metrics \u0026amp; Tracing Health Checks Retries Advanced load balancing TLS Termination with SNI Support HTTP Header modification  \nComponent Architecture In the most basic sense, Gloo is a translation engine and Envoy xDS server providing advanced configuration for Envoy (including Gloo\u0026rsquo;s custom Envoy filters). Gloo follows an event-based architecture, watching various sources of configuration for updates and responding immediately with v2 gRPC updates to Envoy.\n The Config Watcher watches the storage layer for updates to user configuration objects (Upstreams and Virtual Services) The Secret Watcher watches a secret store for updates to secrets (which are required for certain plugins such as the AWS Lambda Plugin) Endpoint Discovery watches service registries such as Kubernetes, Cloud Foundry, and Consul for IPs associated with services. Endpoint Discovery is plugin-specific. For example, the Kubernetes Plugin runs its own Endpoint Discovery goroutine. The Translator receives snapshots of the entire state, composed of user configuration, secrets, and discovery information and initiates a new translation loop, creating a new Envoy xDS Snapshot.  The translation cycle starts by creating Envoy clusters from all configured upstreams. Each upstream has a type, indicating which upstream plugin is responsible for processing that upstream object. Correctly configured upstreams are converted into Envoy clusters by their respective plugins. Plugins may set cluster metadata on the cluster object. The next step in the translation cycle is to process all the functions on each upstream. Functional plugins process the functions on upstream, setting function-specifc cluster metadata, which will be later processed by function-specific Envoy filters. The next step generates all of the Envoy routes via the route plugins . Routes are generated for each route rule defined on the virtual service objects. When all of the routes are created, the translator aggregates them into Envoy virtual services and adds them to a new Envoy HTTP Connection Manager configuration. Filter plugins are queried for their filter configurations, generating the list of HTTP Filters that will go on the Envoy listeners. Finally, a snapshot is composed of the all the valid endpoints, clusters, rds configs, and listeners  The Reporter receives a validation report for every upstream and virtual service processed by the translator. Any invalid config objects are reported back to the user through the storage layer. Invalid objects are marked as \u0026ldquo;Rejected\u0026rdquo; with detailed error messages describing mistakes in the user config. The final snapshot is passed to the xDS server, which notifies Envoy of a successful config update, updating the Envoy cluster with a new configuration to match the desired state set by Gloo.\n  \nDiscovery Architecture Gloo is supported by a suite of optional discovery services that automatically discover and configure gloo with upstreams and functions to simplify routing for users and self-service.\nDiscovery services act as automated Gloo clients, automatically populating the storage layer with upstreams and functions to facilitate easy routing for users.\nDiscovery is optional, but when enabled, will attempt to discover available upstreams and functions.\nCurrently supported:\n Kubernetes Service-Based Upstream Discovery AWS Lambda-Based Function Discovery Google Cloud Function-Based Function Discovery OpenAPI-Based Function Discovery Istio-Based Route Rule Discovery (Experimental)  "
},
{
	"uri": "https://gloo.solo.io/0.8/introduction/architecture/",
	"title": "Architecture",
	"tags": [],
	"description": "",
	"content": "  Overview Component Architecture Discovery Architecture  \nOverview Gloo aggregates back end services and provides function-to-function translation for clients, allowing decoupling from back end APIs\nClients issue requests or emit events to routes defined on Gloo. These routes are mapped to functions on upstream services by Gloo\u0026rsquo;s configuration (provided by clients of Gloo\u0026rsquo;s API).\nClients connect to proxies managed by Gloo who then transform requests into function invocations for a variety of functional backends. Non-functional backends are supported via a traditional Gateway-to-Service routing model.\nGloo performs the necessary transformation between the routes defined by clients and the back end functions. Gloo is able to support various upstream functions through its extendable function plugin interface.\nGloo offers first-class API management features on all functions:\n Timeouts Metrics \u0026amp; Tracing Health Checks Retries Advanced load balancing TLS Termination with SNI Support HTTP Header modification  \nComponent Architecture In the most basic sense, Gloo is a translation engine and Envoy xDS server providing advanced configuration for Envoy (including Gloo\u0026rsquo;s custom Envoy filters). Gloo follows an event-based architecture, watching various sources of configuration for updates and responding immediately with v2 gRPC updates to Envoy.\n The Config Watcher watches the storage layer for updates to user configuration objects (Upstreams and Virtual Services) The Secret Watcher watches a secret store for updates to secrets (which are required for certain plugins such as the AWS Lambda Plugin) Endpoint Discovery watches service registries such as Kubernetes, Cloud Foundry, and Consul for IPs associated with services. Endpoint Discovery is plugin-specific. For example, the Kubernetes Plugin runs its own Endpoint Discovery goroutine. The Translator receives snapshots of the entire state, composed of user configuration, secrets, and discovery information and initiates a new translation loop, creating a new Envoy xDS Snapshot.  The translation cycle starts by creating Envoy clusters from all configured upstreams. Each upstream has a type, indicating which upstream plugin is responsible for processing that upstream object. Correctly configured upstreams are converted into Envoy clusters by their respective plugins. Plugins may set cluster metadata on the cluster object. The next step in the translation cycle is to process all the functions on each upstream. Functional plugins process the functions on upstream, setting function-specifc cluster metadata, which will be later processed by function-specific Envoy filters. The next step generates all of the Envoy routes via the route plugins . Routes are generated for each route rule defined on the virtual service objects. When all of the routes are created, the translator aggregates them into Envoy virtual services and adds them to a new Envoy HTTP Connection Manager configuration. Filter plugins are queried for their filter configurations, generating the list of HTTP Filters that will go on the Envoy listeners. Finally, a snapshot is composed of the all the valid endpoints, clusters, rds configs, and listeners  The Reporter receives a validation report for every upstream and virtual service processed by the translator. Any invalid config objects are reported back to the user through the storage layer. Invalid objects are marked as \u0026ldquo;Rejected\u0026rdquo; with detailed error messages describing mistakes in the user config. The final snapshot is passed to the xDS server, which notifies Envoy of a successful config update, updating the Envoy cluster with a new configuration to match the desired state set by Gloo.\n  \nDiscovery Architecture Gloo is supported by a suite of optional discovery services that automatically discover and configure gloo with upstreams and functions to simplify routing for users and self-service.\nDiscovery services act as automated Gloo clients, automatically populating the storage layer with upstreams and functions to facilitate easy routing for users.\nDiscovery is optional, but when enabled, will attempt to discover available upstreams and functions.\nCurrently supported:\n Kubernetes Service-Based Upstream Discovery AWS Lambda-Based Function Discovery Google Cloud Function-Based Function Discovery OpenAPI-Based Function Discovery Istio-Based Route Rule Discovery (Experimental)  "
},
{
	"uri": "https://gloo.solo.io/0.7/introduction/concepts/",
	"title": "Concepts",
	"tags": [],
	"description": "",
	"content": "  Overview Virtual Services  Routes Matchers Destinations  Upstreams  Functions  Secrets  \nOverview The two top-level concepts in Gloo are Virtual Services and Upstreams.\n Virtual Services define a set of route rules that live under a domain or set of domains. Route rules consist of a matcher, which specifies the kind of function calls to match (requests and events, are currently supported), and the name of the destination (or destinations) to route them to.\n Upstreams define destinations for routes. Upstreams tell Gloo what to route to. Upstreams may also define functions and service specs for function-level routing.\n  \nVirtual Services Virtual Services define a set of route rules, an optional SNI configuration for a given domain or set of domains.\nGloo will select the appropriate virtual service (set of routes) based on the domain specified in a request\u0026rsquo;s Host header (in HTTP 1.1) or :authority header (HTTP 2.0).\nVirtual Services support wildcard domains (starting with *).\nGloo will create a default virtual service for the user if the user does not provide one. The default virtual service matches the * domain, which will serve routes for any request that does not include a Host/:authority header, or a request that requests a domain that does not match another virtual service.\nThe each domain specified for a virtualservice must be unique across the set of all virtual services provided to Gloo.\nFor many use cases, it may be sufficient to let all routes live on a single virtual service. In thise scenario, Gloo will use the same set of route rules to for requests, regardless of their Host or :authority header.\nRoute rules consist of a matcher, which specifies the kind of function calls to match (requests and events, are currently supported), and the name of the destination (or destinations, for load balancing) to route them to.\nA simple virtual service with a single route might look like this:\nname: my-app routes: - request_matcher: path_prefix: / single_destination: upstream: name: my-upstream  Note that domains is empty (not specified). That means this virtual service will act as the default virtual service, matching all domains.\n\nRoutes Routes are the primary building block of the virtual service. A route contains a single matcher and one of: a single destination, or a list of weighted destinations.\nIn short, a route is essentially a rule which tells Gloo: if the request matches this matcher, then route it to this destination.\nBecause multiple matchers can match a single request, the order of routes in the virtual service matters. Gloo will select the first route which matches the request when making routing decisions. It is therefore important to place fallback routes (e.g. matching any request for path / with a custom 404 page) towards the bottom of the route list.\n\nMatchers Matchers currently support two types of requests:\n Request Matchers match on properties of HTTP requests. This includes the request path (:path header in HTTP 2.0), method (:method in HTTP 2.0) headers (their keys and optionally their values), and query parameters.\n Event Matchers match properties of HTTP events, as per the CloudEvents specification. Note: the CloudEvents spec is in version 0.1 and likely to be changed in the future. The only property Event Matcher currently matches on is the event-type of an event (specified by the x-event-type request header).\n  \nDestinations Destinations specify where to route a request once a matching route has been selected. A route can point to a single destination, or it can split traffic for that route among a series of weighted destinations.\nA destination can be either an upstream destination or a function destination.\nUpstream Destinations are analogous to Envoy clusters. Requests routed to upstream destinations will be routed to a server which is expected to handle the request once it has been admitted (and possibly transformed) by Gloo.\nFunction Destinations allow requests to be routed directly to functions that live on various upstreams. A function can be a serverless function call (e.g. Lambda, Google Cloud Function, OpenFaaS function, etc.), an API call on a service (e.g. a REST API call, OpenAPI operation, XML/SOAP request etc.), or publishing to a message queue (e.g. NATS, AMQP, etc.). Function-level routing is enabled in Envoy by Gloo\u0026rsquo;s function-level filters. Gloo supports the addition of new upstream types as well as new function types through our plugin interface.\n\nUpstreams Upstreams define destinations for routes. Upstreams tell Gloo what to route to and how to route to them. Gloo determines how to handle routing for the upstream based on its spec field. Upstreams have a type-specific spec field which must be used to provide routing information to Gloo.\nThe most basic upstream type is the static upstream type, which tells Gloo a list of static hosts or dns names logically grouped together for an upstream. More sophisticated upstream types include the kubernetes upstream and the AWS Lambda upstream.\nLet\u0026rsquo;s walk through an example of a kubernetes upstream in order to understand how this works.\nGloo reads in a configuration that looks like the following:\n--- metadata: labels: app: redis discovered_by: kubernetesplugin name: default-redis-6379 namespace: gloo-system resourceVersion: \u0026quot;7010\u0026quot; status: reportedBy: gloo state: Accepted upstreamSpec: kube: selector: gloo: redis serviceName: redis serviceNamespace: gloo-system servicePort: 6379   name tells Gloo what the identifier for this upstream will be (for routes that point to it). type: kubernetes tells Gloo that the kubernetes plugin knows how to route to this upstream spec: ... tells the kubernetes plugin the service name and namespace, which is used by Gloo for routing\n  \nFunctions Some upstream types support functions. For example, we can add some HTTP functions to this upstream, and Gloo will be able to route to those functions, providing request transformation to format incoming requests to the parameters expected by the upstream service.\nWe can now route to the function in our virtual service:\nAn example of a virtual service with a route to this upstream:\nmetadata: name: default namespace: default resourceVersion: \u0026quot;7306\u0026quot; status: reportedBy: gateway state: Accepted subresourceStatuses: '*v1.Proxy gloo-system gateway-proxy': {} virtualHost: domains: - '*' name: default.default routes: - matcher: prefix: / routeAction: single: upstream: name: gloo-system-redis-6379 namespace: gloo-system routePlugins: prefixRewrite: {}  Note that it is necessary to specify parameters for this function invocation. Some function destinations require extensions to be specified on the route they belong to. Documentation for each plugin can be found in the Plugins section.\n\nSecrets Certain plugins such as the AWS Lambda Plugin require the use of secrets for authentication, configuration of SSL Certificates, and other data that should not be stored in plaintext configuration.\nGloo runs an independent (goroutine) controller to monitor secrets. Secrets are stored in their own secret storage layer. Gloo can monitor secrets stored in the following secret storage services:\n Kubernetes Secrets Hashicorp Vault Plaintext files (recommended only for testing)  Secrets must adhere to a structure, specified by the plugin that requires them.\n"
},
{
	"uri": "https://gloo.solo.io/0.8/introduction/concepts/",
	"title": "Concepts",
	"tags": [],
	"description": "",
	"content": "  Overview Virtual Services  Routes Matchers Destinations  Upstreams  Functions  Secrets  \nOverview The two top-level concepts in Gloo are Virtual Services and Upstreams.\n Virtual Services define a set of route rules that live under a domain or set of domains. Route rules consist of a matcher, which specifies the kind of function calls to match (requests and events, are currently supported), and the name of the destination (or destinations) to route them to.\n Upstreams define destinations for routes. Upstreams tell Gloo what to route to. Upstreams may also define functions and service specs for function-level routing.\n  \nVirtual Services Virtual Services define a set of route rules, an optional SNI configuration for a given domain or set of domains.\nGloo will select the appropriate virtual service (set of routes) based on the domain specified in a request\u0026rsquo;s Host header (in HTTP 1.1) or :authority header (HTTP 2.0).\nVirtual Services support wildcard domains (starting with *).\nGloo will create a default virtual service for the user if the user does not provide one. The default virtual service matches the * domain, which will serve routes for any request that does not include a Host/:authority header, or a request that requests a domain that does not match another virtual service.\nThe each domain specified for a virtualservice must be unique across the set of all virtual services provided to Gloo.\nFor many use cases, it may be sufficient to let all routes live on a single virtual service. In thise scenario, Gloo will use the same set of route rules to for requests, regardless of their Host or :authority header.\nRoute rules consist of a matcher, which specifies the kind of function calls to match (requests and events, are currently supported), and the name of the destination (or destinations, for load balancing) to route them to.\nA simple virtual service with a single route might look like this:\nname: my-app routes: - request_matcher: path_prefix: / single_destination: upstream: name: my-upstream  Note that domains is empty (not specified). That means this virtual service will act as the default virtual service, matching all domains.\n\nRoutes Routes are the primary building block of the virtual service. A route contains a single matcher and one of: a single destination, or a list of weighted destinations.\nIn short, a route is essentially a rule which tells Gloo: if the request matches this matcher, then route it to this destination.\nBecause multiple matchers can match a single request, the order of routes in the virtual service matters. Gloo will select the first route which matches the request when making routing decisions. It is therefore important to place fallback routes (e.g. matching any request for path / with a custom 404 page) towards the bottom of the route list.\n\nMatchers Matchers currently support two types of requests:\n Request Matchers match on properties of HTTP requests. This includes the request path (:path header in HTTP 2.0), method (:method in HTTP 2.0) headers (their keys and optionally their values), and query parameters.\n Event Matchers match properties of HTTP events, as per the CloudEvents specification. Note: the CloudEvents spec is in version 0.1 and likely to be changed in the future. The only property Event Matcher currently matches on is the event-type of an event (specified by the x-event-type request header).\n  \nDestinations Destinations specify where to route a request once a matching route has been selected. A route can point to a single destination, or it can split traffic for that route among a series of weighted destinations.\nA destination can be either an upstream destination or a function destination.\nUpstream Destinations are analogous to Envoy clusters. Requests routed to upstream destinations will be routed to a server which is expected to handle the request once it has been admitted (and possibly transformed) by Gloo.\nFunction Destinations allow requests to be routed directly to functions that live on various upstreams. A function can be a serverless function call (e.g. Lambda, Google Cloud Function, OpenFaaS function, etc.), an API call on a service (e.g. a REST API call, OpenAPI operation, XML/SOAP request etc.), or publishing to a message queue (e.g. NATS, AMQP, etc.). Function-level routing is enabled in Envoy by Gloo\u0026rsquo;s function-level filters. Gloo supports the addition of new upstream types as well as new function types through our plugin interface.\n\nUpstreams Upstreams define destinations for routes. Upstreams tell Gloo what to route to and how to route to them. Gloo determines how to handle routing for the upstream based on its spec field. Upstreams have a type-specific spec field which must be used to provide routing information to Gloo.\nThe most basic upstream type is the static upstream type, which tells Gloo a list of static hosts or dns names logically grouped together for an upstream. More sophisticated upstream types include the kubernetes upstream and the AWS Lambda upstream.\nLet\u0026rsquo;s walk through an example of a kubernetes upstream in order to understand how this works.\nGloo reads in a configuration that looks like the following:\n--- metadata: labels: app: redis discovered_by: kubernetesplugin name: default-redis-6379 namespace: gloo-system resourceVersion: \u0026quot;7010\u0026quot; status: reportedBy: gloo state: Accepted upstreamSpec: kube: selector: gloo: redis serviceName: redis serviceNamespace: gloo-system servicePort: 6379   name tells Gloo what the identifier for this upstream will be (for routes that point to it). type: kubernetes tells Gloo that the kubernetes plugin knows how to route to this upstream spec: ... tells the kubernetes plugin the service name and namespace, which is used by Gloo for routing\n  \nFunctions Some upstream types support functions. For example, we can add some HTTP functions to this upstream, and Gloo will be able to route to those functions, providing request transformation to format incoming requests to the parameters expected by the upstream service.\nWe can now route to the function in our virtual service:\nAn example of a virtual service with a route to this upstream:\nmetadata: name: default namespace: default resourceVersion: \u0026quot;7306\u0026quot; status: reportedBy: gateway state: Accepted subresourceStatuses: '*v1.Proxy gloo-system gateway-proxy': {} virtualHost: domains: - '*' name: default.default routes: - matcher: prefix: / routeAction: single: upstream: name: gloo-system-redis-6379 namespace: gloo-system routePlugins: prefixRewrite: {}  Note that it is necessary to specify parameters for this function invocation. Some function destinations require extensions to be specified on the route they belong to. Documentation for each plugin can be found in the Plugins section.\n\nSecrets Certain plugins such as the AWS Lambda Plugin require the use of secrets for authentication, configuration of SSL Certificates, and other data that should not be stored in plaintext configuration.\nGloo runs an independent (goroutine) controller to monitor secrets. Secrets are stored in their own secret storage layer. Gloo can monitor secrets stored in the following secret storage services:\n Kubernetes Secrets Hashicorp Vault Plaintext files (recommended only for testing)  Secrets must adhere to a structure, specified by the plugin that requires them.\n"
},
{
	"uri": "https://gloo.solo.io/0.7/dev/contributing/",
	"title": "Contributor Guide",
	"tags": [],
	"description": "",
	"content": " Excited about Gloo and want to help make it better?\nAt Solo we strive to make the world of microservices, serverless and service mesh available to everyone. If you want to help but don\u0026rsquo;t know where to start, let us know, and we\u0026rsquo;ll find something for you.\nIf you haven\u0026rsquo;t already, make sure you sign up for the Solo Slack.\nHere are some of the ways you can contribute:\n Filing issues Improving the documentation Small bug fixes Big pull requests Code review guidelines  Filing issues If you encounter a bug, please file an issue on GitHub. If an issue you have is already reported, please add additional information or add a 👍 reaction to indicate your agreement.\nImproving the documentation Improving the documentation, adding examples or use cases can be the easiest way to contribute to Gloo. If you see a piece of content that can be better, open a PR with an improvement, it doesn\u0026rsquo;t matter how small!\nSmall bug fixes If your bug fix is small (around 20 lines of code) just open a pull request. We will try to merge it as soon as possible, just make sure that you include a test that verifies the bug you are fixing.\nBig PRs This includes:\n Big bug fixes New features  For significant changes to the repository, it’s important to settle on a design before starting on the implementation. Reaching out to us early will help minimize the amount of possible wasted effort and will ensure that major improvements are given enough attention.\n Open an issue. Open an issue about your bug in this repo. Message us on Slack. Reach out to us to discuss your proposed changes. Agree on implementation plan. Write a plan for how this feature or bug fix should be implemented. Should this be one pull request or multiple incremental improvements? Who is going to do each part? Submit a work-in-progress PR It\u0026rsquo;s important to get feedback as early as possible to ensure that any big improvements end up being merged. Submit a pull request and label it wip to start getting feedback. Review. At least one Solo team member should sign off on the change before it’s merged. Look at the “code review” section below to learn about what we\u0026rsquo;re looking for. A Solo team member will merge and release!  Code review guidelines It’s important that every piece of code in Gloo is reviewed by at least one Solo team member familiar with that codebase.\n CI check A Solo team member needs to kick off the CI process by commenting /test on your PR. Testing Comments  "
},
{
	"uri": "https://gloo.solo.io/0.8/dev/contributing/",
	"title": "Contributor Guide",
	"tags": [],
	"description": "",
	"content": " Excited about Gloo and want to help make it better?\nAt Solo we strive to make the world of microservices, serverless and service mesh available to everyone. If you want to help but don\u0026rsquo;t know where to start, let us know, and we\u0026rsquo;ll find something for you.\nIf you haven\u0026rsquo;t already, make sure you sign up for the Solo Slack.\nHere are some of the ways you can contribute:\n Filing issues Improving the documentation Small bug fixes Big pull requests Code review guidelines  Filing issues If you encounter a bug, please file an issue on GitHub. If an issue you have is already reported, please add additional information or add a 👍 reaction to indicate your agreement.\nImproving the documentation Improving the documentation, adding examples or use cases can be the easiest way to contribute to Gloo. If you see a piece of content that can be better, open a PR with an improvement, it doesn\u0026rsquo;t matter how small!\nSmall bug fixes If your bug fix is small (around 20 lines of code) just open a pull request. We will try to merge it as soon as possible, just make sure that you include a test that verifies the bug you are fixing.\nBig PRs This includes:\n Big bug fixes New features  For significant changes to the repository, it’s important to settle on a design before starting on the implementation. Reaching out to us early will help minimize the amount of possible wasted effort and will ensure that major improvements are given enough attention.\n Open an issue. Open an issue about your bug in this repo. Message us on Slack. Reach out to us to discuss your proposed changes. Agree on implementation plan. Write a plan for how this feature or bug fix should be implemented. Should this be one pull request or multiple incremental improvements? Who is going to do each part? Submit a work-in-progress PR It\u0026rsquo;s important to get feedback as early as possible to ensure that any big improvements end up being merged. Submit a pull request and label it wip to start getting feedback. Review. At least one Solo team member should sign off on the change before it’s merged. Look at the “code review” section below to learn about what we\u0026rsquo;re looking for. A Solo team member will merge and release!  Code review guidelines It’s important that every piece of code in Gloo is reviewed by at least one Solo team member familiar with that codebase.\n CI check A Solo team member needs to kick off the CI process by commenting /test on your PR. Testing Comments  "
},
{
	"uri": "https://gloo.solo.io/0.7/operator_guide/declarative_infrastructure_and_gitops/",
	"title": "Declarative Infrastructure and GitOps",
	"tags": [],
	"description": "",
	"content": " Kubernetes was built to support declarative configuration management. With Kubernetes, you can describe the desired state of your application through a set of configuration files, and simply run kubectl apply -f .... Kubernetes abstracts away the complexity of computing a diff and redeploying pods, services, or other objects that have changed, while making it easy to reason about the end state of the system after a configuration change.\nGitOps Configuration changes inherently create risk, in that the new configuration may cause a disruption in a running application. For enterprises, the risk of applications breaking can represent a significant financial, reputational, or even existential threat. Operators must be able to manage this configuration safely.\nA common approach for managing this risk is to store all of the configuration for an environment (i.e. production, staging, or dev) in a version control system like Git, a practice that is sometimes referred to as GitOps. In this methodology, the Git repository contains the source of truth for what is deployed to a cluster. Organizations can create processes for submitting changes (pull requests), for managing and approving change requests (code reviews), and for kicking off deployment pipelines when changes are merged in (integrating with a CI/CD system).\nFor example, in a large enterprise, a team of operators may be responsible for managing the current state of production, for which the source of truth is a Git repository containing a set of yaml configurations. In order to push changes to production, the following steps must occur:\n Developers build, test, and release new versions of a service and publish containers to the enterprise\u0026rsquo;s docker registry. Developers or operators request an upgrade to the new version by opening a pull request and updating the image version in the yaml configuration. A pre-approval CI process runs to validate the change, attempting to deploy the updated configuration to a sandbox environment. An operator reviews the change. When the change has passed checks and been approved, it merges in during an approved maintenance window. When the change is merged in, the next phase of the deployment pipeline picks up the change and automatically deploys it to production. A set of acceptance tests are run (by developers, operators, and/or automated systems) against prod to test the newly deployed configuration. If a problem is detected, a pull request can be quickly opened, tested, and reviewed to revert the configuration change.  Using GitOps internally at Solo At Solo, we use GitOps to manage the state of our development and production environments, by integrating with GitHub and Google Cloud Build. For example, after a new version of Gloo Enterprise is released, we want to deploy it our dev instance, which is hosted on a GKE cluster. The developer responsible for the upgrade opens a pull request to the repo containing the dev deployment state, updating the configuration to the new release. When this pull request is approved and merged in to the master branch, a build trigger runs kubectl to apply the new configuration to the cluster. After this configuration is applied, a series of tests are run against the cluster, and the team is notified via Slack about the updates. This is part of our larger release and deployment pipeline we use to test new versions of our product.\n"
},
{
	"uri": "https://gloo.solo.io/0.8/operator_guide/declarative_infrastructure_and_gitops/",
	"title": "Declarative Infrastructure and GitOps",
	"tags": [],
	"description": "",
	"content": " Kubernetes was built to support declarative configuration management. With Kubernetes, you can describe the desired state of your application through a set of configuration files, and simply run kubectl apply -f .... Kubernetes abstracts away the complexity of computing a diff and redeploying pods, services, or other objects that have changed, while making it easy to reason about the end state of the system after a configuration change.\nGitOps Configuration changes inherently create risk, in that the new configuration may cause a disruption in a running application. For enterprises, the risk of applications breaking can represent a significant financial, reputational, or even existential threat. Operators must be able to manage this configuration safely.\nA common approach for managing this risk is to store all of the configuration for an environment (i.e. production, staging, or dev) in a version control system like Git, a practice that is sometimes referred to as GitOps. In this methodology, the Git repository contains the source of truth for what is deployed to a cluster. Organizations can create processes for submitting changes (pull requests), for managing and approving change requests (code reviews), and for kicking off deployment pipelines when changes are merged in (integrating with a CI/CD system).\nFor example, in a large enterprise, a team of operators may be responsible for managing the current state of production, for which the source of truth is a Git repository containing a set of yaml configurations. In order to push changes to production, the following steps must occur:\n Developers build, test, and release new versions of a service and publish containers to the enterprise\u0026rsquo;s docker registry. Developers or operators request an upgrade to the new version by opening a pull request and updating the image version in the yaml configuration. A pre-approval CI process runs to validate the change, attempting to deploy the updated configuration to a sandbox environment. An operator reviews the change. When the change has passed checks and been approved, it merges in during an approved maintenance window. When the change is merged in, the next phase of the deployment pipeline picks up the change and automatically deploys it to production. A set of acceptance tests are run (by developers, operators, and/or automated systems) against prod to test the newly deployed configuration. If a problem is detected, a pull request can be quickly opened, tested, and reviewed to revert the configuration change.  Using GitOps internally at Solo At Solo, we use GitOps to manage the state of our development and production environments, by integrating with GitHub and Google Cloud Build. For example, after a new version of Gloo Enterprise is released, we want to deploy it our dev instance, which is hosted on a GKE cluster. The developer responsible for the upgrade opens a pull request to the repo containing the dev deployment state, updating the configuration to the new release. When this pull request is approved and merged in to the master branch, a build trigger runs kubectl to apply the new configuration to the cluster. After this configuration is applied, a series of tests are run against the cluster, and the team is notified via Slack about the updates. This is part of our larger release and deployment pipeline we use to test new versions of our product.\n"
},
{
	"uri": "https://gloo.solo.io/0.7/user_guides/function_routing/",
	"title": "Function Routing",
	"tags": [],
	"description": "",
	"content": " Function Routing Gloo builds on top of Envoy proxy by giving it the ability to understand functions belonging to upstream clusters. Envoy (and most other gateways) are great at routing to backend clusters/services, but they don\u0026rsquo;t know what functions (REST, gRPC, SOAP, etc) are exposed at each of those clusters/services. Gloo can dynamically discover and understand the details of a Swagger or gRPC reflection, which can help make routing easier. In this tutorial, we\u0026rsquo;ll take a look at Gloo\u0026rsquo;s function routing and transformation capabilities.\nWhat you\u0026rsquo;ll need If you haven\u0026rsquo;t already deployed Gloo and the example swagger service on kubernetes, go back to the first tutorial\nNow that we\u0026rsquo;ve seen the traditional routing functionality of Gloo (i.e. API-to-service), let\u0026rsquo;s try doing some function routing.\nLet\u0026rsquo;s take a look at the upstream that was created for our petstore service:\n glooctl get upstream default-petstore-8080 -o yaml ... serviceSpec: rest: swaggerInfo: url: http://petstore.default.svc.cluster.local:8080/swagger.json transformations: addPet: body: text: '{\u0026quot;id\u0026quot;: {{ default(id, \u0026quot;\u0026quot;) }},\u0026quot;name\u0026quot;: \u0026quot;{{ default(name, \u0026quot;\u0026quot;)}}\u0026quot;,\u0026quot;tag\u0026quot;: \u0026quot;{{ default(tag, \u0026quot;\u0026quot;)}}\u0026quot;}' headers: :method: text: POST :path: text: /api/pets content-type: text: application/json deletePet: headers: :method: text: DELETE :path: text: /api/pets/{{ default(id, \u0026quot;\u0026quot;) }} content-type: text: application/json findPetById: body: {} headers: :method: text: GET :path: text: /api/pets/{{ default(id, \u0026quot;\u0026quot;) }} content-length: text: \u0026quot;0\u0026quot; content-type: {} transfer-encoding: {} findPets: body: {} headers: :method: text: GET :path: text: /api/pets?tags={{default(tags, \u0026quot;\u0026quot;)}}\u0026amp;limit={{default(limit, \u0026quot;\u0026quot;)}} content-length: text: \u0026quot;0\u0026quot; content-type: {} transfer-encoding: {} ...  We can see there are functions on our default-petstore-8080 upstream. These functions were populated automatically by the discovery pod. You can see the function discovery service in action by running kubectl logs -l gloo=discovery\nThe function spec you see on the functions listed above belongs to the transformation plugin. This powerful plugin configures Gloo\u0026rsquo;s request/response transformation Envoy filter to perform transform requests to the structure expected by our petstore app.\nIn a nutshell, this plugin takes Inja templates for HTTP body, headers, and path as its parameters (documented in the plugin spec and transforms incoming requests from those templates. Parameters for these templates can come from the request body (if it\u0026rsquo;s JSON), or they can come from parameters specified in the extensions on a route.\nLet\u0026rsquo;s see how this plugin works by creating some routes to these functions in the next section.\n\nSteps  Start by creating the route with glooctl:\nglooctl add route \\ --path-exact /petstore/findPet \\ --dest-name default-petstore-8080 \\ --rest-function-name findPetById  Notice that, unlike the previous tutorial, we\u0026rsquo;re passing an extra argument to glooctl: --rest-function-name findPetById.\nLet\u0026rsquo;s go ahead and test the route using curl:\nexport GATEWAY_URL=$(glooctl proxy url) curl ${GATEWAY_URL}/petstore/findPet [{\u0026quot;id\u0026quot;:1,\u0026quot;name\u0026quot;:\u0026quot;Dog\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;available\u0026quot;},{\u0026quot;id\u0026quot;:2,\u0026quot;name\u0026quot;:\u0026quot;Cat\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;pending\u0026quot;}]  Looking again at the function findPetById, you\u0026rsquo;ll notice the template wants a variable called id:\n - name: findPetById spec: body: \u0026quot;\u0026quot; headers: :method: GET path: /api/pets/{{id}}  Try the request again, but now add a JSON body which includes the id parameter:\ncurl ${GATEWAY_URL}/petstore/findPet -d '{\u0026quot;id\u0026quot;: 1}' {\u0026quot;id\u0026quot;:1,\u0026quot;name\u0026quot;:\u0026quot;Dog\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;available\u0026quot;} curl ${GATEWAY_URL}/petstore/findPet -d '{\u0026quot;id\u0026quot;: 2}' {\u0026quot;id\u0026quot;:2,\u0026quot;name\u0026quot;:\u0026quot;Cat\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;pending\u0026quot;}  Great! We just called our first function through Gloo.\n Parameters can also come from headers. Let\u0026rsquo;s tell Gloo to look for id in a header.\nLet\u0026rsquo;s take a look at the route we created:\nglooctl get virtualservice -o yaml --- metadata: name: default namespace: gloo-system resourceVersion: \u0026quot;33083\u0026quot; status: reportedBy: gateway state: Accepted subresourceStatuses: '*v1.Proxy gloo-system gateway-proxy': reportedBy: gloo state: Accepted virtualHost: domains: - '*' name: gloo-system.default routes: - matcher: exact: /petstore/findPet routeAction: single: destinationSpec: rest: functionName: findPetById parameters: {} upstream: name: default-petstore-8080 namespace: gloo-system  We can tell Gloo to grab the template parameters from the request with a flag called rest-parameters like this:\nglooctl add route \\ --path-prefix /petstore/findWithId/ \\ --dest-name default-petstore-8080 \\ --rest-function-name findPetById \\ --rest-parameters ':path=/petstore/findWithId/{id}'  Try curl again, this time with the new header:\ncurl ${GATEWAY_URL}/petstore/findWithId/1 {\u0026quot;id\u0026quot;:1,\u0026quot;name\u0026quot;:\u0026quot;Dog\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;available\u0026quot;}  You may be asking \u0026ldquo;why are you calling that a header, it\u0026rsquo;s not a header\u0026rdquo;? We\u0026rsquo;re actually calling the service with a path parameter, but in HTTP2 a header called :path is used to pass the path information around. At the moment, since Envoy has built everything internally around HTTP2, we can use this :path header to pull template parameters. We could have used another header like x-gloo to pass in and then create our rest-parameters with the x-gloo header and accomplish the same thing. We\u0026rsquo;ll leave that as an exercise to the reader.\n  Tutorials for more advanced use-cases are coming soon. In the meantime, please see our plugin documentation for a list of available plugins and their configuration options.\n"
},
{
	"uri": "https://gloo.solo.io/0.8/user_guides/function_routing/",
	"title": "Function Routing",
	"tags": [],
	"description": "",
	"content": " Function Routing Gloo builds on top of Envoy proxy by giving it the ability to understand functions belonging to upstream clusters. Envoy (and most other gateways) are great at routing to backend clusters/services, but they don\u0026rsquo;t know what functions (REST, gRPC, SOAP, etc) are exposed at each of those clusters/services. Gloo can dynamically discover and understand the details of a Swagger or gRPC reflection, which can help make routing easier. In this tutorial, we\u0026rsquo;ll take a look at Gloo\u0026rsquo;s function routing and transformation capabilities.\nWhat you\u0026rsquo;ll need If you haven\u0026rsquo;t already deployed Gloo and the example swagger service on kubernetes, go back to the first tutorial\nNow that we\u0026rsquo;ve seen the traditional routing functionality of Gloo (i.e. API-to-service), let\u0026rsquo;s try doing some function routing.\nLet\u0026rsquo;s take a look at the upstream that was created for our petstore service:\n glooctl get upstream default-petstore-8080 -o yaml ... serviceSpec: rest: swaggerInfo: url: http://petstore.default.svc.cluster.local:8080/swagger.json transformations: addPet: body: text: '{\u0026quot;id\u0026quot;: {{ default(id, \u0026quot;\u0026quot;) }},\u0026quot;name\u0026quot;: \u0026quot;{{ default(name, \u0026quot;\u0026quot;)}}\u0026quot;,\u0026quot;tag\u0026quot;: \u0026quot;{{ default(tag, \u0026quot;\u0026quot;)}}\u0026quot;}' headers: :method: text: POST :path: text: /api/pets content-type: text: application/json deletePet: headers: :method: text: DELETE :path: text: /api/pets/{{ default(id, \u0026quot;\u0026quot;) }} content-type: text: application/json findPetById: body: {} headers: :method: text: GET :path: text: /api/pets/{{ default(id, \u0026quot;\u0026quot;) }} content-length: text: \u0026quot;0\u0026quot; content-type: {} transfer-encoding: {} findPets: body: {} headers: :method: text: GET :path: text: /api/pets?tags={{default(tags, \u0026quot;\u0026quot;)}}\u0026amp;limit={{default(limit, \u0026quot;\u0026quot;)}} content-length: text: \u0026quot;0\u0026quot; content-type: {} transfer-encoding: {} ...  We can see there are functions on our default-petstore-8080 upstream. These functions were populated automatically by the discovery pod. You can see the function discovery service in action by running kubectl logs -l gloo=discovery\nThe function spec you see on the functions listed above belongs to the transformation plugin. This powerful plugin configures Gloo\u0026rsquo;s request/response transformation Envoy filter to perform transform requests to the structure expected by our petstore app.\nIn a nutshell, this plugin takes Inja templates for HTTP body, headers, and path as its parameters (documented in the plugin spec and transforms incoming requests from those templates. Parameters for these templates can come from the request body (if it\u0026rsquo;s JSON), or they can come from parameters specified in the extensions on a route.\nLet\u0026rsquo;s see how this plugin works by creating some routes to these functions in the next section.\n\nSteps  Start by creating the route with glooctl:\nglooctl add route \\ --path-exact /petstore/findPet \\ --dest-name default-petstore-8080 \\ --rest-function-name findPetById  Notice that, unlike the previous tutorial, we\u0026rsquo;re passing an extra argument to glooctl: --rest-function-name findPetById.\nLet\u0026rsquo;s go ahead and test the route using curl:\nexport GATEWAY_URL=$(glooctl proxy url) curl ${GATEWAY_URL}/petstore/findPet [{\u0026quot;id\u0026quot;:1,\u0026quot;name\u0026quot;:\u0026quot;Dog\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;available\u0026quot;},{\u0026quot;id\u0026quot;:2,\u0026quot;name\u0026quot;:\u0026quot;Cat\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;pending\u0026quot;}]  Looking again at the function findPetById, you\u0026rsquo;ll notice the template wants a variable called id:\n - name: findPetById spec: body: \u0026quot;\u0026quot; headers: :method: GET path: /api/pets/{{id}}  Try the request again, but now add a JSON body which includes the id parameter:\ncurl ${GATEWAY_URL}/petstore/findPet -d '{\u0026quot;id\u0026quot;: 1}' {\u0026quot;id\u0026quot;:1,\u0026quot;name\u0026quot;:\u0026quot;Dog\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;available\u0026quot;} curl ${GATEWAY_URL}/petstore/findPet -d '{\u0026quot;id\u0026quot;: 2}' {\u0026quot;id\u0026quot;:2,\u0026quot;name\u0026quot;:\u0026quot;Cat\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;pending\u0026quot;}  Great! We just called our first function through Gloo.\n Parameters can also come from headers. Let\u0026rsquo;s tell Gloo to look for id in a header.\nLet\u0026rsquo;s take a look at the route we created:\nglooctl get virtualservice -o yaml --- metadata: name: default namespace: gloo-system resourceVersion: \u0026quot;33083\u0026quot; status: reportedBy: gateway state: Accepted subresourceStatuses: '*v1.Proxy gloo-system gateway-proxy': reportedBy: gloo state: Accepted virtualHost: domains: - '*' name: gloo-system.default routes: - matcher: exact: /petstore/findPet routeAction: single: destinationSpec: rest: functionName: findPetById parameters: {} upstream: name: default-petstore-8080 namespace: gloo-system  We can tell Gloo to grab the template parameters from the request with a flag called rest-parameters like this:\nglooctl add route \\ --path-prefix /petstore/findWithId/ \\ --dest-name default-petstore-8080 \\ --rest-function-name findPetById \\ --rest-parameters ':path=/petstore/findWithId/{id}'  Try curl again, this time with the new header:\ncurl ${GATEWAY_URL}/petstore/findWithId/1 {\u0026quot;id\u0026quot;:1,\u0026quot;name\u0026quot;:\u0026quot;Dog\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;available\u0026quot;}  You may be asking \u0026ldquo;why are you calling that a header, it\u0026rsquo;s not a header\u0026rdquo;? We\u0026rsquo;re actually calling the service with a path parameter, but in HTTP2 a header called :path is used to pass the path information around. At the moment, since Envoy has built everything internally around HTTP2, we can use this :path header to pull template parameters. We could have used another header like x-gloo to pass in and then create our rest-parameters with the x-gloo header and accomplish the same thing. We\u0026rsquo;ll leave that as an exercise to the reader.\n  Tutorials for more advanced use-cases are coming soon. In the meantime, please see our plugin documentation for a list of available plugins and their configuration options.\n"
},
{
	"uri": "https://gloo.solo.io/0.7/installation/gke/",
	"title": "Google Kubernetes Engine (GKE)",
	"tags": [],
	"description": "",
	"content": " In this document we will review how to install Gloo on Google Kubernetes Engine.\nConfigure kubectl Configure kubectl to use with your cluster:\ngcloud container clusters get-credentials CLUSTER-NAME --zone ZONE --project PROJECRT_ID  Validate that kubectl was successfully configured with:\nkubectl cluster-info  Install Gloo Use kubectl to install gloo using it\u0026rsquo;s released kubernetes manifest:\nkubectl apply -f https://github.com/solo-io/gloo/releases/download/v0.6.19/gloo-gateway.yaml  In this example we are installing version 0.6.19. You can install any other released version.\nThe installation takes a few minutes to fully complete.\nAccess from the Internet Accessing your Gloo virtual services from the internet is easy with Google Kubernetes Engine.\nRequests for Gloo\u0026rsquo;s virtual services are routed via the gateway-proxy service. As the service type is LoadBalancer, Google will allocate a global IP address for it, and load balance requests on that IP address across the instances of the service.\nTo find the address of your Gloo, go to the Services tab of your GKE, add name: gateway-proxy to the search filters. The allocated address will be under the Endpoints column.\nFor Example:\nNOTE: You might not see see the address in the endpoint column immediately, as provisioning the cloud load balancer can take around 10 minutes. Try waiting a few minutes, and clicking the REFRESH link on the top of the page.\nYou can now use the endpoints as your public address for requests.\nFinal Notes In addition to Gloo, usually you will also want to:\n Use a tool like external-dns To setup DNS Record for Gloo. Use a tool like cert-manager to provision SSL certificates to use with Gloo\u0026rsquo;s VirtualService CRD.  "
},
{
	"uri": "https://gloo.solo.io/0.8/installation/gke/",
	"title": "Google Kubernetes Engine (GKE)",
	"tags": [],
	"description": "",
	"content": " In this document we will review how to install Gloo on Google Kubernetes Engine.\nConfigure kubectl Configure kubectl to use with your cluster:\ngcloud container clusters get-credentials CLUSTER-NAME --zone ZONE --project PROJECRT_ID  Validate that kubectl was successfully configured with:\nkubectl cluster-info  Install Gloo Use kubectl to install gloo using it\u0026rsquo;s released kubernetes manifest:\nkubectl apply -f https://github.com/solo-io/gloo/releases/download/v0.6.19/gloo-gateway.yaml  In this example we are installing version 0.6.19. You can install any other released version.\nThe installation takes a few minutes to fully complete.\nAccess from the Internet Accessing your Gloo virtual services from the internet is easy with Google Kubernetes Engine.\nRequests for Gloo\u0026rsquo;s virtual services are routed via the gateway-proxy service. As the service type is LoadBalancer, Google will allocate a global IP address for it, and load balance requests on that IP address across the instances of the service.\nTo find the address of your Gloo, go to the Services tab of your GKE, add name: gateway-proxy to the search filters. The allocated address will be under the Endpoints column.\nFor Example:\nNOTE: You might not see see the address in the endpoint column immediately, as provisioning the cloud load balancer can take around 10 minutes. Try waiting a few minutes, and clicking the REFRESH link on the top of the page.\nYou can now use the endpoints as your public address for requests.\nFinal Notes In addition to Gloo, usually you will also want to:\n Use a tool like external-dns To setup DNS Record for Gloo. Use a tool like cert-manager to provision SSL certificates to use with Gloo\u0026rsquo;s VirtualService CRD.  "
},
{
	"uri": "https://gloo.solo.io/0.7/installation/",
	"title": "Installing Gloo",
	"tags": [],
	"description": "",
	"content": " 1. Install Glooctl If this is your first time running Gloo, you’ll need to download the command-line interface (CLI) onto your local machine. You’ll use this CLI to interact with Gloo, including installing it onto your Kubernetes cluster.\nTo install the CLI, run:\ncurl -sL https://run.solo.io/gloo/install | sh\nAlternatively, you can download the CLI directly via the github releases page.\nNext, add Gloo to your path with:\nexport PATH=$HOME/.gloo/bin:$PATH\nVerify the CLI is installed and running correctly with:\nglooctl --version\n2. Choosing a deployment option There currently exist several options for deploying Gloo depending on your use case and deployment platform.\n Gateway: Gloo\u0026rsquo;s full feature set is available via its v1/Gateway API. The Gateway API is modeled on Envoy\u0026rsquo;s own API with the use of opinionated defaults to make complex configurations possible, while maintaining simplicity where desired.\n Ingress: Gloo will support configuration the Kubernetes Ingress resource, acting as a Kubernetes Ingress Controller. Note that ingress objects must have the annotation \u0026quot;kubernetes.io/ingress.class\u0026quot;: \u0026quot;gloo\u0026quot; to be processed by the Gloo Ingress.\n Knative: Gloo will integrate automatically with Knative as a cluster-level ingress for Knative-Serving. Gloo can be used in this way as a lightweight replacement for Istio when using Knative-Serving.\n  \n2a. Install the Gloo Gateway to your Kubernetes Cluster using Glooctl Once your Kubernetes cluster is up and running, run the following command to deploy the Gloo Gateway to the gloo-system namespace:\nglooctl install gateway  Check that the Gloo pods and services have been created:\nkubectl get all -n gloo-system NAME READY STATUS RESTARTS AGE pod/discovery-f7548d984-slddk 1/1 Running 0 5m pod/gateway-5689fd59d7-wsg7f 1/1 Running 0 5m pod/gateway-proxy-9d79d48cd-wg8b8 1/1 Running 0 5m pod/gloo-5b7b748dbf-jdsvg 1/1 Running 0 5m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/gateway-proxy LoadBalancer 10.97.232.107 \u0026lt;pending\u0026gt; 8080:31800/TCP 5m service/gloo ClusterIP 10.100.64.166 \u0026lt;none\u0026gt; 9977/TCP 5m NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.apps/discovery 1 1 1 1 5m deployment.apps/gateway 1 1 1 1 5m deployment.apps/gateway-proxy 1 1 1 1 5m deployment.apps/gloo 1 1 1 1 5m NAME DESIRED CURRENT READY AGE replicaset.apps/discovery-f7548d984 1 1 1 5m replicaset.apps/gateway-5689fd59d7 1 1 1 5m replicaset.apps/gateway-proxy-9d79d48cd 1 1 1 5m replicaset.apps/gloo-5b7b748dbf 1 1 1 5m  See Getting Started on Kubernetes to get started using the Gloo Gateway.\n\n2b. Install the Gloo Ingress Controller to your Kubernetes Cluster using Glooctl Once your Kubernetes cluster is up and running, run the following command to deploy the Gloo Ingress to the gloo-system namespace:\nglooctl install ingress  Check that the Gloo pods and services have been created:\nkubectl get all -n gloo-system NAME READY STATUS RESTARTS AGE pod/discovery-f7548d984-lfhsz 1/1 Running 0 3s pod/gloo-5b7b748dbf-vtjvx 1/1 Running 0 4s pod/ingress-9c59ffc64-ndsj9 1/1 Running 0 4s pod/ingress-proxy-7b676c5b7-tqnlq 1/1 Running 0 4s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/gloo ClusterIP 10.101.127.201 \u0026lt;none\u0026gt; 9977/TCP 4s service/ingress-proxy LoadBalancer 10.106.91.246 \u0026lt;pending\u0026gt; 80:30999/TCP,443:31628/TCP 4s NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.apps/discovery 1 1 1 1 4s deployment.apps/gloo 1 1 1 1 4s deployment.apps/ingress 1 1 1 1 4s deployment.apps/ingress-proxy 1 1 1 1 4s NAME DESIRED CURRENT READY AGE replicaset.apps/discovery-f7548d984 1 1 1 4s replicaset.apps/gloo-5b7b748dbf 1 1 1 4s replicaset.apps/ingress-9c59ffc64 1 1 1 4s replicaset.apps/ingress-proxy-7b676c5b7 1 1 1 4s  See Getting Started with Kubernetes Ingress to get started using the Gloo Ingress Controller.\n\n2c. Install the Gloo Knative Cluster Ingress to your Kubernetes Cluster using Glooctl Once your Kubernetes cluster is up and running, run the following command to deploy Knative-Serving components to the knative-serving namespace and Gloo to the gloo-system namespace:\nglooctl install knative\nCheck that the Gloo and Knative pods and services have been created:\nkubectl get all -n gloo-system NAME READY STATUS RESTARTS AGE pod/clusteringress-proxy-cc5c6db57-2jtgd 1/1 Running 0 13s pod/discovery-f7548d984-lqj6t 1/1 Running 0 13s pod/gloo-5b7b748dbf-g42cg 1/1 Running 0 13s pod/ingress-54fcb854f9-z5bmv 1/1 Running 0 13s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/clusteringress-proxy LoadBalancer 10.106.92.134 \u0026lt;pending\u0026gt; 80:30602/TCP,443:31006/TCP 14s service/gloo ClusterIP 10.111.161.176 \u0026lt;none\u0026gt; 9977/TCP 14s NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.apps/clusteringress-proxy 1 1 1 1 14s deployment.apps/discovery 1 1 1 1 14s deployment.apps/gloo 1 1 1 1 14s deployment.apps/ingress 1 1 1 1 14s NAME DESIRED CURRENT READY AGE replicaset.apps/clusteringress-proxy-cc5c6db57 1 1 1 14s replicaset.apps/discovery-f7548d984 1 1 1 14s replicaset.apps/gloo-5b7b748dbf 1 1 1 14s replicaset.apps/ingress-54fcb854f9 1 1 1 14s  kubectl get all -n knative-serving NAME READY STATUS RESTARTS AGE pod/activator-5c8d977d45-6x9s4 1/1 Running 0 2m pod/autoscaler-5cd4bb6dbc-kwt4q 1/1 Running 0 2m pod/controller-66cd7d99df-c9fnx 1/1 Running 0 30s pod/webhook-6d9568d-q27vv 1/1 Running 0 2m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/activator-service ClusterIP 10.104.212.24 \u0026lt;none\u0026gt; 80/TCP,9090/TCP 2m service/autoscaler ClusterIP 10.98.232.40 \u0026lt;none\u0026gt; 8080/TCP,9090/TCP 2m service/controller ClusterIP 10.102.58.151 \u0026lt;none\u0026gt; 9090/TCP 2m service/webhook ClusterIP 10.106.233.95 \u0026lt;none\u0026gt; 443/TCP 2m NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.apps/activator 1 1 1 1 2m deployment.apps/autoscaler 1 1 1 1 2m deployment.apps/controller 1 1 1 1 2m deployment.apps/webhook 1 1 1 1 2m NAME DESIRED CURRENT READY AGE replicaset.apps/activator-5c8d977d45 1 1 1 2m replicaset.apps/autoscaler-5cd4bb6dbc 1 1 1 2m replicaset.apps/controller-66cd7d99df 1 1 1 2m replicaset.apps/webhook-6d9568d 1 1 1 2m NAME AGE image.caching.internal.knative.dev/fluentd-sidecar 2m image.caching.internal.knative.dev/queue-proxy 2m  See Getting Started with Gloo and Knative to get started using Gloo as your Knative Ingress.\nNext steps Everything should be up and running. If this process does not work, please open an issue. We are happy to answer questions on our diligently staffed Slack channel.\nUninstall To uninstall Gloo and all related components, simply run\nglooctl uninstall  Note that this will also remove Knative-Serving, if it was installed by Glooctl.\n"
},
{
	"uri": "https://gloo.solo.io/0.8/installation/",
	"title": "Installing Gloo",
	"tags": [],
	"description": "",
	"content": " 1. Install Glooctl If this is your first time running Gloo, you’ll need to download the command-line interface (CLI) onto your local machine. You’ll use this CLI to interact with Gloo, including installing it onto your Kubernetes cluster.\nTo install the CLI, run:\ncurl -sL https://run.solo.io/gloo/install | sh\nAlternatively, you can download the CLI directly via the github releases page.\nNext, add Gloo to your path with:\nexport PATH=$HOME/.gloo/bin:$PATH\nVerify the CLI is installed and running correctly with:\nglooctl --version\n2. Choosing a deployment option There currently exist several options for deploying Gloo depending on your use case and deployment platform.\n Gateway: Gloo\u0026rsquo;s full feature set is available via its v1/Gateway API. The Gateway API is modeled on Envoy\u0026rsquo;s own API with the use of opinionated defaults to make complex configurations possible, while maintaining simplicity where desired.\n Ingress: Gloo will support configuration the Kubernetes Ingress resource, acting as a Kubernetes Ingress Controller. Note that ingress objects must have the annotation \u0026quot;kubernetes.io/ingress.class\u0026quot;: \u0026quot;gloo\u0026quot; to be processed by the Gloo Ingress.\n Knative: Gloo will integrate automatically with Knative as a cluster-level ingress for Knative-Serving. Gloo can be used in this way as a lightweight replacement for Istio when using Knative-Serving.\n  \n2a. Install the Gloo Gateway to your Kubernetes Cluster using Glooctl Once your Kubernetes cluster is up and running, run the following command to deploy the Gloo Gateway to the gloo-system namespace:\nglooctl install gateway  Check that the Gloo pods and services have been created:\nkubectl get all -n gloo-system NAME READY STATUS RESTARTS AGE pod/discovery-f7548d984-slddk 1/1 Running 0 5m pod/gateway-5689fd59d7-wsg7f 1/1 Running 0 5m pod/gateway-proxy-9d79d48cd-wg8b8 1/1 Running 0 5m pod/gloo-5b7b748dbf-jdsvg 1/1 Running 0 5m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/gateway-proxy LoadBalancer 10.97.232.107 \u0026lt;pending\u0026gt; 8080:31800/TCP 5m service/gloo ClusterIP 10.100.64.166 \u0026lt;none\u0026gt; 9977/TCP 5m NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.apps/discovery 1 1 1 1 5m deployment.apps/gateway 1 1 1 1 5m deployment.apps/gateway-proxy 1 1 1 1 5m deployment.apps/gloo 1 1 1 1 5m NAME DESIRED CURRENT READY AGE replicaset.apps/discovery-f7548d984 1 1 1 5m replicaset.apps/gateway-5689fd59d7 1 1 1 5m replicaset.apps/gateway-proxy-9d79d48cd 1 1 1 5m replicaset.apps/gloo-5b7b748dbf 1 1 1 5m  See Getting Started on Kubernetes to get started using the Gloo Gateway.\n\n2b. Install the Gloo Ingress Controller to your Kubernetes Cluster using Glooctl Once your Kubernetes cluster is up and running, run the following command to deploy the Gloo Ingress to the gloo-system namespace:\nglooctl install ingress  Check that the Gloo pods and services have been created:\nkubectl get all -n gloo-system NAME READY STATUS RESTARTS AGE pod/discovery-f7548d984-lfhsz 1/1 Running 0 3s pod/gloo-5b7b748dbf-vtjvx 1/1 Running 0 4s pod/ingress-9c59ffc64-ndsj9 1/1 Running 0 4s pod/ingress-proxy-7b676c5b7-tqnlq 1/1 Running 0 4s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/gloo ClusterIP 10.101.127.201 \u0026lt;none\u0026gt; 9977/TCP 4s service/ingress-proxy LoadBalancer 10.106.91.246 \u0026lt;pending\u0026gt; 80:30999/TCP,443:31628/TCP 4s NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.apps/discovery 1 1 1 1 4s deployment.apps/gloo 1 1 1 1 4s deployment.apps/ingress 1 1 1 1 4s deployment.apps/ingress-proxy 1 1 1 1 4s NAME DESIRED CURRENT READY AGE replicaset.apps/discovery-f7548d984 1 1 1 4s replicaset.apps/gloo-5b7b748dbf 1 1 1 4s replicaset.apps/ingress-9c59ffc64 1 1 1 4s replicaset.apps/ingress-proxy-7b676c5b7 1 1 1 4s  See Getting Started with Kubernetes Ingress to get started using the Gloo Ingress Controller.\n\n2c. Install the Gloo Knative Cluster Ingress to your Kubernetes Cluster using Glooctl Once your Kubernetes cluster is up and running, run the following command to deploy Knative-Serving components to the knative-serving namespace and Gloo to the gloo-system namespace:\nglooctl install knative\nCheck that the Gloo and Knative pods and services have been created:\nkubectl get all -n gloo-system NAME READY STATUS RESTARTS AGE pod/clusteringress-proxy-cc5c6db57-2jtgd 1/1 Running 0 13s pod/discovery-f7548d984-lqj6t 1/1 Running 0 13s pod/gloo-5b7b748dbf-g42cg 1/1 Running 0 13s pod/ingress-54fcb854f9-z5bmv 1/1 Running 0 13s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/clusteringress-proxy LoadBalancer 10.106.92.134 \u0026lt;pending\u0026gt; 80:30602/TCP,443:31006/TCP 14s service/gloo ClusterIP 10.111.161.176 \u0026lt;none\u0026gt; 9977/TCP 14s NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.apps/clusteringress-proxy 1 1 1 1 14s deployment.apps/discovery 1 1 1 1 14s deployment.apps/gloo 1 1 1 1 14s deployment.apps/ingress 1 1 1 1 14s NAME DESIRED CURRENT READY AGE replicaset.apps/clusteringress-proxy-cc5c6db57 1 1 1 14s replicaset.apps/discovery-f7548d984 1 1 1 14s replicaset.apps/gloo-5b7b748dbf 1 1 1 14s replicaset.apps/ingress-54fcb854f9 1 1 1 14s  kubectl get all -n knative-serving NAME READY STATUS RESTARTS AGE pod/activator-5c8d977d45-6x9s4 1/1 Running 0 2m pod/autoscaler-5cd4bb6dbc-kwt4q 1/1 Running 0 2m pod/controller-66cd7d99df-c9fnx 1/1 Running 0 30s pod/webhook-6d9568d-q27vv 1/1 Running 0 2m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/activator-service ClusterIP 10.104.212.24 \u0026lt;none\u0026gt; 80/TCP,9090/TCP 2m service/autoscaler ClusterIP 10.98.232.40 \u0026lt;none\u0026gt; 8080/TCP,9090/TCP 2m service/controller ClusterIP 10.102.58.151 \u0026lt;none\u0026gt; 9090/TCP 2m service/webhook ClusterIP 10.106.233.95 \u0026lt;none\u0026gt; 443/TCP 2m NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE deployment.apps/activator 1 1 1 1 2m deployment.apps/autoscaler 1 1 1 1 2m deployment.apps/controller 1 1 1 1 2m deployment.apps/webhook 1 1 1 1 2m NAME DESIRED CURRENT READY AGE replicaset.apps/activator-5c8d977d45 1 1 1 2m replicaset.apps/autoscaler-5cd4bb6dbc 1 1 1 2m replicaset.apps/controller-66cd7d99df 1 1 1 2m replicaset.apps/webhook-6d9568d 1 1 1 2m NAME AGE image.caching.internal.knative.dev/fluentd-sidecar 2m image.caching.internal.knative.dev/queue-proxy 2m  See Getting Started with Gloo and Knative to get started using Gloo as your Knative Ingress.\nNext steps Everything should be up and running. If this process does not work, please open an issue. We are happy to answer questions on our diligently staffed Slack channel.\nUninstall To uninstall Gloo and all related components, simply run\nglooctl uninstall  Note that this will also remove Knative-Serving, if it was installed by Glooctl.\n"
},
{
	"uri": "https://gloo.solo.io/0.7/user_guides/external_api_routing/",
	"title": "External API Routing",
	"tags": [],
	"description": "",
	"content": " External API Routing In this tutorial, we\u0026rsquo;ll take a look at routing to services that live outside of your deployment platform and that have not been configured for automatic discovery. You can consider that these could be existing monoliths or static endpoints that do not lend themselves easily to be discovered. Gloo\u0026rsquo;s power comes from it\u0026rsquo;s ability to live in unpredictable and dynamic environments just fine, but for those use cases where we need to explicitly add upstreams, we can do that following these steps.\nWhat you\u0026rsquo;ll need You\u0026rsquo;ll need to have Gloo installed on Kubernetes and have access to that Kubernetes cluster. Please refer to the Gloo installation for guidance on installing Gloo into Kubernetes.\nYou\u0026rsquo;ll also need access from the Kubernetes cluster to an external API. You can use whichever external API you wish; we\u0026rsquo;ll use an API called JSONPlaceholder which simulates a REST API for basic testing.\nTo route to an external API, we need to first create a Gloo upstream. A quick recap will show that a Gloo upstream is a network entry (think host:port) in the Gloo service catalog (or \u0026ldquo;cluster\u0026rdquo; as Envoy proxy calls it). We\u0026rsquo;ll use glooctl create upstream command to do this:\n glooctl create upstream static jsonplaceholder-80 --static-hosts jsonplaceholder.typicode.com:80 +--------------------+--------+---------+---------------------------------+ | UPSTREAM | TYPE | STATUS | DETAILS | +--------------------+--------+---------+---------------------------------+ | jsonplaceholder-80 | Static | Pending | hosts: | | | | | - | | | | | jsonplaceholder.typicode.com:80 | | | | | | +--------------------+--------+---------+---------------------------------+  In this case, we created a static upstream which means this is not something Gloo dynamically discovered on its own using its powerful upstream and function discovery mechanisms but rather that we added it explicitly. Feel free to explore the other glooctl create upstream options to create additional upstream entries.\nGloo should now know about our jsonplaceholder upstream. To verify run glooctl get upstream -n default and notice the Status column:\n glooctl get upstream -n default glooctl get upstream -n default +--------------------+--------+----------+---------------------------------+ | UPSTREAM | TYPE | STATUS | DETAILS | +--------------------+--------+----------+---------------------------------+ | jsonplaceholder-80 | Static | Accepted | hosts: | | | | | - | | | | | jsonplaceholder.typicode.com:80 | | | | | | +--------------------+--------+----------+---------------------------------+  Note that we explicitly specified the namespace otherwise glooctl would default to the gloo-system namespace.\nLet\u0026rsquo;s add a route like we did in the basic routing tutorial to route incoming traffic from /api/posts to our new jsonplaceholder upstream:\n glooctl add route \\ --dest-name jsonplaceholder-80 \\ --dest-namespace default \\ --path-exact /api/posts \\ --prefix-rewrite /posts creating virtualservice default with default domain * +-----------------+---------+------+---------+---------+--------------------------------+ | VIRTUAL SERVICE | DOMAINS | SSL | STATUS | PLUGINS | ROUTES | +-----------------+---------+------+---------+---------+--------------------------------+ | default | * | none | Pending | | /api/posts -\u0026gt; | | | | | | | jsonplaceholder-80 | +-----------------+---------+------+---------+---------+--------------------------------+  Let\u0026rsquo;s try calling our new API:\n export GATEWAY_URL=$(glooctl proxy url) curl ${GATEWAY_URL}/api/posts  Now we should see output similar to:\n ... { \u0026quot;userId\u0026quot;: 1, \u0026quot;id\u0026quot;: 1, \u0026quot;title\u0026quot;: \u0026quot;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026quot;, \u0026quot;body\u0026quot;: \u0026quot;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026quot; }, { \u0026quot;userId\u0026quot;: 1, \u0026quot;id\u0026quot;: 2, \u0026quot;title\u0026quot;: \u0026quot;qui est esse\u0026quot;, \u0026quot;body\u0026quot;: \u0026quot;est rerum tempore vitae\\nsequi sint nihil reprehenderit dolor beatae ea dolores neque\\nfugiat blanditiis voluptate porro vel nihil molestiae ut reiciendis\\nqui aperiam non debitis possimus qui neque nisi $ ulla\u0026quot; }, { \u0026quot;userId\u0026quot;: 1, \u0026quot;id\u0026quot;: 3, \u0026quot;title\u0026quot;: \u0026quot;ea molestias quasi exercitationem repellat qui ipsa sit aut\u0026quot;, \u0026quot;body\u0026quot;: \u0026quot;et iusto sed quo iure\\nvoluptatem occaecati omnis eligendi aut ad\\nvoluptatem doloribus vel accusantium quis pariatur\\nmolestiae porro eius odio et labore et velit aut\u0026quot; }, { \u0026quot;userId\u0026quot;: 1, \u0026quot;id\u0026quot;: 4, \u0026quot;title\u0026quot;: \u0026quot;eum et est occaecati\u0026quot;, \u0026quot;body\u0026quot;: \u0026quot;ullam et saepe reiciendis voluptatem adipisci\\nsit amet autem assumenda provident rerum culpa\\nquis hic commodi nesciunt rem tenetur doloremque ipsam iure\\nquis sunt voluptatem rerum illo velit\u0026quot; }, { \u0026quot;userId\u0026quot;: 1, \u0026quot;id\u0026quot;: 5, \u0026quot;title\u0026quot;: \u0026quot;nesciunt quas odio\u0026quot;, \u0026quot;body\u0026quot;: \u0026quot;repudiandae veniam quaerat sunt sed\\nalias aut fugiat sit autem sed est\\nvoluptatem omnis possimus esse voluptatibus quis\\nest aut tenetur dolor neque\u0026quot; }, { \u0026quot;userId\u0026quot;: 1, \u0026quot;id\u0026quot;: 6, \u0026quot;title\u0026quot;: \u0026quot;dolorem eum magni eos aperiam quia\u0026quot;, \u0026quot;body\u0026quot;: \u0026quot;ut aspernatur corporis harum nihil quis provident sequi\\nmollitia nobis aliquid molestiae\\nperspiciatis et ea nemo ab reprehenderit accusantium quas\\nvoluptate dolores velit et doloremque molestiae\u0026quot; }, ...  "
},
{
	"uri": "https://gloo.solo.io/0.8/user_guides/external_api_routing/",
	"title": "External API Routing",
	"tags": [],
	"description": "",
	"content": " External API Routing In this tutorial, we\u0026rsquo;ll take a look at routing to services that live outside of your deployment platform and that have not been configured for automatic discovery. You can consider that these could be existing monoliths or static endpoints that do not lend themselves easily to be discovered. Gloo\u0026rsquo;s power comes from it\u0026rsquo;s ability to live in unpredictable and dynamic environments just fine, but for those use cases where we need to explicitly add upstreams, we can do that following these steps.\nWhat you\u0026rsquo;ll need You\u0026rsquo;ll need to have Gloo installed on Kubernetes and have access to that Kubernetes cluster. Please refer to the Gloo installation for guidance on installing Gloo into Kubernetes.\nYou\u0026rsquo;ll also need access from the Kubernetes cluster to an external API. You can use whichever external API you wish; we\u0026rsquo;ll use an API called JSONPlaceholder which simulates a REST API for basic testing.\nTo route to an external API, we need to first create a Gloo upstream. A quick recap will show that a Gloo upstream is a network entry (think host:port) in the Gloo service catalog (or \u0026ldquo;cluster\u0026rdquo; as Envoy proxy calls it). We\u0026rsquo;ll use glooctl create upstream command to do this:\n glooctl create upstream static jsonplaceholder-80 --static-hosts jsonplaceholder.typicode.com:80 +--------------------+--------+---------+---------------------------------+ | UPSTREAM | TYPE | STATUS | DETAILS | +--------------------+--------+---------+---------------------------------+ | jsonplaceholder-80 | Static | Pending | hosts: | | | | | - | | | | | jsonplaceholder.typicode.com:80 | | | | | | +--------------------+--------+---------+---------------------------------+  In this case, we created a static upstream which means this is not something Gloo dynamically discovered on its own using its powerful upstream and function discovery mechanisms but rather that we added it explicitly. Feel free to explore the other glooctl create upstream options to create additional upstream entries.\nGloo should now know about our jsonplaceholder upstream. To verify run glooctl get upstream -n default and notice the Status column:\n glooctl get upstream -n default glooctl get upstream -n default +--------------------+--------+----------+---------------------------------+ | UPSTREAM | TYPE | STATUS | DETAILS | +--------------------+--------+----------+---------------------------------+ | jsonplaceholder-80 | Static | Accepted | hosts: | | | | | - | | | | | jsonplaceholder.typicode.com:80 | | | | | | +--------------------+--------+----------+---------------------------------+  Note that we explicitly specified the namespace otherwise glooctl would default to the gloo-system namespace.\nLet\u0026rsquo;s add a route like we did in the basic routing tutorial to route incoming traffic from /api/posts to our new jsonplaceholder upstream:\n glooctl add route \\ --dest-name jsonplaceholder-80 \\ --dest-namespace default \\ --path-exact /api/posts \\ --prefix-rewrite /posts creating virtualservice default with default domain * +-----------------+---------+------+---------+---------+--------------------------------+ | VIRTUAL SERVICE | DOMAINS | SSL | STATUS | PLUGINS | ROUTES | +-----------------+---------+------+---------+---------+--------------------------------+ | default | * | none | Pending | | /api/posts -\u0026gt; | | | | | | | jsonplaceholder-80 | +-----------------+---------+------+---------+---------+--------------------------------+  Let\u0026rsquo;s try calling our new API:\n export GATEWAY_URL=$(glooctl proxy url) curl ${GATEWAY_URL}/api/posts  Now we should see output similar to:\n ... { \u0026quot;userId\u0026quot;: 1, \u0026quot;id\u0026quot;: 1, \u0026quot;title\u0026quot;: \u0026quot;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026quot;, \u0026quot;body\u0026quot;: \u0026quot;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026quot; }, { \u0026quot;userId\u0026quot;: 1, \u0026quot;id\u0026quot;: 2, \u0026quot;title\u0026quot;: \u0026quot;qui est esse\u0026quot;, \u0026quot;body\u0026quot;: \u0026quot;est rerum tempore vitae\\nsequi sint nihil reprehenderit dolor beatae ea dolores neque\\nfugiat blanditiis voluptate porro vel nihil molestiae ut reiciendis\\nqui aperiam non debitis possimus qui neque nisi $ ulla\u0026quot; }, { \u0026quot;userId\u0026quot;: 1, \u0026quot;id\u0026quot;: 3, \u0026quot;title\u0026quot;: \u0026quot;ea molestias quasi exercitationem repellat qui ipsa sit aut\u0026quot;, \u0026quot;body\u0026quot;: \u0026quot;et iusto sed quo iure\\nvoluptatem occaecati omnis eligendi aut ad\\nvoluptatem doloribus vel accusantium quis pariatur\\nmolestiae porro eius odio et labore et velit aut\u0026quot; }, { \u0026quot;userId\u0026quot;: 1, \u0026quot;id\u0026quot;: 4, \u0026quot;title\u0026quot;: \u0026quot;eum et est occaecati\u0026quot;, \u0026quot;body\u0026quot;: \u0026quot;ullam et saepe reiciendis voluptatem adipisci\\nsit amet autem assumenda provident rerum culpa\\nquis hic commodi nesciunt rem tenetur doloremque ipsam iure\\nquis sunt voluptatem rerum illo velit\u0026quot; }, { \u0026quot;userId\u0026quot;: 1, \u0026quot;id\u0026quot;: 5, \u0026quot;title\u0026quot;: \u0026quot;nesciunt quas odio\u0026quot;, \u0026quot;body\u0026quot;: \u0026quot;repudiandae veniam quaerat sunt sed\\nalias aut fugiat sit autem sed est\\nvoluptatem omnis possimus esse voluptatibus quis\\nest aut tenetur dolor neque\u0026quot; }, { \u0026quot;userId\u0026quot;: 1, \u0026quot;id\u0026quot;: 6, \u0026quot;title\u0026quot;: \u0026quot;dolorem eum magni eos aperiam quia\u0026quot;, \u0026quot;body\u0026quot;: \u0026quot;ut aspernatur corporis harum nihil quis provident sequi\\nmollitia nobis aliquid molestiae\\nperspiciatis et ea nemo ab reprehenderit accusantium quas\\nvoluptate dolores velit et doloremque molestiae\u0026quot; }, ...  "
},
{
	"uri": "https://gloo.solo.io/0.7/operator_guide/gloo_declarative_model/",
	"title": "Gloo as Declarative Infrastructure",
	"tags": [],
	"description": "",
	"content": " At it\u0026rsquo;s core, Gloo is a simple product that adheres to the declarative infrastructure model: - It watches the current state, known as a snapshot, consisting of proxies, secrets, endpoints, upstreams, and artifacts. - It runs an event loop that, when the snapshot changes, reconciles it with the current state and applies any necessary changes.\nGitOps with Gloo Following the GitOps methodology, custom Gloo configuration can be stored in a version control repo, and controlling how that configuration is reviewed, merged, and deployed can help mitigate operational risk. Coming soon, Gloo Enterprise will be shipping with a feature that simplifies the design of a GitOps process. With Gloo Enterprise, when users make changes in the Gloo UI, they will automatically persist in a changeset that is backed by a Git repository. Only when the change is reviewed and merged in, the configuration will be deployed. Users will be able to see the current deployed state, as well as the pending changeset changes, via the Gloo UI. Contact us for more information about this feature.\nSolo Kit, the declarative product generator Gloo was created using Solo Kit, an open source library that simplifies the creation of declarative products. A product can simply define it\u0026rsquo;s custom API objects in Protocol Buffer format, and Solo Kit will automatically generate: - Strongly typed clients for reading and writing those objects (i.e. upstreams or virtualservices). Solo Kit clients are configured with a pluggable storage layer, and support Kubernetes CRDs, Consul, Vault, and many others out of the box. - An event loop that watches a configuration snapshot. Products simply define the object types that make up a snapshot, and the namespaces to watch for config changes. - API Documentation in markdown format.\nThe architecture of solo kit-generated projects has a few advantages: - Most of the code is automatically generated, speeding up development time. - The user interfaces (CLI, enterprise UI) are very simple \u0026ndash; they simply facilitate the editing of stored yaml configuration. - Multiple solo kit products can run as a pipeline, each watching a writing a set of CRDs. For instance, Gloo deploys with another service called Discovery, that automatically detects upstreams and endpoints from Kubernetes, AWS, and elsewhere. When those get written out to the storage layer, Gloo\u0026rsquo;s main event loop now has an updated snapshot including the discovered objects.\n"
},
{
	"uri": "https://gloo.solo.io/0.8/operator_guide/gloo_declarative_model/",
	"title": "Gloo as Declarative Infrastructure",
	"tags": [],
	"description": "",
	"content": " At it\u0026rsquo;s core, Gloo is a simple product that adheres to the declarative infrastructure model: - It watches the current state, known as a snapshot, consisting of proxies, secrets, endpoints, upstreams, and artifacts. - It runs an event loop that, when the snapshot changes, reconciles it with the current state and applies any necessary changes.\nGitOps with Gloo Following the GitOps methodology, custom Gloo configuration can be stored in a version control repo, and controlling how that configuration is reviewed, merged, and deployed can help mitigate operational risk. Coming soon, Gloo Enterprise will be shipping with a feature that simplifies the design of a GitOps process. With Gloo Enterprise, when users make changes in the Gloo UI, they will automatically persist in a changeset that is backed by a Git repository. Only when the change is reviewed and merged in, the configuration will be deployed. Users will be able to see the current deployed state, as well as the pending changeset changes, via the Gloo UI. Contact us for more information about this feature.\nSolo Kit, the declarative product generator Gloo was created using Solo Kit, an open source library that simplifies the creation of declarative products. A product can simply define it\u0026rsquo;s custom API objects in Protocol Buffer format, and Solo Kit will automatically generate: - Strongly typed clients for reading and writing those objects (i.e. upstreams or virtualservices). Solo Kit clients are configured with a pluggable storage layer, and support Kubernetes CRDs, Consul, Vault, and many others out of the box. - An event loop that watches a configuration snapshot. Products simply define the object types that make up a snapshot, and the namespaces to watch for config changes. - API Documentation in markdown format.\nThe architecture of solo kit-generated projects has a few advantages: - Most of the code is automatically generated, speeding up development time. - The user interfaces (CLI, enterprise UI) are very simple \u0026ndash; they simply facilitate the editing of stored yaml configuration. - Multiple solo kit products can run as a pipeline, each watching a writing a set of CRDs. For instance, Gloo deploys with another service called Discovery, that automatically detects upstreams and endpoints from Kubernetes, AWS, and elsewhere. When those get written out to the storage layer, Gloo\u0026rsquo;s main event loop now has an updated snapshot including the discovered objects.\n"
},
{
	"uri": "https://gloo.solo.io/0.7/installation/docker-compose/",
	"title": "Install Gloo using Docker-Compose",
	"tags": [],
	"description": "",
	"content": "  Clone the gloo repository, and cd to this example: git clone https://github.com/solo-io/gloo \u0026amp;\u0026amp; cd gloo/docs/user_guides/docker-compose Run ./prepare-config-directories.sh You can optionally set GLOO_VERSION environment variable to the gloo version you want (defaults to \u0026ldquo;0.6.19\u0026rdquo;). Run docker compose up  Example This configuration comes pre-loaded with an example upstream:\n# view the upstream definition cat data/config/upstreams/gloo-system/petstore.yaml metadata: name: petstore namespace: gloo-system upstream_spec: static: hosts: - addr: petstore port: 8080 # gloo will automatically discover functions (may take a few seconds) cat data/config/upstreams/gloo-system/petstore.yaml metadata: name: petstore namespace: gloo-system resourceVersion: \u0026quot;4\u0026quot; status: reportedBy: gloo state: Accepted upstreamSpec: static: hosts: - addr: petstore port: 8080 serviceSpec: rest: swaggerInfo: url: http://petstore:8080/swagger.json transformations: addPet: body: text: '{\u0026quot;id\u0026quot;: {{ default(id, \u0026quot;\u0026quot;) }},\u0026quot;name\u0026quot;: \u0026quot;{{ default(name, \u0026quot;\u0026quot;)}}\u0026quot;,\u0026quot;tag\u0026quot;: \u0026quot;{{ default(tag, \u0026quot;\u0026quot;)}}\u0026quot;}' headers: :method: text: POST :path: text: /api/pets content-type: text: application/json deletePet: headers: :method: text: DELETE :path: text: /api/pets/{{ default(id, \u0026quot;\u0026quot;) }} content-type: text: application/json findPetById: body: {} headers: :method: text: GET :path: text: /api/pets/{{ default(id, \u0026quot;\u0026quot;) }} content-length: text: \u0026quot;0\u0026quot; content-type: {} transfer-encoding: {} findPets: body: {} headers: :method: text: GET :path: text: /api/pets?tags={{default(tags, \u0026quot;\u0026quot;)}}\u0026amp;limit={{default(limit, \u0026quot;\u0026quot;)}} content-length: text: \u0026quot;0\u0026quot; content-type: {} transfer-encoding: {} # see how the route is configured: cat data/config/virtualservices/gloo-system/default.yaml metadata: name: default namespace: gloo-system resourceVersion: \u0026quot;2\u0026quot; status: reportedBy: gateway state: Accepted subresourceStatuses: '*v1.Proxy gloo-system gateway-proxy': reportedBy: gloo state: Accepted virtualHost: name: gloo-system.default routes: - matcher: exact: /petstore/findPet routeAction: single: destinationSpec: rest: functionName: findPetById upstream: name: petstore namespace: gloo-system # try the route curl localhost:8080/petstore/findPet  "
},
{
	"uri": "https://gloo.solo.io/0.8/installation/docker-compose/",
	"title": "Install Gloo using Docker-Compose",
	"tags": [],
	"description": "",
	"content": "  Clone the gloo repository, and cd to this example: git clone https://github.com/solo-io/gloo \u0026amp;\u0026amp; cd gloo/docs/user_guides/docker-compose Run ./prepare-config-directories.sh You can optionally set GLOO_VERSION environment variable to the gloo version you want (defaults to \u0026ldquo;0.6.19\u0026rdquo;). Run docker compose up  Example This configuration comes pre-loaded with an example upstream:\n# view the upstream definition cat data/config/upstreams/gloo-system/petstore.yaml metadata: name: petstore namespace: gloo-system upstream_spec: static: hosts: - addr: petstore port: 8080 # gloo will automatically discover functions (may take a few seconds) cat data/config/upstreams/gloo-system/petstore.yaml metadata: name: petstore namespace: gloo-system resourceVersion: \u0026quot;4\u0026quot; status: reportedBy: gloo state: Accepted upstreamSpec: static: hosts: - addr: petstore port: 8080 serviceSpec: rest: swaggerInfo: url: http://petstore:8080/swagger.json transformations: addPet: body: text: '{\u0026quot;id\u0026quot;: {{ default(id, \u0026quot;\u0026quot;) }},\u0026quot;name\u0026quot;: \u0026quot;{{ default(name, \u0026quot;\u0026quot;)}}\u0026quot;,\u0026quot;tag\u0026quot;: \u0026quot;{{ default(tag, \u0026quot;\u0026quot;)}}\u0026quot;}' headers: :method: text: POST :path: text: /api/pets content-type: text: application/json deletePet: headers: :method: text: DELETE :path: text: /api/pets/{{ default(id, \u0026quot;\u0026quot;) }} content-type: text: application/json findPetById: body: {} headers: :method: text: GET :path: text: /api/pets/{{ default(id, \u0026quot;\u0026quot;) }} content-length: text: \u0026quot;0\u0026quot; content-type: {} transfer-encoding: {} findPets: body: {} headers: :method: text: GET :path: text: /api/pets?tags={{default(tags, \u0026quot;\u0026quot;)}}\u0026amp;limit={{default(limit, \u0026quot;\u0026quot;)}} content-length: text: \u0026quot;0\u0026quot; content-type: {} transfer-encoding: {} # see how the route is configured: cat data/config/virtualservices/gloo-system/default.yaml metadata: name: default namespace: gloo-system resourceVersion: \u0026quot;2\u0026quot; status: reportedBy: gateway state: Accepted subresourceStatuses: '*v1.Proxy gloo-system gateway-proxy': reportedBy: gloo state: Accepted virtualHost: name: gloo-system.default routes: - matcher: exact: /petstore/findPet routeAction: single: destinationSpec: rest: functionName: findPetById upstream: name: petstore namespace: gloo-system # try the route curl localhost:8080/petstore/findPet  "
},
{
	"uri": "https://gloo.solo.io/0.7/user_guides/",
	"title": "User Guides",
	"tags": [],
	"description": "",
	"content": "Follow these guides to get started using Gloo!\nAPI Gateway Routing:\n Basic Routing Function Routing External API Routing  Ingress:\n Basic Ingress  Knative:\n Gloo with Knative  "
},
{
	"uri": "https://gloo.solo.io/0.8/user_guides/",
	"title": "User Guides",
	"tags": [],
	"description": "",
	"content": "Follow these guides to get started using Gloo!\nAPI Gateway Routing:\n Basic Routing Function Routing External API Routing  Ingress:\n Basic Ingress  Knative:\n Gloo with Knative  "
},
{
	"uri": "https://gloo.solo.io/0.7/user_guides/basic_ingress/",
	"title": "Ingress Routing",
	"tags": [],
	"description": "",
	"content": " Kubernetes Ingress Controllers are used for simple traffic routing into a kubernetes cluster. When Gloo is installed with the glooctl install ingress command, Gloo will configure Envoy as a Kubernetes Ingress Controller, supporting Ingress objects written with the annotation kubernetes.io/ingress.class: gloo.\nWhat you\u0026rsquo;ll need  kubectl Kubernetes v1.11.3+ deployed somewhere. Minikube is a great way to get a cluster up quickly.  Steps  The Gloo Ingress installed and running on Kubernetes.\n Next, deploy the Pet Store app to kubernetes:\nkubectl apply \\ -f https://raw.githubusercontent.com/solo-io/gloo/master/example/petstore/petstore.yaml  Let\u0026rsquo;s create a Kubernetes Ingress object to route requests to the petstore\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: extensions/v1beta1 kind: Ingress metadata: name: petstore-ingress namespace: default annotations: kubernetes.io/ingress.class: gloo spec: rules: - http: paths: - path: /.* backend: serviceName: petstore servicePort: 8080 EOF  ingress.extensions \u0026ldquo;petstore-ingress\u0026rdquo; created\n Let\u0026rsquo;s test the route /api/pets using curl:\nexport INGRESS_URL=$(glooctl proxy url --name ingress-proxy) curl ${INGRESS_URL}/api/pets [{\u0026quot;id\u0026quot;:1,\u0026quot;name\u0026quot;:\u0026quot;Dog\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;available\u0026quot;},{\u0026quot;id\u0026quot;:2,\u0026quot;name\u0026quot;:\u0026quot;Cat\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;pending\u0026quot;}]   Great! our ingress is up and running. See https://kubernetes.io/docs/concepts/services-networking/ingress/ for more information on using kubernetes ingress controllers.\n"
},
{
	"uri": "https://gloo.solo.io/0.8/user_guides/basic_ingress/",
	"title": "Ingress Routing",
	"tags": [],
	"description": "",
	"content": " Kubernetes Ingress Controllers are used for simple traffic routing into a kubernetes cluster. When Gloo is installed with the glooctl install ingress command, Gloo will configure Envoy as a Kubernetes Ingress Controller, supporting Ingress objects written with the annotation kubernetes.io/ingress.class: gloo.\nWhat you\u0026rsquo;ll need  kubectl Kubernetes v1.11.3+ deployed somewhere. Minikube is a great way to get a cluster up quickly.  Steps  The Gloo Ingress installed and running on Kubernetes.\n Next, deploy the Pet Store app to kubernetes:\nkubectl apply \\ -f https://raw.githubusercontent.com/solo-io/gloo/master/example/petstore/petstore.yaml  Let\u0026rsquo;s create a Kubernetes Ingress object to route requests to the petstore\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: extensions/v1beta1 kind: Ingress metadata: name: petstore-ingress namespace: default annotations: kubernetes.io/ingress.class: gloo spec: rules: - http: paths: - path: /.* backend: serviceName: petstore servicePort: 8080 EOF  ingress.extensions \u0026ldquo;petstore-ingress\u0026rdquo; created\n Let\u0026rsquo;s test the route /api/pets using curl:\nexport INGRESS_URL=$(glooctl proxy url --name ingress-proxy) curl ${INGRESS_URL}/api/pets [{\u0026quot;id\u0026quot;:1,\u0026quot;name\u0026quot;:\u0026quot;Dog\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;available\u0026quot;},{\u0026quot;id\u0026quot;:2,\u0026quot;name\u0026quot;:\u0026quot;Cat\u0026quot;,\u0026quot;status\u0026quot;:\u0026quot;pending\u0026quot;}]   Great! our ingress is up and running. See https://kubernetes.io/docs/concepts/services-networking/ingress/ for more information on using kubernetes ingress controllers.\n"
},
{
	"uri": "https://gloo.solo.io/0.7/operator_guide/",
	"title": "Operator Guide",
	"tags": [],
	"description": "",
	"content": "As an operator of Gloo, it\u0026rsquo;s important to understand how Gloo manages it\u0026rsquo;s configuration, and how this can fit into the processes for managing production environments at your enterprise.\n"
},
{
	"uri": "https://gloo.solo.io/0.8/operator_guide/",
	"title": "Operator Guide",
	"tags": [],
	"description": "",
	"content": "As an operator of Gloo, it\u0026rsquo;s important to understand how Gloo manages it\u0026rsquo;s configuration, and how this can fit into the processes for managing production environments at your enterprise.\n"
},
{
	"uri": "https://gloo.solo.io/0.7/v1/",
	"title": "API Reference",
	"tags": [],
	"description": "",
	"content": " API Reference for Gloo, The Hybrid Application Gateway API Version: gloo.solo.io.v1\nGloo is a high-performance, plugin-extendable, platform-agnostic API Gateway built on top of Envoy. Gloo is designed for microservice, monolithic, and serverless applications. By employing function-level routing, Gloo can completely decouple client APIs from upstream APIs at the routing level. Gloo serves as an abstraction layer between clients and upstream services, allowing front-end teams to work independently of teams developing the microservices their apps connect to.\nAPI Resources:  Overview  Upstreams Virtual Services Secrets Artifacts Ingress ClusterIngress KubeService  Plugins  Transformation Transformation Parameters Transformation Prefix Rewrite Service Spec AWS Azure Rest Static Consul Kubernetes gRPC Fault Injection  Core  Metadata Status ResourceRef  Advanced  Settings Gateways Proxies    "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/",
	"title": "API Reference",
	"tags": [],
	"description": "",
	"content": " API Reference for Gloo, The Hybrid Application Gateway API Version: gloo.solo.io.v1\nGloo is a high-performance, plugin-extendable, platform-agnostic API Gateway built on top of Envoy. Gloo is designed for microservice, monolithic, and serverless applications. By employing function-level routing, Gloo can completely decouple client APIs from upstream APIs at the routing level. Gloo serves as an abstraction layer between clients and upstream services, allowing front-end teams to work independently of teams developing the microservices their apps connect to.\nAPI Resources:  Overview  Upstreams Virtual Services Secrets Artifacts Ingress ClusterIngress KubeService  Plugins  Transformation Transformation Parameters Transformation Prefix Rewrite Service Spec AWS Azure Rest Static Consul Kubernetes gRPC Fault Injection  Core  Metadata Status ResourceRef  Advanced  Settings Gateways Proxies    "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/",
	"title": "Command Line Reference",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gloo.solo.io/0.8/cli/",
	"title": "Command Line Reference",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gloo.solo.io/0.7/user_guides/gloo_with_knative/",
	"title": "Gloo with Knative",
	"tags": [],
	"description": "",
	"content": " Google\u0026rsquo;s Knative project leverages a Kubernetes Cluster Ingress Controller to route requests to apps managed and autoscaled by Knative. At the time of writing, the only available options for Cluster Ingress are Istio and Gloo. This tutorial explains how to get started using Gloo as your Knative Cluster Ingress.\nWhat you\u0026rsquo;ll need  kubectl Kubernetes v1.11.3+ deployed somewhere. Minikube is a great way to get a cluster up quickly. Docker installed and running on your local machine, and a Docker Hub account configured (we\u0026rsquo;ll use it for a container registry).  Steps  First, deploy the Gloo Cluster Ingress and Knative installed on Kubernetes. Knative can be deployed independently, or using glooctl install knative.\n Next, we\u0026rsquo;ll create a sample Go web app to deploy with Knative.\n Create a new file named helloworld.go and paste the following code. This code creates a basic web server which listens on port 8080:\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;os\u0026quot; ) func handler(w http.ResponseWriter, r *http.Request) { log.Print(\u0026quot;Hello world received a request.\u0026quot;) target := os.Getenv(\u0026quot;TARGET\u0026quot;) if target == \u0026quot;\u0026quot; { target = \u0026quot;World\u0026quot; } fmt.Fprintf(w, \u0026quot;Hello %s!\\n\u0026quot;, target) } func main() { log.Print(\u0026quot;Hello world sample started.\u0026quot;) http.HandleFunc(\u0026quot;/\u0026quot;, handler) port := os.Getenv(\u0026quot;PORT\u0026quot;) if port == \u0026quot;\u0026quot; { port = \u0026quot;8080\u0026quot; } log.Fatal(http.ListenAndServe(fmt.Sprintf(\u0026quot;:%s\u0026quot;, port), nil)) }  in your project directory, create a file named Dockerfile and copy the code block below into it. For detailed instructions on dockerizing a Go app, see Deploying Go servers with Docker.\n# Use the official Golang image to create a build artifact. # This is based on Debian and sets the GOPATH to /go. # https://hub.docker.com/_/golang FROM golang as builder # Copy local code to the container image. WORKDIR /go/src/github.com/knative/docs/helloworld COPY . . # Build the helloworld command inside the container. # (You may fetch or manage dependencies here, # either manually or with a tool like \u0026quot;godep\u0026quot;.) RUN CGO_ENABLED=0 GOOS=linux go build -v -o helloworld # Use a Docker multi-stage build to create a lean production image. # https://docs.docker.com/develop/develop-images/multistage-build/#use-multi-stage-builds FROM alpine # Copy the binary to the production image from the builder stage. COPY --from=builder /go/src/github.com/knative/docs/helloworld/helloworld /helloworld # Service must listen to $PORT environment variable. # This default value facilitates local development. ENV PORT 8080 # Run the web service on container startup. CMD [\u0026quot;/helloworld\u0026quot;]  Create a new file, service.yaml and copy the following service definition into the file. Make sure to replace {username} with your Docker Hub username.\napiVersion: serving.knative.dev/v1alpha1 kind: Service metadata: name: helloworld-go namespace: default spec: runLatest: configuration: revisionTemplate: spec: container: image: docker.io/{username}/helloworld-go env: - name: TARGET value: \u0026quot;Go Sample v1\u0026quot;   Once the sample code has been created, we\u0026rsquo;ll build and deploy it\n Use Docker to build the sample code into a container. To build and push with Docker Hub, run these commands replacing {username} with your Docker Hub username:\n# Build the container on your local machine docker build -t {username}/helloworld-go . # Push the container to docker registry docker push {username}/helloworld-go  After the build has completed and the container is pushed to docker hub, you can deploy the app into your cluster. Ensure that the container image value in service.yaml matches the container you built in the previous step. Apply the configuration using kubectl:\nkubectl apply --filename service.yaml  Now that your service is created, Knative will perform the following steps:\n Create a new immutable revision for this version of the app. Network programming to create a route, ingress, service, and load balance for your app. Automatically scale your pods up and down (including to zero active pods).  Run the following command to find the external IP address for the Gloo cluster ingress.\nCLUSTERINGRESS_URL=$(glooctl proxy url --name clusteringress-proxy) echo $CLUSTERINGRESS_URL http://192.168.99.230:31864  Run the following command to find the domain URL for your service:\nkubectl get ksvc helloworld-go -n default --output=custom-columns=NAME:.metadata.name,DOMAIN:.status.domain  Example:\nNAME DOMAIN helloworld-go helloworld-go.default.example.com  Test your app by sending it a request. Use the following curl command with the domain URL helloworld-go.default.example.com and EXTERNAL-IP address that you retrieved in the previous steps:\ncurl -H \u0026quot;Host: helloworld-go.default.example.com\u0026quot; ${CLUSTERINGRESS_URL} Hello Go Sample v1!   Note: Add -v option to get more detail if the curl command failed.\n Removing the sample app deployment\nTo remove the sample app from your cluster, delete the service record:\nkubectl delete --filename service.yaml    Great! our Knative ingress is up and running. See https://github.com/knative/docs for more information on using Knative.\n"
},
{
	"uri": "https://gloo.solo.io/0.8/user_guides/gloo_with_knative/",
	"title": "Gloo with Knative",
	"tags": [],
	"description": "",
	"content": " Google\u0026rsquo;s Knative project leverages a Kubernetes Cluster Ingress Controller to route requests to apps managed and autoscaled by Knative. At the time of writing, the only available options for Cluster Ingress are Istio and Gloo. This tutorial explains how to get started using Gloo as your Knative Cluster Ingress.\nWhat you\u0026rsquo;ll need  kubectl Kubernetes v1.11.3+ deployed somewhere. Minikube is a great way to get a cluster up quickly. Docker installed and running on your local machine, and a Docker Hub account configured (we\u0026rsquo;ll use it for a container registry).  Steps  First, deploy the Gloo Cluster Ingress and Knative installed on Kubernetes. Knative can be deployed independently, or using glooctl install knative.\n Next, we\u0026rsquo;ll create a sample Go web app to deploy with Knative.\n Create a new file named helloworld.go and paste the following code. This code creates a basic web server which listens on port 8080:\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;os\u0026quot; ) func handler(w http.ResponseWriter, r *http.Request) { log.Print(\u0026quot;Hello world received a request.\u0026quot;) target := os.Getenv(\u0026quot;TARGET\u0026quot;) if target == \u0026quot;\u0026quot; { target = \u0026quot;World\u0026quot; } fmt.Fprintf(w, \u0026quot;Hello %s!\\n\u0026quot;, target) } func main() { log.Print(\u0026quot;Hello world sample started.\u0026quot;) http.HandleFunc(\u0026quot;/\u0026quot;, handler) port := os.Getenv(\u0026quot;PORT\u0026quot;) if port == \u0026quot;\u0026quot; { port = \u0026quot;8080\u0026quot; } log.Fatal(http.ListenAndServe(fmt.Sprintf(\u0026quot;:%s\u0026quot;, port), nil)) }  in your project directory, create a file named Dockerfile and copy the code block below into it. For detailed instructions on dockerizing a Go app, see Deploying Go servers with Docker.\n# Use the official Golang image to create a build artifact. # This is based on Debian and sets the GOPATH to /go. # https://hub.docker.com/_/golang FROM golang as builder # Copy local code to the container image. WORKDIR /go/src/github.com/knative/docs/helloworld COPY . . # Build the helloworld command inside the container. # (You may fetch or manage dependencies here, # either manually or with a tool like \u0026quot;godep\u0026quot;.) RUN CGO_ENABLED=0 GOOS=linux go build -v -o helloworld # Use a Docker multi-stage build to create a lean production image. # https://docs.docker.com/develop/develop-images/multistage-build/#use-multi-stage-builds FROM alpine # Copy the binary to the production image from the builder stage. COPY --from=builder /go/src/github.com/knative/docs/helloworld/helloworld /helloworld # Service must listen to $PORT environment variable. # This default value facilitates local development. ENV PORT 8080 # Run the web service on container startup. CMD [\u0026quot;/helloworld\u0026quot;]  Create a new file, service.yaml and copy the following service definition into the file. Make sure to replace {username} with your Docker Hub username.\napiVersion: serving.knative.dev/v1alpha1 kind: Service metadata: name: helloworld-go namespace: default spec: runLatest: configuration: revisionTemplate: spec: container: image: docker.io/{username}/helloworld-go env: - name: TARGET value: \u0026quot;Go Sample v1\u0026quot;   Once the sample code has been created, we\u0026rsquo;ll build and deploy it\n Use Docker to build the sample code into a container. To build and push with Docker Hub, run these commands replacing {username} with your Docker Hub username:\n# Build the container on your local machine docker build -t {username}/helloworld-go . # Push the container to docker registry docker push {username}/helloworld-go  After the build has completed and the container is pushed to docker hub, you can deploy the app into your cluster. Ensure that the container image value in service.yaml matches the container you built in the previous step. Apply the configuration using kubectl:\nkubectl apply --filename service.yaml  Now that your service is created, Knative will perform the following steps:\n Create a new immutable revision for this version of the app. Network programming to create a route, ingress, service, and load balance for your app. Automatically scale your pods up and down (including to zero active pods).  Run the following command to find the external IP address for the Gloo cluster ingress.\nCLUSTERINGRESS_URL=$(glooctl proxy url --name clusteringress-proxy) echo $CLUSTERINGRESS_URL http://192.168.99.230:31864  Run the following command to find the domain URL for your service:\nkubectl get ksvc helloworld-go -n default --output=custom-columns=NAME:.metadata.name,DOMAIN:.status.domain  Example:\nNAME DOMAIN helloworld-go helloworld-go.default.example.com  Test your app by sending it a request. Use the following curl command with the domain URL helloworld-go.default.example.com and EXTERNAL-IP address that you retrieved in the previous steps:\ncurl -H \u0026quot;Host: helloworld-go.default.example.com\u0026quot; ${CLUSTERINGRESS_URL} Hello Go Sample v1!   Note: Add -v option to get more detail if the curl command failed.\n Removing the sample app deployment\nTo remove the sample app from your cluster, delete the service record:\nkubectl delete --filename service.yaml    Great! our Knative ingress is up and running. See https://github.com/knative/docs for more information on using Knative.\n"
},
{
	"uri": "https://gloo.solo.io/0.7/v1/google/protobuf/any.proto.sk/",
	"title": "any.proto",
	"tags": [],
	"description": "",
	"content": " Package: google.protobuf Protocol Buffers - Google\u0026rsquo;s data interchange format Copyright 2008 Google Inc. All rights reserved. https://developers.google.com/protocol-buffers/\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n* Redistributions of source code must retain the above copyright  notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026ldquo;AS IS\u0026rdquo; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nTypes:  Any   Source File: google/protobuf/any.proto Any Any contains an arbitrary serialized protocol buffer message along with a URL that describes the type of the serialized message.\nProtobuf library provides support to pack/unpack Any values in the form of utility functions or additional generated methods of the Any type.\nExample 1: Pack and unpack a message in C++.\nFoo foo = ...; Any any; any.PackFrom(foo); ... if (any.UnpackTo(\u0026amp;foo)) { ... }  Example 2: Pack and unpack a message in Java.\nFoo foo = ...; Any any = Any.pack(foo); ... if (any.is(Foo.class)) { foo = any.unpack(Foo.class); }  Example 3: Pack and unpack a message in Python.\nfoo = Foo(...) any = Any() any.Pack(foo) ... if any.Is(Foo.DESCRIPTOR): any.Unpack(foo) ...  The pack methods provided by protobuf library will by default use \u0026lsquo;type.googleapis.com/full.type.name\u0026rsquo; as the type URL and the unpack methods only use the fully qualified type name after the last \u0026lsquo;/\u0026rsquo; in the type URL, for example \u0026ldquo;foo.bar.com/x/y.z\u0026rdquo; will yield type name \u0026ldquo;y.z\u0026rdquo;.\nJSON The JSON representation of an Any value uses the regular representation of the deserialized, embedded message, with an additional field @type which contains the type URL. Example:\npackage google.profile; message Person { string first_name = 1; string last_name = 2; } { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/google.profile.Person\u0026quot;, \u0026quot;firstName\u0026quot;: \u0026lt;string\u0026gt;, \u0026quot;lastName\u0026quot;: \u0026lt;string\u0026gt; }  If the embedded message type is well-known and has a custom JSON representation, that representation will be embedded adding a field value which holds the custom JSON in addition to the @type field. Example (for message [google.protobuf.Duration][]):\n{ \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/google.protobuf.Duration\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;1.212s\u0026quot; }  \u0026quot;type_url\u0026quot;: string \u0026quot;value\u0026quot;: bytes     Field Type Description Default     type_url string A URL/resource name whose content describes the type of the serialized protocol buffer message. For URLs which use the scheme http, https, or no scheme, the following restrictions and interpretations apply: * If no scheme is provided, https is assumed. * The last segment of the URL\u0026rsquo;s path must represent the fully qualified name of the type (as in path/google.protobuf.Duration). The name should be in a canonical form (e.g., leading \u0026ldquo;.\u0026rdquo; is not accepted). * An HTTP GET on the URL must yield a [google.protobuf.Type][] value in binary format, or produce an error. * Applications are allowed to cache lookup results based on the URL, or have them precompiled into a binary to avoid any lookup. Therefore, binary compatibility needs to be preserved on changes to types. (Use versioned type names to manage breaking changes.) Schemes other than http, https (or the empty scheme) might be used with implementation specific semantics.    value bytes Must be a valid serialized protocol buffer of the above specified type.      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/google/protobuf/any.proto.sk/",
	"title": "any.proto",
	"tags": [],
	"description": "",
	"content": " Package: google.protobuf Protocol Buffers - Google\u0026rsquo;s data interchange format Copyright 2008 Google Inc. All rights reserved. https://developers.google.com/protocol-buffers/\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n* Redistributions of source code must retain the above copyright  notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026ldquo;AS IS\u0026rdquo; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nTypes:  Any   Source File: google/protobuf/any.proto Any Any contains an arbitrary serialized protocol buffer message along with a URL that describes the type of the serialized message.\nProtobuf library provides support to pack/unpack Any values in the form of utility functions or additional generated methods of the Any type.\nExample 1: Pack and unpack a message in C++.\nFoo foo = ...; Any any; any.PackFrom(foo); ... if (any.UnpackTo(\u0026amp;foo)) { ... }  Example 2: Pack and unpack a message in Java.\nFoo foo = ...; Any any = Any.pack(foo); ... if (any.is(Foo.class)) { foo = any.unpack(Foo.class); }  Example 3: Pack and unpack a message in Python.\nfoo = Foo(...) any = Any() any.Pack(foo) ... if any.Is(Foo.DESCRIPTOR): any.Unpack(foo) ...  The pack methods provided by protobuf library will by default use \u0026lsquo;type.googleapis.com/full.type.name\u0026rsquo; as the type URL and the unpack methods only use the fully qualified type name after the last \u0026lsquo;/\u0026rsquo; in the type URL, for example \u0026ldquo;foo.bar.com/x/y.z\u0026rdquo; will yield type name \u0026ldquo;y.z\u0026rdquo;.\nJSON The JSON representation of an Any value uses the regular representation of the deserialized, embedded message, with an additional field @type which contains the type URL. Example:\npackage google.profile; message Person { string first_name = 1; string last_name = 2; } { \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/google.profile.Person\u0026quot;, \u0026quot;firstName\u0026quot;: \u0026lt;string\u0026gt;, \u0026quot;lastName\u0026quot;: \u0026lt;string\u0026gt; }  If the embedded message type is well-known and has a custom JSON representation, that representation will be embedded adding a field value which holds the custom JSON in addition to the @type field. Example (for message [google.protobuf.Duration][]):\n{ \u0026quot;@type\u0026quot;: \u0026quot;type.googleapis.com/google.protobuf.Duration\u0026quot;, \u0026quot;value\u0026quot;: \u0026quot;1.212s\u0026quot; }  \u0026quot;type_url\u0026quot;: string \u0026quot;value\u0026quot;: bytes     Field Type Description Default     type_url string A URL/resource name whose content describes the type of the serialized protocol buffer message. For URLs which use the scheme http, https, or no scheme, the following restrictions and interpretations apply: * If no scheme is provided, https is assumed. * The last segment of the URL\u0026rsquo;s path must represent the fully qualified name of the type (as in path/google.protobuf.Duration). The name should be in a canonical form (e.g., leading \u0026ldquo;.\u0026rdquo; is not accepted). * An HTTP GET on the URL must yield a [google.protobuf.Type][] value in binary format, or produce an error. * Applications are allowed to cache lookup results based on the URL, or have them precompiled into a binary to avoid any lookup. Therefore, binary compatibility needs to be preserved on changes to types. (Use versioned type names to manage breaking changes.) Schemes other than http, https (or the empty scheme) might be used with implementation specific semantics.    value bytes Must be a valid serialized protocol buffer of the above specified type.      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/artifact.proto.sk/",
	"title": "artifact.proto",
	"tags": [],
	"description": "",
	"content": " Package: gloo.solo.io Types:  Artifact Top-Level Resource   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/artifact.proto Artifact Gloo Artifacts are used by Gloo to store small bits of binary or file data.\nCertain plugins such as the gRPC plugin read and write artifacts to one of Gloo\u0026rsquo;s configured storage layer.\nArtifacts can be backed by files on disk, Kubernetes ConfigMaps, and Consul Key/Value pairs.\nSupported artifact backends can be selected in Gloo\u0026rsquo;s boostrap options.\n\u0026quot;data\u0026quot;: string \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata     Field Type Description Default     data string Raw data data being stored    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/artifact.proto.sk/",
	"title": "artifact.proto",
	"tags": [],
	"description": "",
	"content": " Package: gloo.solo.io Types:  Artifact Top-Level Resource   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/artifact.proto Artifact Gloo Artifacts are used by Gloo to store small bits of binary or file data.\nCertain plugins such as the gRPC plugin read and write artifacts to one of Gloo\u0026rsquo;s configured storage layer.\nArtifacts can be backed by files on disk, Kubernetes ConfigMaps, and Consul Key/Value pairs.\nSupported artifact backends can be selected in Gloo\u0026rsquo;s boostrap options.\n\u0026quot;data\u0026quot;: string \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata     Field Type Description Default     data string Raw data data being stored    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/aws/aws.proto.sk/",
	"title": "aws.proto",
	"tags": [],
	"description": "",
	"content": " Package: aws.plugins.gloo.solo.io Types:  UpstreamSpec LambdaFunctionSpec DestinationSpec InvocationStyle   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/aws/aws.proto UpstreamSpec Upstream Spec for AWS Lambda Upstreams AWS Upstreams represent a collection of Lambda Functions for a particular AWS Account (IAM Role or User account) in a particular region\n\u0026quot;region\u0026quot;: string \u0026quot;secret_ref\u0026quot;: .core.solo.io.ResourceRef \u0026quot;lambda_functions\u0026quot;: []aws.plugins.gloo.solo.io.LambdaFunctionSpec     Field Type Description Default     region string The AWS Region where the desired Lambda Functions exxist    secret_ref .core.solo.io.ResourceRef A Gloo Secret Ref to an AWS Secret AWS Secrets can be created with glooctl secret create aws ... If the secret is created manually, it must conform to the following structure: access_key: \u0026lt;aws access key\u0026gt; secret_key: \u0026lt;aws secret key\u0026gt;    lambda_functions []aws.plugins.gloo.solo.io.LambdaFunctionSpec The list of Lambda Functions contained within this region. This list will be automatically populated by Gloo if discovery is enabled for AWS Lambda Functions     LambdaFunctionSpec Each Lambda Function Spec contains data necessary for Gloo to invoke Lambda functions: - name of the function - qualifier for the function\n\u0026quot;logical_name\u0026quot;: string \u0026quot;lambda_function_name\u0026quot;: string \u0026quot;qualifier\u0026quot;: string     Field Type Description Default     logical_name string the logical name gloo should associate with this function. if left empty, it will default to lambda_function_name+qualifier    lambda_function_name string The Name of the Lambda Function as it appears in the AWS Lambda Portal    qualifier string The Qualifier for the Lambda Function. Qualifiers act as a kind of version for Lambda Functions. See https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html for more info.     DestinationSpec Each Lambda Function Spec contains data necessary for Gloo to invoke Lambda functions\n\u0026quot;logical_name\u0026quot;: string \u0026quot;invocation_style\u0026quot;: .aws.plugins.gloo.solo.io.DestinationSpec.InvocationStyle \u0026quot;response_transformation\u0026quot;: bool     Field Type Description Default     logical_name string The Logical Name of the LambdaFunctionSpec to be invoked.    invocation_style .aws.plugins.gloo.solo.io.DestinationSpec.InvocationStyle Can be either Sync or Async.    response_transformation bool de-jsonify response bodies returned from aws lambda     InvocationStyle    Name Description     SYNC    ASYNC      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/aws/aws.proto.sk/",
	"title": "aws.proto",
	"tags": [],
	"description": "",
	"content": " Package: aws.plugins.gloo.solo.io Types:  UpstreamSpec LambdaFunctionSpec DestinationSpec InvocationStyle   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/aws/aws.proto UpstreamSpec Upstream Spec for AWS Lambda Upstreams AWS Upstreams represent a collection of Lambda Functions for a particular AWS Account (IAM Role or User account) in a particular region\n\u0026quot;region\u0026quot;: string \u0026quot;secret_ref\u0026quot;: .core.solo.io.ResourceRef \u0026quot;lambda_functions\u0026quot;: []aws.plugins.gloo.solo.io.LambdaFunctionSpec     Field Type Description Default     region string The AWS Region where the desired Lambda Functions exxist    secret_ref .core.solo.io.ResourceRef A Gloo Secret Ref to an AWS Secret AWS Secrets can be created with glooctl secret create aws ... If the secret is created manually, it must conform to the following structure: access_key: \u0026lt;aws access key\u0026gt; secret_key: \u0026lt;aws secret key\u0026gt;    lambda_functions []aws.plugins.gloo.solo.io.LambdaFunctionSpec The list of Lambda Functions contained within this region. This list will be automatically populated by Gloo if discovery is enabled for AWS Lambda Functions     LambdaFunctionSpec Each Lambda Function Spec contains data necessary for Gloo to invoke Lambda functions: - name of the function - qualifier for the function\n\u0026quot;logical_name\u0026quot;: string \u0026quot;lambda_function_name\u0026quot;: string \u0026quot;qualifier\u0026quot;: string     Field Type Description Default     logical_name string the logical name gloo should associate with this function. if left empty, it will default to lambda_function_name+qualifier    lambda_function_name string The Name of the Lambda Function as it appears in the AWS Lambda Portal    qualifier string The Qualifier for the Lambda Function. Qualifiers act as a kind of version for Lambda Functions. See https://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html for more info.     DestinationSpec Each Lambda Function Spec contains data necessary for Gloo to invoke Lambda functions\n\u0026quot;logical_name\u0026quot;: string \u0026quot;invocation_style\u0026quot;: .aws.plugins.gloo.solo.io.DestinationSpec.InvocationStyle \u0026quot;response_transformation\u0026quot;: bool     Field Type Description Default     logical_name string The Logical Name of the LambdaFunctionSpec to be invoked.    invocation_style .aws.plugins.gloo.solo.io.DestinationSpec.InvocationStyle Can be either Sync or Async.    response_transformation bool de-jsonify response bodies returned from aws lambda     InvocationStyle    Name Description     SYNC    ASYNC      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/azure/azure.proto.sk/",
	"title": "azure.proto",
	"tags": [],
	"description": "",
	"content": " Package: azure.plugins.gloo.solo.io Types:  UpstreamSpec FunctionSpec AuthLevel DestinationSpec   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/azure/azure.proto UpstreamSpec Upstream Spec for Azure Functions Upstreams Azure Upstreams represent a collection of Azure Functions for a particular Azure Account within a particular Function App\n\u0026quot;function_app_name\u0026quot;: string \u0026quot;secret_ref\u0026quot;: .core.solo.io.ResourceRef \u0026quot;functions\u0026quot;: []azure.plugins.gloo.solo.io.UpstreamSpec.FunctionSpec     Field Type Description Default     function_app_name string The Name of the Azure Function App where the functions are grouped    secret_ref .core.solo.io.ResourceRef A Gloo Secret Ref to an Azure Publish Profile JSON file. {{ hide_not_implemented \u0026ldquo;Azure Secrets can be created with glooctl secret create azure ...\u0026rdquo; }} Note that this secret is not required unless Function Discovery is enabled    functions []azure.plugins.gloo.solo.io.UpstreamSpec.FunctionSpec      FunctionSpec Function Spec for Functions on Azure Functions Upstreams The Function Spec contains data necessary for Gloo to invoke Azure functions\n\u0026quot;function_name\u0026quot;: string \u0026quot;auth_level\u0026quot;: .azure.plugins.gloo.solo.io.UpstreamSpec.FunctionSpec.AuthLevel     Field Type Description Default     function_name string The Name of the Azure Function as it appears in the Azure Functions Portal    auth_level .azure.plugins.gloo.solo.io.UpstreamSpec.FunctionSpec.AuthLevel Auth Level can bve either \u0026ldquo;anonymous\u0026rdquo; \u0026ldquo;function\u0026rdquo; or \u0026ldquo;admin\u0026rdquo; See https://vincentlauzon.com/2017/12/04/azure-functions-http-authorization-levels/ for more details     AuthLevel    Name Description     Anonymous    Function    Admin     DestinationSpec \u0026quot;function_name\u0026quot;: string     Field Type Description Default     function_name string The Function Name of the FunctionSpec to be invoked.      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/azure/azure.proto.sk/",
	"title": "azure.proto",
	"tags": [],
	"description": "",
	"content": " Package: azure.plugins.gloo.solo.io Types:  UpstreamSpec FunctionSpec AuthLevel DestinationSpec   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/azure/azure.proto UpstreamSpec Upstream Spec for Azure Functions Upstreams Azure Upstreams represent a collection of Azure Functions for a particular Azure Account within a particular Function App\n\u0026quot;function_app_name\u0026quot;: string \u0026quot;secret_ref\u0026quot;: .core.solo.io.ResourceRef \u0026quot;functions\u0026quot;: []azure.plugins.gloo.solo.io.UpstreamSpec.FunctionSpec     Field Type Description Default     function_app_name string The Name of the Azure Function App where the functions are grouped    secret_ref .core.solo.io.ResourceRef A Gloo Secret Ref to an Azure Publish Profile JSON file. {{ hide_not_implemented \u0026ldquo;Azure Secrets can be created with glooctl secret create azure ...\u0026rdquo; }} Note that this secret is not required unless Function Discovery is enabled    functions []azure.plugins.gloo.solo.io.UpstreamSpec.FunctionSpec      FunctionSpec Function Spec for Functions on Azure Functions Upstreams The Function Spec contains data necessary for Gloo to invoke Azure functions\n\u0026quot;function_name\u0026quot;: string \u0026quot;auth_level\u0026quot;: .azure.plugins.gloo.solo.io.UpstreamSpec.FunctionSpec.AuthLevel     Field Type Description Default     function_name string The Name of the Azure Function as it appears in the Azure Functions Portal    auth_level .azure.plugins.gloo.solo.io.UpstreamSpec.FunctionSpec.AuthLevel Auth Level can bve either \u0026ldquo;anonymous\u0026rdquo; \u0026ldquo;function\u0026rdquo; or \u0026ldquo;admin\u0026rdquo; See https://vincentlauzon.com/2017/12/04/azure-functions-http-authorization-levels/ for more details     AuthLevel    Name Description     Anonymous    Function    Admin     DestinationSpec \u0026quot;function_name\u0026quot;: string     Field Type Description Default     function_name string The Function Name of the FunctionSpec to be invoked.      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/clusteringress/api/v1/cluster_ingress.proto.sk/",
	"title": "cluster_ingress.proto",
	"tags": [],
	"description": "",
	"content": " Package: clusteringress.gloo.solo.io Types:  ClusterIngress Top-Level Resource   Source File: github.com/solo-io/gloo/projects/clusteringress/api/v1/cluster_ingress.proto ClusterIngress A simple wrapper for a kNative ClusterIngress Object.\n\u0026quot;metadata\u0026quot;: .core.solo.io.Metadata \u0026quot;status\u0026quot;: .core.solo.io.Status \u0026quot;cluster_ingress_spec\u0026quot;: .google.protobuf.Any \u0026quot;cluster_ingress_status\u0026quot;: .google.protobuf.Any     Field Type Description Default     metadata .core.solo.io.Metadata     status .core.solo.io.Status     cluster_ingress_spec .google.protobuf.Any a raw byte representation of the cluster ingress this resource wraps    cluster_ingress_status .google.protobuf.Any a raw byte representation of the ingress status of the cluster ingress object      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/clusteringress/api/v1/cluster_ingress.proto.sk/",
	"title": "cluster_ingress.proto",
	"tags": [],
	"description": "",
	"content": " Package: clusteringress.gloo.solo.io Types:  ClusterIngress Top-Level Resource   Source File: github.com/solo-io/gloo/projects/clusteringress/api/v1/cluster_ingress.proto ClusterIngress A simple wrapper for a kNative ClusterIngress Object.\n\u0026quot;metadata\u0026quot;: .core.solo.io.Metadata \u0026quot;status\u0026quot;: .core.solo.io.Status \u0026quot;cluster_ingress_spec\u0026quot;: .google.protobuf.Any \u0026quot;cluster_ingress_status\u0026quot;: .google.protobuf.Any     Field Type Description Default     metadata .core.solo.io.Metadata     status .core.solo.io.Status     cluster_ingress_spec .google.protobuf.Any a raw byte representation of the cluster ingress this resource wraps    cluster_ingress_status .google.protobuf.Any a raw byte representation of the ingress status of the cluster ingress object      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/consul/consul.proto.sk/",
	"title": "consul.proto",
	"tags": [],
	"description": "",
	"content": " Package: consul.plugins.gloo.solo.io Types:  UpstreamSpec   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/consul/consul.proto UpstreamSpec Upstream Spec for Consul Upstreams consul Upstreams represent a set of one or more addressable pods for a consul Service the Gloo consul Upstream maps to a single service port. Because consul Services support multiple ports, Gloo requires that a different upstream be created for each port consul Upstreams are typically generated automatically by Gloo from the consul API\n\u0026quot;service_name\u0026quot;: string \u0026quot;service_tags\u0026quot;: []string \u0026quot;service_spec\u0026quot;: .plugins.gloo.solo.io.ServiceSpec \u0026quot;connect_enabled\u0026quot;: bool     Field Type Description Default     service_name string The name of the Consul Service    service_tags []string The list of service tags Gloo should search for on a service instance before deciding whether or not to include the instance as part of this upstream    service_spec .plugins.gloo.solo.io.ServiceSpec An optional Service Spec describing the service listening at this address    connect_enabled bool is this consul service connect enabled.      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/consul/consul.proto.sk/",
	"title": "consul.proto",
	"tags": [],
	"description": "",
	"content": " Package: consul.plugins.gloo.solo.io Types:  UpstreamSpec   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/consul/consul.proto UpstreamSpec Upstream Spec for Consul Upstreams consul Upstreams represent a set of one or more addressable pods for a consul Service the Gloo consul Upstream maps to a single service port. Because consul Services support multiple ports, Gloo requires that a different upstream be created for each port consul Upstreams are typically generated automatically by Gloo from the consul API\n\u0026quot;service_name\u0026quot;: string \u0026quot;service_tags\u0026quot;: []string \u0026quot;service_spec\u0026quot;: .plugins.gloo.solo.io.ServiceSpec \u0026quot;connect_enabled\u0026quot;: bool     Field Type Description Default     service_name string The name of the Consul Service    service_tags []string The list of service tags Gloo should search for on a service instance before deciding whether or not to include the instance as part of this upstream    service_spec .plugins.gloo.solo.io.ServiceSpec An optional Service Spec describing the service listening at this address    connect_enabled bool is this consul service connect enabled.      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/google/protobuf/descriptor.proto.sk/",
	"title": "descriptor.proto",
	"tags": [],
	"description": "",
	"content": " Package: google.protobuf Protocol Buffers - Google\u0026rsquo;s data interchange format Copyright 2008 Google Inc. All rights reserved. https://developers.google.com/protocol-buffers/\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n* Redistributions of source code must retain the above copyright  notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026ldquo;AS IS\u0026rdquo; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nAuthor: kenton@google.com (Kenton Varda) Based on original Protocol Buffers design by Sanjay Ghemawat, Jeff Dean, and others.\nThe messages in this file describe the definitions found in .proto files. A valid .proto file can be translated directly to a FileDescriptorProto without any other information (e.g. without reading its imports).\nTypes:  FileDescriptorSet FileDescriptorProto DescriptorProto ExtensionRange ReservedRange FieldDescriptorProto Type Label OneofDescriptorProto EnumDescriptorProto EnumValueDescriptorProto ServiceDescriptorProto MethodDescriptorProto FileOptions OptimizeMode MessageOptions FieldOptions CType JSType OneofOptions EnumOptions EnumValueOptions ServiceOptions MethodOptions IdempotencyLevel UninterpretedOption NamePart SourceCodeInfo Location GeneratedCodeInfo Annotation   Source File: google/protobuf/descriptor.proto FileDescriptorSet The protocol compiler can output a FileDescriptorSet containing the .proto files it parses.\n\u0026quot;file\u0026quot;: []google.protobuf.FileDescriptorProto     Field Type Description Default     file []google.protobuf.FileDescriptorProto      FileDescriptorProto Describes a complete .proto file.\n\u0026quot;name\u0026quot;: string \u0026quot;package\u0026quot;: string \u0026quot;dependency\u0026quot;: []string \u0026quot;public_dependency\u0026quot;: []int \u0026quot;weak_dependency\u0026quot;: []int \u0026quot;message_type\u0026quot;: []google.protobuf.DescriptorProto \u0026quot;enum_type\u0026quot;: []google.protobuf.EnumDescriptorProto \u0026quot;service\u0026quot;: []google.protobuf.ServiceDescriptorProto \u0026quot;extension\u0026quot;: []google.protobuf.FieldDescriptorProto \u0026quot;options\u0026quot;: .google.protobuf.FileOptions \u0026quot;source_code_info\u0026quot;: .google.protobuf.SourceCodeInfo \u0026quot;syntax\u0026quot;: string     Field Type Description Default     name string     package string     dependency []string Names of files imported by this file.    public_dependency []int Indexes of the public imported files in the dependency list above.    weak_dependency []int Indexes of the weak imported files in the dependency list. For Google-internal migration only. Do not use.    message_type []google.protobuf.DescriptorProto All top-level definitions in this file.    enum_type []google.protobuf.EnumDescriptorProto     service []google.protobuf.ServiceDescriptorProto     extension []google.protobuf.FieldDescriptorProto     options .google.protobuf.FileOptions     source_code_info .google.protobuf.SourceCodeInfo This field contains optional information about the original source code. You may safely remove this entire field without harming runtime functionality of the descriptors \u0026ndash; the information is needed only by development tools.    syntax string The syntax of the proto file. The supported values are \u0026ldquo;proto2\u0026rdquo; and \u0026ldquo;proto3\u0026rdquo;.     DescriptorProto Describes a message type.\n\u0026quot;name\u0026quot;: string \u0026quot;field\u0026quot;: []google.protobuf.FieldDescriptorProto \u0026quot;extension\u0026quot;: []google.protobuf.FieldDescriptorProto \u0026quot;nested_type\u0026quot;: []google.protobuf.DescriptorProto \u0026quot;enum_type\u0026quot;: []google.protobuf.EnumDescriptorProto \u0026quot;extension_range\u0026quot;: []google.protobuf.DescriptorProto.ExtensionRange \u0026quot;oneof_decl\u0026quot;: []google.protobuf.OneofDescriptorProto \u0026quot;options\u0026quot;: .google.protobuf.MessageOptions \u0026quot;reserved_range\u0026quot;: []google.protobuf.DescriptorProto.ReservedRange \u0026quot;reserved_name\u0026quot;: []string     Field Type Description Default     name string     field []google.protobuf.FieldDescriptorProto     extension []google.protobuf.FieldDescriptorProto     nested_type []google.protobuf.DescriptorProto     enum_type []google.protobuf.EnumDescriptorProto     extension_range []google.protobuf.DescriptorProto.ExtensionRange     oneof_decl []google.protobuf.OneofDescriptorProto     options .google.protobuf.MessageOptions     reserved_range []google.protobuf.DescriptorProto.ReservedRange     reserved_name []string Reserved field names, which may not be used by fields in the same message. A given name may only be reserved once.     ExtensionRange \u0026quot;start\u0026quot;: int \u0026quot;end\u0026quot;: int     Field Type Description Default     start int     end int      ReservedRange Range of reserved tag numbers. Reserved tag numbers may not be used by fields or extension ranges in the same message. Reserved ranges may not overlap.\n\u0026quot;start\u0026quot;: int \u0026quot;end\u0026quot;: int     Field Type Description Default     start int     end int      FieldDescriptorProto Describes a field within a message.\n\u0026quot;name\u0026quot;: string \u0026quot;number\u0026quot;: int \u0026quot;label\u0026quot;: .google.protobuf.FieldDescriptorProto.Label \u0026quot;type\u0026quot;: .google.protobuf.FieldDescriptorProto.Type \u0026quot;type_name\u0026quot;: string \u0026quot;extendee\u0026quot;: string \u0026quot;default_value\u0026quot;: string \u0026quot;oneof_index\u0026quot;: int \u0026quot;json_name\u0026quot;: string \u0026quot;options\u0026quot;: .google.protobuf.FieldOptions     Field Type Description Default     name string     number int     label .google.protobuf.FieldDescriptorProto.Label     type .google.protobuf.FieldDescriptorProto.Type If type_name is set, this need not be set. If both this and type_name are set, this must be one of TYPE_ENUM, TYPE_MESSAGE or TYPE_GROUP.    type_name string For message and enum types, this is the name of the type. If the name starts with a \u0026lsquo;.\u0026rsquo;, it is fully-qualified. Otherwise, C++-like scoping rules are used to find the type (i.e. first the nested types within this message are searched, then within the parent, on up to the root namespace).    extendee string For extensions, this is the name of the type being extended. It is resolved in the same manner as type_name.    default_value string For numeric types, contains the original text representation of the value. For booleans, \u0026ldquo;true\u0026rdquo; or \u0026ldquo;false\u0026rdquo;. For strings, contains the default text contents (not escaped in any way). For bytes, contains the C escaped value. All bytes \u0026gt;= 128 are escaped. TODO(kenton): Base-64 encode?    oneof_index int If set, gives the index of a oneof in the containing type\u0026rsquo;s oneof_decl list. This field is a member of that oneof.    json_name string JSON name of this field. The value is set by protocol compiler. If the user has set a \u0026ldquo;json_name\u0026rdquo; option on this field, that option\u0026rsquo;s value will be used. Otherwise, it\u0026rsquo;s deduced from the field\u0026rsquo;s name by converting it to camelCase.    options .google.protobuf.FieldOptions      Type    Name Description     TYPE_DOUBLE 0 is reserved for errors. Order is weird for historical reasons.   TYPE_FLOAT    TYPE_INT64 Not ZigZag encoded. Negative numbers take 10 bytes. Use TYPE_SINT64 if negative values are likely.   TYPE_UINT64    TYPE_INT32 Not ZigZag encoded. Negative numbers take 10 bytes. Use TYPE_SINT32 if negative values are likely.   TYPE_FIXED64    TYPE_FIXED32    TYPE_BOOL    TYPE_STRING    TYPE_GROUP Tag-delimited aggregate. Group type is deprecated and not supported in proto3. However, Proto3 implementations should still be able to parse the group wire format and treat group fields as unknown fields.   TYPE_MESSAGE    TYPE_BYTES New in version 2.   TYPE_UINT32    TYPE_ENUM    TYPE_SFIXED32    TYPE_SFIXED64    TYPE_SINT32    TYPE_SINT64     Label    Name Description     LABEL_OPTIONAL 0 is reserved for errors   LABEL_REQUIRED    LABEL_REPEATED     OneofDescriptorProto Describes a oneof.\n\u0026quot;name\u0026quot;: string \u0026quot;options\u0026quot;: .google.protobuf.OneofOptions     Field Type Description Default     name string     options .google.protobuf.OneofOptions      EnumDescriptorProto Describes an enum type.\n\u0026quot;name\u0026quot;: string \u0026quot;value\u0026quot;: []google.protobuf.EnumValueDescriptorProto \u0026quot;options\u0026quot;: .google.protobuf.EnumOptions     Field Type Description Default     name string     value []google.protobuf.EnumValueDescriptorProto     options .google.protobuf.EnumOptions      EnumValueDescriptorProto Describes a value within an enum.\n\u0026quot;name\u0026quot;: string \u0026quot;number\u0026quot;: int \u0026quot;options\u0026quot;: .google.protobuf.EnumValueOptions     Field Type Description Default     name string     number int     options .google.protobuf.EnumValueOptions      ServiceDescriptorProto Describes a service.\n\u0026quot;name\u0026quot;: string \u0026quot;method\u0026quot;: []google.protobuf.MethodDescriptorProto \u0026quot;options\u0026quot;: .google.protobuf.ServiceOptions     Field Type Description Default     name string     method []google.protobuf.MethodDescriptorProto     options .google.protobuf.ServiceOptions      MethodDescriptorProto Describes a method of a service.\n\u0026quot;name\u0026quot;: string \u0026quot;input_type\u0026quot;: string \u0026quot;output_type\u0026quot;: string \u0026quot;options\u0026quot;: .google.protobuf.MethodOptions \u0026quot;client_streaming\u0026quot;: bool \u0026quot;server_streaming\u0026quot;: bool     Field Type Description Default     name string     input_type string Input and output type names. These are resolved in the same way as FieldDescriptorProto.type_name, but must refer to a message type.    output_type string     options .google.protobuf.MethodOptions     client_streaming bool Identifies if client streams multiple client messages Default: false   server_streaming bool Identifies if server streams multiple server messages Default: false    FileOptions \u0026quot;java_package\u0026quot;: string \u0026quot;java_outer_classname\u0026quot;: string \u0026quot;java_multiple_files\u0026quot;: bool \u0026quot;java_generate_equals_and_hash\u0026quot;: bool \u0026quot;java_string_check_utf8\u0026quot;: bool \u0026quot;optimize_for\u0026quot;: .google.protobuf.FileOptions.OptimizeMode \u0026quot;go_package\u0026quot;: string \u0026quot;cc_generic_services\u0026quot;: bool \u0026quot;java_generic_services\u0026quot;: bool \u0026quot;py_generic_services\u0026quot;: bool \u0026quot;deprecated\u0026quot;: bool \u0026quot;cc_enable_arenas\u0026quot;: bool \u0026quot;objc_class_prefix\u0026quot;: string \u0026quot;csharp_namespace\u0026quot;: string \u0026quot;swift_prefix\u0026quot;: string \u0026quot;php_class_prefix\u0026quot;: string \u0026quot;uninterpreted_option\u0026quot;: []google.protobuf.UninterpretedOption     Field Type Description Default     java_package string Sets the Java package where classes generated from this .proto will be placed. By default, the proto package is used, but this is often inappropriate because proto packages do not normally start with backwards domain names.    java_outer_classname string If set, all the classes from the .proto file are wrapped in a single outer class with the given name. This applies to both Proto1 (equivalent to the old \u0026ldquo;\u0026ndash;one_java_file\u0026rdquo; option) and Proto2 (where a .proto always translates to a single class, but you may want to explicitly choose the class name).    java_multiple_files bool If set true, then the Java code generator will generate a separate .java file for each top-level message, enum, and service defined in the .proto file. Thus, these types will not be nested inside the outer class named by java_outer_classname. However, the outer class will still be generated to contain the file\u0026rsquo;s getDescriptor() method as well as any top-level extensions defined in the file. Default: false   java_generate_equals_and_hash bool This option does nothing.    java_string_check_utf8 bool If set true, then the Java2 code generator will generate code that throws an exception whenever an attempt is made to assign a non-UTF-8 byte sequence to a string field. Message reflection will do the same. However, an extension field still accepts non-UTF-8 byte sequences. This option has no effect on when used with the lite runtime. Default: false   optimize_for .google.protobuf.FileOptions.OptimizeMode  Default: SPEED   go_package string Sets the Go package where structs generated from this .proto will be placed. If omitted, the Go package will be derived from the following: - The basename of the package import path, if provided. - Otherwise, the package statement in the .proto file, if present. - Otherwise, the basename of the .proto file, without extension.    cc_generic_services bool Should generic services be generated in each language? \u0026ldquo;Generic\u0026rdquo; services are not specific to any particular RPC system. They are generated by the main code generators in each language (without additional plugins). Generic services were the only kind of service generation supported by early versions of google.protobuf. Generic services are now considered deprecated in favor of using plugins that generate code specific to your particular RPC system. Therefore, these default to false. Old code which depends on generic services should explicitly set them to true. Default: false   java_generic_services bool  Default: false   py_generic_services bool  Default: false   deprecated bool Is this file deprecated? Depending on the target platform, this can emit Deprecated annotations for everything in the file, or it will be completely ignored; in the very least, this is a formalization for deprecating files. Default: false   cc_enable_arenas bool Enables the use of arenas for the proto messages in this file. This applies only to generated classes for C++. Default: false   objc_class_prefix string Sets the objective c class prefix which is prepended to all objective c generated classes from this .proto. There is no default.    csharp_namespace string Namespace for generated classes; defaults to the package.    swift_prefix string By default Swift generators will take the proto package and CamelCase it replacing \u0026lsquo;.\u0026rsquo; with underscore and use that to prefix the types/symbols defined. When this options is provided, they will use this value instead to prefix the types/symbols defined.    php_class_prefix string Sets the php class prefix which is prepended to all php generated classes from this .proto. Default is empty.    uninterpreted_option []google.protobuf.UninterpretedOption The parser stores options it doesn\u0026rsquo;t recognize here. See above.     OptimizeMode Generated classes can be optimized for speed or code size.\n   Name Description     SPEED    CODE_SIZE etc.   LITE_RUNTIME     MessageOptions \u0026quot;message_set_wire_format\u0026quot;: bool \u0026quot;no_standard_descriptor_accessor\u0026quot;: bool \u0026quot;deprecated\u0026quot;: bool \u0026quot;map_entry\u0026quot;: bool \u0026quot;uninterpreted_option\u0026quot;: []google.protobuf.UninterpretedOption     Field Type Description Default     message_set_wire_format bool Set true to use the old proto1 MessageSet wire format for extensions. This is provided for backwards-compatibility with the MessageSet wire format. You should not use this for any other reason: It\u0026rsquo;s less efficient, has fewer features, and is more complicated. The message must be defined exactly as follows: message Foo { option message_set_wire_format = true; extensions 4 to max; } Note that the message cannot have any defined fields; MessageSets only have extensions. All extensions of your type must be singular messages; e.g. they cannot be int32s, enums, or repeated messages. Because this is an option, the above two restrictions are not enforced by the protocol compiler. Default: false   no_standard_descriptor_accessor bool Disables the generation of the standard \u0026ldquo;descriptor()\u0026rdquo; accessor, which can conflict with a field of the same name. This is meant to make migration from proto1 easier; new code should avoid fields named \u0026ldquo;descriptor\u0026rdquo;. Default: false   deprecated bool Is this message deprecated? Depending on the target platform, this can emit Deprecated annotations for the message, or it will be completely ignored; in the very least, this is a formalization for deprecating messages. Default: false   map_entry bool Whether the message is an automatically generated map entry type for the maps field. For maps fields: mapmap_field = 1; The parsed descriptor looks like: message MapFieldEntry { option map_entry = true; optional KeyType key = 1; optional ValueType value = 2; } repeated MapFieldEntry map_field = 1; Implementations may choose not to generate the map_entry=true message, but use a native map in the target language to hold the keys and values. The reflection APIs in such implementions still need to work as if the field is a repeated message field. NOTE: Do not set the option in .proto files. Always use the maps syntax instead. The option should only be implicitly set by the proto compiler parser.    uninterpreted_option []google.protobuf.UninterpretedOption The parser stores options it doesn\u0026rsquo;t recognize here. See above.     FieldOptions \u0026quot;ctype\u0026quot;: .google.protobuf.FieldOptions.CType \u0026quot;packed\u0026quot;: bool \u0026quot;jstype\u0026quot;: .google.protobuf.FieldOptions.JSType \u0026quot;lazy\u0026quot;: bool \u0026quot;deprecated\u0026quot;: bool \u0026quot;weak\u0026quot;: bool \u0026quot;uninterpreted_option\u0026quot;: []google.protobuf.UninterpretedOption     Field Type Description Default     ctype .google.protobuf.FieldOptions.CType The ctype option instructs the C++ code generator to use a different representation of the field than it normally would. See the specific options below. This option is not yet implemented in the open source release \u0026ndash; sorry, we\u0026rsquo;ll try to include it in a future version! Default: STRING   packed bool The packed option can be enabled for repeated primitive fields to enable a more efficient representation on the wire. Rather than repeatedly writing the tag and type for each element, the entire array is encoded as a single length-delimited blob. In proto3, only explicit setting it to false will avoid using packed encoding.    jstype .google.protobuf.FieldOptions.JSType The jstype option determines the JavaScript type used for values of the field. The option is permitted only for 64 bit integral and fixed types (int64, uint64, sint64, fixed64, sfixed64). By default these types are represented as JavaScript strings. This avoids loss of precision that can happen when a large value is converted to a floating point JavaScript numbers. Specifying JS_NUMBER for the jstype causes the generated JavaScript code to use the JavaScript \u0026ldquo;number\u0026rdquo; type instead of strings. This option is an enum to permit additional types to be added, e.g. goog.math.Integer. Default: JS_NORMAL   lazy bool Should this field be parsed lazily? Lazy applies only to message-type fields. It means that when the outer message is initially parsed, the inner message\u0026rsquo;s contents will not be parsed but instead stored in encoded form. The inner message will actually be parsed when it is first accessed. This is only a hint. Implementations are free to choose whether to use eager or lazy parsing regardless of the value of this option. However, setting this option true suggests that the protocol author believes that using lazy parsing on this field is worth the additional bookkeeping overhead typically needed to implement it. This option does not affect the public interface of any generated code; all method signatures remain the same. Furthermore, thread-safety of the interface is not affected by this option; const methods remain safe to call from multiple threads concurrently, while non-const methods continue to require exclusive access. Note that implementations may choose not to check required fields within a lazy sub-message. That is, calling IsInitialized() on the outer message may return true even if the inner message has missing required fields. This is necessary because otherwise the inner message would have to be parsed in order to perform the check, defeating the purpose of lazy parsing. An implementation which chooses not to check required fields must be consistent about it. That is, for any particular sub-message, the implementation must either always check its required fields, or never check its required fields, regardless of whether or not the message has been parsed. Default: false   deprecated bool Is this field deprecated? Depending on the target platform, this can emit Deprecated annotations for accessors, or it will be completely ignored; in the very least, this is a formalization for deprecating fields. Default: false   weak bool For Google-internal migration only. Do not use. Default: false   uninterpreted_option []google.protobuf.UninterpretedOption The parser stores options it doesn\u0026rsquo;t recognize here. See above.     CType    Name Description     STRING Default mode.   CORD    STRING_PIECE     JSType    Name Description     JS_NORMAL Use the default type.   JS_STRING Use JavaScript strings.   JS_NUMBER Use JavaScript numbers.    OneofOptions \u0026quot;uninterpreted_option\u0026quot;: []google.protobuf.UninterpretedOption     Field Type Description Default     uninterpreted_option []google.protobuf.UninterpretedOption The parser stores options it doesn\u0026rsquo;t recognize here. See above.     EnumOptions \u0026quot;allow_alias\u0026quot;: bool \u0026quot;deprecated\u0026quot;: bool \u0026quot;uninterpreted_option\u0026quot;: []google.protobuf.UninterpretedOption     Field Type Description Default     allow_alias bool Set this option to true to allow mapping different tag names to the same value.    deprecated bool Is this enum deprecated? Depending on the target platform, this can emit Deprecated annotations for the enum, or it will be completely ignored; in the very least, this is a formalization for deprecating enums. Default: false   uninterpreted_option []google.protobuf.UninterpretedOption The parser stores options it doesn\u0026rsquo;t recognize here. See above.     EnumValueOptions \u0026quot;deprecated\u0026quot;: bool \u0026quot;uninterpreted_option\u0026quot;: []google.protobuf.UninterpretedOption     Field Type Description Default     deprecated bool Is this enum value deprecated? Depending on the target platform, this can emit Deprecated annotations for the enum value, or it will be completely ignored; in the very least, this is a formalization for deprecating enum values. Default: false   uninterpreted_option []google.protobuf.UninterpretedOption The parser stores options it doesn\u0026rsquo;t recognize here. See above.     ServiceOptions \u0026quot;deprecated\u0026quot;: bool \u0026quot;uninterpreted_option\u0026quot;: []google.protobuf.UninterpretedOption     Field Type Description Default     deprecated bool Is this service deprecated? Depending on the target platform, this can emit Deprecated annotations for the service, or it will be completely ignored; in the very least, this is a formalization for deprecating services. Default: false   uninterpreted_option []google.protobuf.UninterpretedOption The parser stores options it doesn\u0026rsquo;t recognize here. See above.     MethodOptions \u0026quot;deprecated\u0026quot;: bool \u0026quot;idempotency_level\u0026quot;: .google.protobuf.MethodOptions.IdempotencyLevel \u0026quot;uninterpreted_option\u0026quot;: []google.protobuf.UninterpretedOption     Field Type Description Default     deprecated bool Is this method deprecated? Depending on the target platform, this can emit Deprecated annotations for the method, or it will be completely ignored; in the very least, this is a formalization for deprecating methods. Default: false   idempotency_level .google.protobuf.MethodOptions.IdempotencyLevel  Default: IDEMPOTENCY_UNKNOWN   uninterpreted_option []google.protobuf.UninterpretedOption The parser stores options it doesn\u0026rsquo;t recognize here. See above.     IdempotencyLevel Is this method side-effect-free (or safe in HTTP parlance), or idempotent, or neither? HTTP based RPC implementation may choose GET verb for safe methods, and PUT verb for idempotent methods instead of the default POST.\n   Name Description     IDEMPOTENCY_UNKNOWN    NO_SIDE_EFFECTS    IDEMPOTENT     UninterpretedOption A message representing a option the parser does not recognize. This only appears in options protos created by the compiler::Parser class. DescriptorPool resolves these when building Descriptor objects. Therefore, options protos in descriptor objects (e.g. returned by Descriptor::options(), or produced by Descriptor::CopyTo()) will never have UninterpretedOptions in them.\n\u0026quot;name\u0026quot;: []google.protobuf.UninterpretedOption.NamePart \u0026quot;identifier_value\u0026quot;: string \u0026quot;positive_int_value\u0026quot;: int \u0026quot;negative_int_value\u0026quot;: int \u0026quot;double_value\u0026quot;: float \u0026quot;string_value\u0026quot;: bytes \u0026quot;aggregate_value\u0026quot;: string     Field Type Description Default     name []google.protobuf.UninterpretedOption.NamePart     identifier_value string The value of the uninterpreted option, in whatever type the tokenizer identified it as during parsing. Exactly one of these should be set.    positive_int_value int     negative_int_value int     double_value float     string_value bytes     aggregate_value string      NamePart The name of the uninterpreted option. Each string represents a segment in a dot-separated name. is_extension is true iff a segment represents an extension (denoted with parentheses in options specs in .proto files). E.g.,{ [\u0026ldquo;foo\u0026rdquo;, false], [\u0026ldquo;bar.baz\u0026rdquo;, true], [\u0026ldquo;qux\u0026rdquo;, false] } represents \u0026ldquo;foo.(bar.baz).qux\u0026rdquo;.\n\u0026quot;name_part\u0026quot;: string \u0026quot;is_extension\u0026quot;: bool     Field Type Description Default     name_part string     is_extension bool      SourceCodeInfo Encapsulates information about the original source file from which a FileDescriptorProto was generated.\n\u0026quot;location\u0026quot;: []google.protobuf.SourceCodeInfo.Location     Field Type Description Default     location []google.protobuf.SourceCodeInfo.Location A Location identifies a piece of source code in a .proto file which corresponds to a particular definition. This information is intended to be useful to IDEs, code indexers, documentation generators, and similar tools. For example, say we have a file like: message Foo { optional string foo = 1; } Let\u0026rsquo;s look at just the field definition: optional string foo = 1; ^ ^^ ^^ ^ ^^^ a bc de f ghi We have the following locations: span path represents [a,i) [ 4, 0, 2, 0 ] The whole field definition. [a,b) [ 4, 0, 2, 0, 4 ] The label (optional). [c,d) [ 4, 0, 2, 0, 5 ] The type (string). [e,f) [ 4, 0, 2, 0, 1 ] The name (foo). [g,h) [ 4, 0, 2, 0, 3 ] The number (1). Notes: - A location may refer to a repeated field itself (i.e. not to any particular index within it). This is used whenever a set of elements are logically enclosed in a single code segment. For example, an entire extend block (possibly containing multiple extension definitions) will have an outer location whose path refers to the \u0026ldquo;extensions\u0026rdquo; repeated field without an index. - Multiple locations may have the same path. This happens when a single logical declaration is spread out across multiple places. The most obvious example is the \u0026ldquo;extend\u0026rdquo; block again \u0026ndash; there may be multiple extend blocks in the same scope, each of which will have the same path. - A location\u0026rsquo;s span is not always a subset of its parent\u0026rsquo;s span. For example, the \u0026ldquo;extendee\u0026rdquo; of an extension declaration appears at the beginning of the \u0026ldquo;extend\u0026rdquo; block and is shared by all extensions within the block. - Just because a location\u0026rsquo;s span is a subset of some other location\u0026rsquo;s span does not mean that it is a descendent. For example, a \u0026ldquo;group\u0026rdquo; defines both a type and a field in a single declaration. Thus, the locations corresponding to the type and field and their components will overlap. - Code which tries to interpret locations should probably be designed to ignore those that it doesn\u0026rsquo;t understand, as more types of locations could be recorded in the future.     Location \u0026quot;path\u0026quot;: []int \u0026quot;span\u0026quot;: []int \u0026quot;leading_comments\u0026quot;: string \u0026quot;trailing_comments\u0026quot;: string \u0026quot;leading_detached_comments\u0026quot;: []string     Field Type Description Default     path []int Identifies which part of the FileDescriptorProto was defined at this location. Each element is a field number or an index. They form a path from the root FileDescriptorProto to the place where the definition. For example, this path: [ 4, 3, 2, 7, 1 ] refers to: file.message_type(3) // 4, 3 .field(7) // 2, 7 .name() // 1 This is because FileDescriptorProto.message_type has field number 4: repeated DescriptorProto message_type = 4; and DescriptorProto.field has field number 2: repeated FieldDescriptorProto field = 2; and FieldDescriptorProto.name has field number 1: optional string name = 1; Thus, the above path gives the location of a field name. If we removed the last element: [ 4, 3, 2, 7 ] this path refers to the whole field declaration (from the beginning of the label to the terminating semicolon).    span []int Always has exactly three or four elements: start line, start column, end line (optional, otherwise assumed same as start line), end column. These are packed into a single field for efficiency. Note that line and column numbers are zero-based \u0026ndash; typically you will want to add 1 to each before displaying to a user.    leading_comments string If this SourceCodeInfo represents a complete declaration, these are any comments appearing before and after the declaration which appear to be attached to the declaration. A series of line comments appearing on consecutive lines, with no other tokens appearing on those lines, will be treated as a single comment. leading_detached_comments will keep paragraphs of comments that appear before (but not connected to) the current element. Each paragraph, separated by empty lines, will be one comment element in the repeated field. Only the comment content is provided; comment markers (e.g. //) are stripped out. For block comments, leading whitespace and an asterisk will be stripped from the beginning of each line other than the first. Newlines are included in the output. Examples: optional int32 foo = 1; // Comment attached to foo. // Comment attached to bar. optional int32 bar = 2; optional string baz = 3; // Comment attached to baz. // Another line attached to baz. // Comment attached to qux. // // Another line attached to qux. optional double qux = 4; // Detached comment for corge. This is not leading or trailing comments // to qux or corge because there are blank lines separating it from // both. // Detached comment for corge paragraph 2. optional string corge = 5; /* Block comment attached * to corge. Leading asterisks * will be removed. / / Block comment attached to * grault. */ optional int32 grault = 6; // ignored detached comments.    trailing_comments string     leading_detached_comments []string      GeneratedCodeInfo Describes the relationship between generated code and its original source file. A GeneratedCodeInfo message is associated with only one generated source file, but may contain references to different source .proto files.\n\u0026quot;annotation\u0026quot;: []google.protobuf.GeneratedCodeInfo.Annotation     Field Type Description Default     annotation []google.protobuf.GeneratedCodeInfo.Annotation An Annotation connects some span of text in generated code to an element of its generating .proto file.     Annotation \u0026quot;path\u0026quot;: []int \u0026quot;source_file\u0026quot;: string \u0026quot;begin\u0026quot;: int \u0026quot;end\u0026quot;: int     Field Type Description Default     path []int Identifies the element in the original source .proto file. This field is formatted the same as SourceCodeInfo.Location.path.    source_file string Identifies the filesystem path to the original source .proto.    begin int Identifies the starting offset in bytes in the generated code that relates to the identified object.    end int Identifies the ending offset in bytes in the generated code that relates to the identified offset. The end offset should be one past the last relevant byte (so the length of the text = end - begin).      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/google/protobuf/descriptor.proto.sk/",
	"title": "descriptor.proto",
	"tags": [],
	"description": "",
	"content": " Package: google.protobuf Protocol Buffers - Google\u0026rsquo;s data interchange format Copyright 2008 Google Inc. All rights reserved. https://developers.google.com/protocol-buffers/\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n* Redistributions of source code must retain the above copyright  notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026ldquo;AS IS\u0026rdquo; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nAuthor: kenton@google.com (Kenton Varda) Based on original Protocol Buffers design by Sanjay Ghemawat, Jeff Dean, and others.\nThe messages in this file describe the definitions found in .proto files. A valid .proto file can be translated directly to a FileDescriptorProto without any other information (e.g. without reading its imports).\nTypes:  FileDescriptorSet FileDescriptorProto DescriptorProto ExtensionRange ReservedRange FieldDescriptorProto Type Label OneofDescriptorProto EnumDescriptorProto EnumValueDescriptorProto ServiceDescriptorProto MethodDescriptorProto FileOptions OptimizeMode MessageOptions FieldOptions CType JSType OneofOptions EnumOptions EnumValueOptions ServiceOptions MethodOptions IdempotencyLevel UninterpretedOption NamePart SourceCodeInfo Location GeneratedCodeInfo Annotation   Source File: google/protobuf/descriptor.proto FileDescriptorSet The protocol compiler can output a FileDescriptorSet containing the .proto files it parses.\n\u0026quot;file\u0026quot;: []google.protobuf.FileDescriptorProto     Field Type Description Default     file []google.protobuf.FileDescriptorProto      FileDescriptorProto Describes a complete .proto file.\n\u0026quot;name\u0026quot;: string \u0026quot;package\u0026quot;: string \u0026quot;dependency\u0026quot;: []string \u0026quot;public_dependency\u0026quot;: []int \u0026quot;weak_dependency\u0026quot;: []int \u0026quot;message_type\u0026quot;: []google.protobuf.DescriptorProto \u0026quot;enum_type\u0026quot;: []google.protobuf.EnumDescriptorProto \u0026quot;service\u0026quot;: []google.protobuf.ServiceDescriptorProto \u0026quot;extension\u0026quot;: []google.protobuf.FieldDescriptorProto \u0026quot;options\u0026quot;: .google.protobuf.FileOptions \u0026quot;source_code_info\u0026quot;: .google.protobuf.SourceCodeInfo \u0026quot;syntax\u0026quot;: string     Field Type Description Default     name string     package string     dependency []string Names of files imported by this file.    public_dependency []int Indexes of the public imported files in the dependency list above.    weak_dependency []int Indexes of the weak imported files in the dependency list. For Google-internal migration only. Do not use.    message_type []google.protobuf.DescriptorProto All top-level definitions in this file.    enum_type []google.protobuf.EnumDescriptorProto     service []google.protobuf.ServiceDescriptorProto     extension []google.protobuf.FieldDescriptorProto     options .google.protobuf.FileOptions     source_code_info .google.protobuf.SourceCodeInfo This field contains optional information about the original source code. You may safely remove this entire field without harming runtime functionality of the descriptors \u0026ndash; the information is needed only by development tools.    syntax string The syntax of the proto file. The supported values are \u0026ldquo;proto2\u0026rdquo; and \u0026ldquo;proto3\u0026rdquo;.     DescriptorProto Describes a message type.\n\u0026quot;name\u0026quot;: string \u0026quot;field\u0026quot;: []google.protobuf.FieldDescriptorProto \u0026quot;extension\u0026quot;: []google.protobuf.FieldDescriptorProto \u0026quot;nested_type\u0026quot;: []google.protobuf.DescriptorProto \u0026quot;enum_type\u0026quot;: []google.protobuf.EnumDescriptorProto \u0026quot;extension_range\u0026quot;: []google.protobuf.DescriptorProto.ExtensionRange \u0026quot;oneof_decl\u0026quot;: []google.protobuf.OneofDescriptorProto \u0026quot;options\u0026quot;: .google.protobuf.MessageOptions \u0026quot;reserved_range\u0026quot;: []google.protobuf.DescriptorProto.ReservedRange \u0026quot;reserved_name\u0026quot;: []string     Field Type Description Default     name string     field []google.protobuf.FieldDescriptorProto     extension []google.protobuf.FieldDescriptorProto     nested_type []google.protobuf.DescriptorProto     enum_type []google.protobuf.EnumDescriptorProto     extension_range []google.protobuf.DescriptorProto.ExtensionRange     oneof_decl []google.protobuf.OneofDescriptorProto     options .google.protobuf.MessageOptions     reserved_range []google.protobuf.DescriptorProto.ReservedRange     reserved_name []string Reserved field names, which may not be used by fields in the same message. A given name may only be reserved once.     ExtensionRange \u0026quot;start\u0026quot;: int \u0026quot;end\u0026quot;: int     Field Type Description Default     start int     end int      ReservedRange Range of reserved tag numbers. Reserved tag numbers may not be used by fields or extension ranges in the same message. Reserved ranges may not overlap.\n\u0026quot;start\u0026quot;: int \u0026quot;end\u0026quot;: int     Field Type Description Default     start int     end int      FieldDescriptorProto Describes a field within a message.\n\u0026quot;name\u0026quot;: string \u0026quot;number\u0026quot;: int \u0026quot;label\u0026quot;: .google.protobuf.FieldDescriptorProto.Label \u0026quot;type\u0026quot;: .google.protobuf.FieldDescriptorProto.Type \u0026quot;type_name\u0026quot;: string \u0026quot;extendee\u0026quot;: string \u0026quot;default_value\u0026quot;: string \u0026quot;oneof_index\u0026quot;: int \u0026quot;json_name\u0026quot;: string \u0026quot;options\u0026quot;: .google.protobuf.FieldOptions     Field Type Description Default     name string     number int     label .google.protobuf.FieldDescriptorProto.Label     type .google.protobuf.FieldDescriptorProto.Type If type_name is set, this need not be set. If both this and type_name are set, this must be one of TYPE_ENUM, TYPE_MESSAGE or TYPE_GROUP.    type_name string For message and enum types, this is the name of the type. If the name starts with a \u0026lsquo;.\u0026rsquo;, it is fully-qualified. Otherwise, C++-like scoping rules are used to find the type (i.e. first the nested types within this message are searched, then within the parent, on up to the root namespace).    extendee string For extensions, this is the name of the type being extended. It is resolved in the same manner as type_name.    default_value string For numeric types, contains the original text representation of the value. For booleans, \u0026ldquo;true\u0026rdquo; or \u0026ldquo;false\u0026rdquo;. For strings, contains the default text contents (not escaped in any way). For bytes, contains the C escaped value. All bytes \u0026gt;= 128 are escaped. TODO(kenton): Base-64 encode?    oneof_index int If set, gives the index of a oneof in the containing type\u0026rsquo;s oneof_decl list. This field is a member of that oneof.    json_name string JSON name of this field. The value is set by protocol compiler. If the user has set a \u0026ldquo;json_name\u0026rdquo; option on this field, that option\u0026rsquo;s value will be used. Otherwise, it\u0026rsquo;s deduced from the field\u0026rsquo;s name by converting it to camelCase.    options .google.protobuf.FieldOptions      Type    Name Description     TYPE_DOUBLE 0 is reserved for errors. Order is weird for historical reasons.   TYPE_FLOAT    TYPE_INT64 Not ZigZag encoded. Negative numbers take 10 bytes. Use TYPE_SINT64 if negative values are likely.   TYPE_UINT64    TYPE_INT32 Not ZigZag encoded. Negative numbers take 10 bytes. Use TYPE_SINT32 if negative values are likely.   TYPE_FIXED64    TYPE_FIXED32    TYPE_BOOL    TYPE_STRING    TYPE_GROUP Tag-delimited aggregate. Group type is deprecated and not supported in proto3. However, Proto3 implementations should still be able to parse the group wire format and treat group fields as unknown fields.   TYPE_MESSAGE    TYPE_BYTES New in version 2.   TYPE_UINT32    TYPE_ENUM    TYPE_SFIXED32    TYPE_SFIXED64    TYPE_SINT32    TYPE_SINT64     Label    Name Description     LABEL_OPTIONAL 0 is reserved for errors   LABEL_REQUIRED    LABEL_REPEATED     OneofDescriptorProto Describes a oneof.\n\u0026quot;name\u0026quot;: string \u0026quot;options\u0026quot;: .google.protobuf.OneofOptions     Field Type Description Default     name string     options .google.protobuf.OneofOptions      EnumDescriptorProto Describes an enum type.\n\u0026quot;name\u0026quot;: string \u0026quot;value\u0026quot;: []google.protobuf.EnumValueDescriptorProto \u0026quot;options\u0026quot;: .google.protobuf.EnumOptions     Field Type Description Default     name string     value []google.protobuf.EnumValueDescriptorProto     options .google.protobuf.EnumOptions      EnumValueDescriptorProto Describes a value within an enum.\n\u0026quot;name\u0026quot;: string \u0026quot;number\u0026quot;: int \u0026quot;options\u0026quot;: .google.protobuf.EnumValueOptions     Field Type Description Default     name string     number int     options .google.protobuf.EnumValueOptions      ServiceDescriptorProto Describes a service.\n\u0026quot;name\u0026quot;: string \u0026quot;method\u0026quot;: []google.protobuf.MethodDescriptorProto \u0026quot;options\u0026quot;: .google.protobuf.ServiceOptions     Field Type Description Default     name string     method []google.protobuf.MethodDescriptorProto     options .google.protobuf.ServiceOptions      MethodDescriptorProto Describes a method of a service.\n\u0026quot;name\u0026quot;: string \u0026quot;input_type\u0026quot;: string \u0026quot;output_type\u0026quot;: string \u0026quot;options\u0026quot;: .google.protobuf.MethodOptions \u0026quot;client_streaming\u0026quot;: bool \u0026quot;server_streaming\u0026quot;: bool     Field Type Description Default     name string     input_type string Input and output type names. These are resolved in the same way as FieldDescriptorProto.type_name, but must refer to a message type.    output_type string     options .google.protobuf.MethodOptions     client_streaming bool Identifies if client streams multiple client messages Default: false   server_streaming bool Identifies if server streams multiple server messages Default: false    FileOptions \u0026quot;java_package\u0026quot;: string \u0026quot;java_outer_classname\u0026quot;: string \u0026quot;java_multiple_files\u0026quot;: bool \u0026quot;java_generate_equals_and_hash\u0026quot;: bool \u0026quot;java_string_check_utf8\u0026quot;: bool \u0026quot;optimize_for\u0026quot;: .google.protobuf.FileOptions.OptimizeMode \u0026quot;go_package\u0026quot;: string \u0026quot;cc_generic_services\u0026quot;: bool \u0026quot;java_generic_services\u0026quot;: bool \u0026quot;py_generic_services\u0026quot;: bool \u0026quot;deprecated\u0026quot;: bool \u0026quot;cc_enable_arenas\u0026quot;: bool \u0026quot;objc_class_prefix\u0026quot;: string \u0026quot;csharp_namespace\u0026quot;: string \u0026quot;swift_prefix\u0026quot;: string \u0026quot;php_class_prefix\u0026quot;: string \u0026quot;uninterpreted_option\u0026quot;: []google.protobuf.UninterpretedOption     Field Type Description Default     java_package string Sets the Java package where classes generated from this .proto will be placed. By default, the proto package is used, but this is often inappropriate because proto packages do not normally start with backwards domain names.    java_outer_classname string If set, all the classes from the .proto file are wrapped in a single outer class with the given name. This applies to both Proto1 (equivalent to the old \u0026ldquo;\u0026ndash;one_java_file\u0026rdquo; option) and Proto2 (where a .proto always translates to a single class, but you may want to explicitly choose the class name).    java_multiple_files bool If set true, then the Java code generator will generate a separate .java file for each top-level message, enum, and service defined in the .proto file. Thus, these types will not be nested inside the outer class named by java_outer_classname. However, the outer class will still be generated to contain the file\u0026rsquo;s getDescriptor() method as well as any top-level extensions defined in the file. Default: false   java_generate_equals_and_hash bool This option does nothing.    java_string_check_utf8 bool If set true, then the Java2 code generator will generate code that throws an exception whenever an attempt is made to assign a non-UTF-8 byte sequence to a string field. Message reflection will do the same. However, an extension field still accepts non-UTF-8 byte sequences. This option has no effect on when used with the lite runtime. Default: false   optimize_for .google.protobuf.FileOptions.OptimizeMode  Default: SPEED   go_package string Sets the Go package where structs generated from this .proto will be placed. If omitted, the Go package will be derived from the following: - The basename of the package import path, if provided. - Otherwise, the package statement in the .proto file, if present. - Otherwise, the basename of the .proto file, without extension.    cc_generic_services bool Should generic services be generated in each language? \u0026ldquo;Generic\u0026rdquo; services are not specific to any particular RPC system. They are generated by the main code generators in each language (without additional plugins). Generic services were the only kind of service generation supported by early versions of google.protobuf. Generic services are now considered deprecated in favor of using plugins that generate code specific to your particular RPC system. Therefore, these default to false. Old code which depends on generic services should explicitly set them to true. Default: false   java_generic_services bool  Default: false   py_generic_services bool  Default: false   deprecated bool Is this file deprecated? Depending on the target platform, this can emit Deprecated annotations for everything in the file, or it will be completely ignored; in the very least, this is a formalization for deprecating files. Default: false   cc_enable_arenas bool Enables the use of arenas for the proto messages in this file. This applies only to generated classes for C++. Default: false   objc_class_prefix string Sets the objective c class prefix which is prepended to all objective c generated classes from this .proto. There is no default.    csharp_namespace string Namespace for generated classes; defaults to the package.    swift_prefix string By default Swift generators will take the proto package and CamelCase it replacing \u0026lsquo;.\u0026rsquo; with underscore and use that to prefix the types/symbols defined. When this options is provided, they will use this value instead to prefix the types/symbols defined.    php_class_prefix string Sets the php class prefix which is prepended to all php generated classes from this .proto. Default is empty.    uninterpreted_option []google.protobuf.UninterpretedOption The parser stores options it doesn\u0026rsquo;t recognize here. See above.     OptimizeMode Generated classes can be optimized for speed or code size.\n   Name Description     SPEED    CODE_SIZE etc.   LITE_RUNTIME     MessageOptions \u0026quot;message_set_wire_format\u0026quot;: bool \u0026quot;no_standard_descriptor_accessor\u0026quot;: bool \u0026quot;deprecated\u0026quot;: bool \u0026quot;map_entry\u0026quot;: bool \u0026quot;uninterpreted_option\u0026quot;: []google.protobuf.UninterpretedOption     Field Type Description Default     message_set_wire_format bool Set true to use the old proto1 MessageSet wire format for extensions. This is provided for backwards-compatibility with the MessageSet wire format. You should not use this for any other reason: It\u0026rsquo;s less efficient, has fewer features, and is more complicated. The message must be defined exactly as follows: message Foo { option message_set_wire_format = true; extensions 4 to max; } Note that the message cannot have any defined fields; MessageSets only have extensions. All extensions of your type must be singular messages; e.g. they cannot be int32s, enums, or repeated messages. Because this is an option, the above two restrictions are not enforced by the protocol compiler. Default: false   no_standard_descriptor_accessor bool Disables the generation of the standard \u0026ldquo;descriptor()\u0026rdquo; accessor, which can conflict with a field of the same name. This is meant to make migration from proto1 easier; new code should avoid fields named \u0026ldquo;descriptor\u0026rdquo;. Default: false   deprecated bool Is this message deprecated? Depending on the target platform, this can emit Deprecated annotations for the message, or it will be completely ignored; in the very least, this is a formalization for deprecating messages. Default: false   map_entry bool Whether the message is an automatically generated map entry type for the maps field. For maps fields: mapmap_field = 1; The parsed descriptor looks like: message MapFieldEntry { option map_entry = true; optional KeyType key = 1; optional ValueType value = 2; } repeated MapFieldEntry map_field = 1; Implementations may choose not to generate the map_entry=true message, but use a native map in the target language to hold the keys and values. The reflection APIs in such implementions still need to work as if the field is a repeated message field. NOTE: Do not set the option in .proto files. Always use the maps syntax instead. The option should only be implicitly set by the proto compiler parser.    uninterpreted_option []google.protobuf.UninterpretedOption The parser stores options it doesn\u0026rsquo;t recognize here. See above.     FieldOptions \u0026quot;ctype\u0026quot;: .google.protobuf.FieldOptions.CType \u0026quot;packed\u0026quot;: bool \u0026quot;jstype\u0026quot;: .google.protobuf.FieldOptions.JSType \u0026quot;lazy\u0026quot;: bool \u0026quot;deprecated\u0026quot;: bool \u0026quot;weak\u0026quot;: bool \u0026quot;uninterpreted_option\u0026quot;: []google.protobuf.UninterpretedOption     Field Type Description Default     ctype .google.protobuf.FieldOptions.CType The ctype option instructs the C++ code generator to use a different representation of the field than it normally would. See the specific options below. This option is not yet implemented in the open source release \u0026ndash; sorry, we\u0026rsquo;ll try to include it in a future version! Default: STRING   packed bool The packed option can be enabled for repeated primitive fields to enable a more efficient representation on the wire. Rather than repeatedly writing the tag and type for each element, the entire array is encoded as a single length-delimited blob. In proto3, only explicit setting it to false will avoid using packed encoding.    jstype .google.protobuf.FieldOptions.JSType The jstype option determines the JavaScript type used for values of the field. The option is permitted only for 64 bit integral and fixed types (int64, uint64, sint64, fixed64, sfixed64). By default these types are represented as JavaScript strings. This avoids loss of precision that can happen when a large value is converted to a floating point JavaScript numbers. Specifying JS_NUMBER for the jstype causes the generated JavaScript code to use the JavaScript \u0026ldquo;number\u0026rdquo; type instead of strings. This option is an enum to permit additional types to be added, e.g. goog.math.Integer. Default: JS_NORMAL   lazy bool Should this field be parsed lazily? Lazy applies only to message-type fields. It means that when the outer message is initially parsed, the inner message\u0026rsquo;s contents will not be parsed but instead stored in encoded form. The inner message will actually be parsed when it is first accessed. This is only a hint. Implementations are free to choose whether to use eager or lazy parsing regardless of the value of this option. However, setting this option true suggests that the protocol author believes that using lazy parsing on this field is worth the additional bookkeeping overhead typically needed to implement it. This option does not affect the public interface of any generated code; all method signatures remain the same. Furthermore, thread-safety of the interface is not affected by this option; const methods remain safe to call from multiple threads concurrently, while non-const methods continue to require exclusive access. Note that implementations may choose not to check required fields within a lazy sub-message. That is, calling IsInitialized() on the outer message may return true even if the inner message has missing required fields. This is necessary because otherwise the inner message would have to be parsed in order to perform the check, defeating the purpose of lazy parsing. An implementation which chooses not to check required fields must be consistent about it. That is, for any particular sub-message, the implementation must either always check its required fields, or never check its required fields, regardless of whether or not the message has been parsed. Default: false   deprecated bool Is this field deprecated? Depending on the target platform, this can emit Deprecated annotations for accessors, or it will be completely ignored; in the very least, this is a formalization for deprecating fields. Default: false   weak bool For Google-internal migration only. Do not use. Default: false   uninterpreted_option []google.protobuf.UninterpretedOption The parser stores options it doesn\u0026rsquo;t recognize here. See above.     CType    Name Description     STRING Default mode.   CORD    STRING_PIECE     JSType    Name Description     JS_NORMAL Use the default type.   JS_STRING Use JavaScript strings.   JS_NUMBER Use JavaScript numbers.    OneofOptions \u0026quot;uninterpreted_option\u0026quot;: []google.protobuf.UninterpretedOption     Field Type Description Default     uninterpreted_option []google.protobuf.UninterpretedOption The parser stores options it doesn\u0026rsquo;t recognize here. See above.     EnumOptions \u0026quot;allow_alias\u0026quot;: bool \u0026quot;deprecated\u0026quot;: bool \u0026quot;uninterpreted_option\u0026quot;: []google.protobuf.UninterpretedOption     Field Type Description Default     allow_alias bool Set this option to true to allow mapping different tag names to the same value.    deprecated bool Is this enum deprecated? Depending on the target platform, this can emit Deprecated annotations for the enum, or it will be completely ignored; in the very least, this is a formalization for deprecating enums. Default: false   uninterpreted_option []google.protobuf.UninterpretedOption The parser stores options it doesn\u0026rsquo;t recognize here. See above.     EnumValueOptions \u0026quot;deprecated\u0026quot;: bool \u0026quot;uninterpreted_option\u0026quot;: []google.protobuf.UninterpretedOption     Field Type Description Default     deprecated bool Is this enum value deprecated? Depending on the target platform, this can emit Deprecated annotations for the enum value, or it will be completely ignored; in the very least, this is a formalization for deprecating enum values. Default: false   uninterpreted_option []google.protobuf.UninterpretedOption The parser stores options it doesn\u0026rsquo;t recognize here. See above.     ServiceOptions \u0026quot;deprecated\u0026quot;: bool \u0026quot;uninterpreted_option\u0026quot;: []google.protobuf.UninterpretedOption     Field Type Description Default     deprecated bool Is this service deprecated? Depending on the target platform, this can emit Deprecated annotations for the service, or it will be completely ignored; in the very least, this is a formalization for deprecating services. Default: false   uninterpreted_option []google.protobuf.UninterpretedOption The parser stores options it doesn\u0026rsquo;t recognize here. See above.     MethodOptions \u0026quot;deprecated\u0026quot;: bool \u0026quot;idempotency_level\u0026quot;: .google.protobuf.MethodOptions.IdempotencyLevel \u0026quot;uninterpreted_option\u0026quot;: []google.protobuf.UninterpretedOption     Field Type Description Default     deprecated bool Is this method deprecated? Depending on the target platform, this can emit Deprecated annotations for the method, or it will be completely ignored; in the very least, this is a formalization for deprecating methods. Default: false   idempotency_level .google.protobuf.MethodOptions.IdempotencyLevel  Default: IDEMPOTENCY_UNKNOWN   uninterpreted_option []google.protobuf.UninterpretedOption The parser stores options it doesn\u0026rsquo;t recognize here. See above.     IdempotencyLevel Is this method side-effect-free (or safe in HTTP parlance), or idempotent, or neither? HTTP based RPC implementation may choose GET verb for safe methods, and PUT verb for idempotent methods instead of the default POST.\n   Name Description     IDEMPOTENCY_UNKNOWN    NO_SIDE_EFFECTS    IDEMPOTENT     UninterpretedOption A message representing a option the parser does not recognize. This only appears in options protos created by the compiler::Parser class. DescriptorPool resolves these when building Descriptor objects. Therefore, options protos in descriptor objects (e.g. returned by Descriptor::options(), or produced by Descriptor::CopyTo()) will never have UninterpretedOptions in them.\n\u0026quot;name\u0026quot;: []google.protobuf.UninterpretedOption.NamePart \u0026quot;identifier_value\u0026quot;: string \u0026quot;positive_int_value\u0026quot;: int \u0026quot;negative_int_value\u0026quot;: int \u0026quot;double_value\u0026quot;: float \u0026quot;string_value\u0026quot;: bytes \u0026quot;aggregate_value\u0026quot;: string     Field Type Description Default     name []google.protobuf.UninterpretedOption.NamePart     identifier_value string The value of the uninterpreted option, in whatever type the tokenizer identified it as during parsing. Exactly one of these should be set.    positive_int_value int     negative_int_value int     double_value float     string_value bytes     aggregate_value string      NamePart The name of the uninterpreted option. Each string represents a segment in a dot-separated name. is_extension is true iff a segment represents an extension (denoted with parentheses in options specs in .proto files). E.g.,{ [\u0026ldquo;foo\u0026rdquo;, false], [\u0026ldquo;bar.baz\u0026rdquo;, true], [\u0026ldquo;qux\u0026rdquo;, false] } represents \u0026ldquo;foo.(bar.baz).qux\u0026rdquo;.\n\u0026quot;name_part\u0026quot;: string \u0026quot;is_extension\u0026quot;: bool     Field Type Description Default     name_part string     is_extension bool      SourceCodeInfo Encapsulates information about the original source file from which a FileDescriptorProto was generated.\n\u0026quot;location\u0026quot;: []google.protobuf.SourceCodeInfo.Location     Field Type Description Default     location []google.protobuf.SourceCodeInfo.Location A Location identifies a piece of source code in a .proto file which corresponds to a particular definition. This information is intended to be useful to IDEs, code indexers, documentation generators, and similar tools. For example, say we have a file like: message Foo { optional string foo = 1; } Let\u0026rsquo;s look at just the field definition: optional string foo = 1; ^ ^^ ^^ ^ ^^^ a bc de f ghi We have the following locations: span path represents [a,i) [ 4, 0, 2, 0 ] The whole field definition. [a,b) [ 4, 0, 2, 0, 4 ] The label (optional). [c,d) [ 4, 0, 2, 0, 5 ] The type (string). [e,f) [ 4, 0, 2, 0, 1 ] The name (foo). [g,h) [ 4, 0, 2, 0, 3 ] The number (1). Notes: - A location may refer to a repeated field itself (i.e. not to any particular index within it). This is used whenever a set of elements are logically enclosed in a single code segment. For example, an entire extend block (possibly containing multiple extension definitions) will have an outer location whose path refers to the \u0026ldquo;extensions\u0026rdquo; repeated field without an index. - Multiple locations may have the same path. This happens when a single logical declaration is spread out across multiple places. The most obvious example is the \u0026ldquo;extend\u0026rdquo; block again \u0026ndash; there may be multiple extend blocks in the same scope, each of which will have the same path. - A location\u0026rsquo;s span is not always a subset of its parent\u0026rsquo;s span. For example, the \u0026ldquo;extendee\u0026rdquo; of an extension declaration appears at the beginning of the \u0026ldquo;extend\u0026rdquo; block and is shared by all extensions within the block. - Just because a location\u0026rsquo;s span is a subset of some other location\u0026rsquo;s span does not mean that it is a descendent. For example, a \u0026ldquo;group\u0026rdquo; defines both a type and a field in a single declaration. Thus, the locations corresponding to the type and field and their components will overlap. - Code which tries to interpret locations should probably be designed to ignore those that it doesn\u0026rsquo;t understand, as more types of locations could be recorded in the future.     Location \u0026quot;path\u0026quot;: []int \u0026quot;span\u0026quot;: []int \u0026quot;leading_comments\u0026quot;: string \u0026quot;trailing_comments\u0026quot;: string \u0026quot;leading_detached_comments\u0026quot;: []string     Field Type Description Default     path []int Identifies which part of the FileDescriptorProto was defined at this location. Each element is a field number or an index. They form a path from the root FileDescriptorProto to the place where the definition. For example, this path: [ 4, 3, 2, 7, 1 ] refers to: file.message_type(3) // 4, 3 .field(7) // 2, 7 .name() // 1 This is because FileDescriptorProto.message_type has field number 4: repeated DescriptorProto message_type = 4; and DescriptorProto.field has field number 2: repeated FieldDescriptorProto field = 2; and FieldDescriptorProto.name has field number 1: optional string name = 1; Thus, the above path gives the location of a field name. If we removed the last element: [ 4, 3, 2, 7 ] this path refers to the whole field declaration (from the beginning of the label to the terminating semicolon).    span []int Always has exactly three or four elements: start line, start column, end line (optional, otherwise assumed same as start line), end column. These are packed into a single field for efficiency. Note that line and column numbers are zero-based \u0026ndash; typically you will want to add 1 to each before displaying to a user.    leading_comments string If this SourceCodeInfo represents a complete declaration, these are any comments appearing before and after the declaration which appear to be attached to the declaration. A series of line comments appearing on consecutive lines, with no other tokens appearing on those lines, will be treated as a single comment. leading_detached_comments will keep paragraphs of comments that appear before (but not connected to) the current element. Each paragraph, separated by empty lines, will be one comment element in the repeated field. Only the comment content is provided; comment markers (e.g. //) are stripped out. For block comments, leading whitespace and an asterisk will be stripped from the beginning of each line other than the first. Newlines are included in the output. Examples: optional int32 foo = 1; // Comment attached to foo. // Comment attached to bar. optional int32 bar = 2; optional string baz = 3; // Comment attached to baz. // Another line attached to baz. // Comment attached to qux. // // Another line attached to qux. optional double qux = 4; // Detached comment for corge. This is not leading or trailing comments // to qux or corge because there are blank lines separating it from // both. // Detached comment for corge paragraph 2. optional string corge = 5; /* Block comment attached * to corge. Leading asterisks * will be removed. / / Block comment attached to * grault. */ optional int32 grault = 6; // ignored detached comments.    trailing_comments string     leading_detached_comments []string      GeneratedCodeInfo Describes the relationship between generated code and its original source file. A GeneratedCodeInfo message is associated with only one generated source file, but may contain references to different source .proto files.\n\u0026quot;annotation\u0026quot;: []google.protobuf.GeneratedCodeInfo.Annotation     Field Type Description Default     annotation []google.protobuf.GeneratedCodeInfo.Annotation An Annotation connects some span of text in generated code to an element of its generating .proto file.     Annotation \u0026quot;path\u0026quot;: []int \u0026quot;source_file\u0026quot;: string \u0026quot;begin\u0026quot;: int \u0026quot;end\u0026quot;: int     Field Type Description Default     path []int Identifies the element in the original source .proto file. This field is formatted the same as SourceCodeInfo.Location.path.    source_file string Identifies the filesystem path to the original source .proto.    begin int Identifies the starting offset in bytes in the generated code that relates to the identified object.    end int Identifies the ending offset in bytes in the generated code that relates to the identified offset. The end offset should be one past the last relevant byte (so the length of the text = end - begin).      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/google/protobuf/duration.proto.sk/",
	"title": "duration.proto",
	"tags": [],
	"description": "",
	"content": " Package: google.protobuf Protocol Buffers - Google\u0026rsquo;s data interchange format Copyright 2008 Google Inc. All rights reserved. https://developers.google.com/protocol-buffers/\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n* Redistributions of source code must retain the above copyright  notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026ldquo;AS IS\u0026rdquo; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nTypes:  Duration   Source File: google/protobuf/duration.proto Duration A Duration represents a signed, fixed-length span of time represented as a count of seconds and fractions of seconds at nanosecond resolution. It is independent of any calendar and concepts like \u0026ldquo;day\u0026rdquo; or \u0026ldquo;month\u0026rdquo;. It is related to Timestamp in that the difference between two Timestamp values is a Duration and it can be added or subtracted from a Timestamp. Range is approximately +-10,000 years.\nExamples Example 1: Compute Duration from two Timestamps in pseudo code.\nTimestamp start = ...; Timestamp end = ...; Duration duration = ...; duration.seconds = end.seconds - start.seconds; duration.nanos = end.nanos - start.nanos; if (duration.seconds \u0026lt; 0 \u0026amp;\u0026amp; duration.nanos \u0026gt; 0) { duration.seconds += 1; duration.nanos -= 1000000000; } else if (durations.seconds \u0026gt; 0 \u0026amp;\u0026amp; duration.nanos \u0026lt; 0) { duration.seconds -= 1; duration.nanos += 1000000000; }  Example 2: Compute Timestamp from Timestamp + Duration in pseudo code.\nTimestamp start = ...; Duration duration = ...; Timestamp end = ...; end.seconds = start.seconds + duration.seconds; end.nanos = start.nanos + duration.nanos; if (end.nanos \u0026lt; 0) { end.seconds -= 1; end.nanos += 1000000000; } else if (end.nanos \u0026gt;= 1000000000) { end.seconds += 1; end.nanos -= 1000000000; }  Example 3: Compute Duration from datetime.timedelta in Python.\ntd = datetime.timedelta(days=3, minutes=10) duration = Duration() duration.FromTimedelta(td)  JSON Mapping In JSON format, the Duration type is encoded as a string rather than an object, where the string ends in the suffix \u0026ldquo;s\u0026rdquo; (indicating seconds) and is preceded by the number of seconds, with nanoseconds expressed as fractional seconds. For example, 3 seconds with 0 nanoseconds should be encoded in JSON format as \u0026ldquo;3s\u0026rdquo;, while 3 seconds and 1 nanosecond should be expressed in JSON format as \u0026ldquo;3.000000001s\u0026rdquo;, and 3 seconds and 1 microsecond should be expressed in JSON format as \u0026ldquo;3.000001s\u0026rdquo;.\n\u0026quot;seconds\u0026quot;: int \u0026quot;nanos\u0026quot;: int     Field Type Description Default     seconds int Signed seconds of the span of time. Must be from -315,576,000,000 to +315,576,000,000 inclusive. Note: these bounds are computed from: 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years    nanos int Signed fractions of a second at nanosecond resolution of the span of time. Durations less than one second are represented with a 0 seconds field and a positive or negative nanos field. For durations of one second or more, a non-zero value for the nanos field must be of the same sign as the seconds field. Must be from -999,999,999 to +999,999,999 inclusive.      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/google/protobuf/duration.proto.sk/",
	"title": "duration.proto",
	"tags": [],
	"description": "",
	"content": " Package: google.protobuf Protocol Buffers - Google\u0026rsquo;s data interchange format Copyright 2008 Google Inc. All rights reserved. https://developers.google.com/protocol-buffers/\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n* Redistributions of source code must retain the above copyright  notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026ldquo;AS IS\u0026rdquo; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nTypes:  Duration   Source File: google/protobuf/duration.proto Duration A Duration represents a signed, fixed-length span of time represented as a count of seconds and fractions of seconds at nanosecond resolution. It is independent of any calendar and concepts like \u0026ldquo;day\u0026rdquo; or \u0026ldquo;month\u0026rdquo;. It is related to Timestamp in that the difference between two Timestamp values is a Duration and it can be added or subtracted from a Timestamp. Range is approximately +-10,000 years.\nExamples Example 1: Compute Duration from two Timestamps in pseudo code.\nTimestamp start = ...; Timestamp end = ...; Duration duration = ...; duration.seconds = end.seconds - start.seconds; duration.nanos = end.nanos - start.nanos; if (duration.seconds \u0026lt; 0 \u0026amp;\u0026amp; duration.nanos \u0026gt; 0) { duration.seconds += 1; duration.nanos -= 1000000000; } else if (durations.seconds \u0026gt; 0 \u0026amp;\u0026amp; duration.nanos \u0026lt; 0) { duration.seconds -= 1; duration.nanos += 1000000000; }  Example 2: Compute Timestamp from Timestamp + Duration in pseudo code.\nTimestamp start = ...; Duration duration = ...; Timestamp end = ...; end.seconds = start.seconds + duration.seconds; end.nanos = start.nanos + duration.nanos; if (end.nanos \u0026lt; 0) { end.seconds -= 1; end.nanos += 1000000000; } else if (end.nanos \u0026gt;= 1000000000) { end.seconds += 1; end.nanos -= 1000000000; }  Example 3: Compute Duration from datetime.timedelta in Python.\ntd = datetime.timedelta(days=3, minutes=10) duration = Duration() duration.FromTimedelta(td)  JSON Mapping In JSON format, the Duration type is encoded as a string rather than an object, where the string ends in the suffix \u0026ldquo;s\u0026rdquo; (indicating seconds) and is preceded by the number of seconds, with nanoseconds expressed as fractional seconds. For example, 3 seconds with 0 nanoseconds should be encoded in JSON format as \u0026ldquo;3s\u0026rdquo;, while 3 seconds and 1 nanosecond should be expressed in JSON format as \u0026ldquo;3.000000001s\u0026rdquo;, and 3 seconds and 1 microsecond should be expressed in JSON format as \u0026ldquo;3.000001s\u0026rdquo;.\n\u0026quot;seconds\u0026quot;: int \u0026quot;nanos\u0026quot;: int     Field Type Description Default     seconds int Signed seconds of the span of time. Must be from -315,576,000,000 to +315,576,000,000 inclusive. Note: these bounds are computed from: 60 sec/min * 60 min/hr * 24 hr/day * 365.25 days/year * 10000 years    nanos int Signed fractions of a second at nanosecond resolution of the span of time. Durations less than one second are represented with a 0 seconds field and a positive or negative nanos field. For durations of one second or more, a non-zero value for the nanos field must be of the same sign as the seconds field. Must be from -999,999,999 to +999,999,999 inclusive.      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/endpoint.proto.sk/",
	"title": "endpoint.proto",
	"tags": [],
	"description": "",
	"content": " Package: gloo.solo.io Types:  Endpoint Top-Level Resource   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/endpoint.proto Endpoint Endpoints represent dynamically discovered address/ports where an upstream service is listening\n\u0026quot;upstreams\u0026quot;: []core.solo.io.ResourceRef \u0026quot;address\u0026quot;: string \u0026quot;port\u0026quot;: int \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata     Field Type Description Default     upstreams []core.solo.io.ResourceRef List of the upstreams the endpoint belongs to    address string Address of the endpoint (ip or hostname)    port int listening port for the endpoint    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/endpoint.proto.sk/",
	"title": "endpoint.proto",
	"tags": [],
	"description": "",
	"content": " Package: gloo.solo.io Types:  Endpoint Top-Level Resource   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/endpoint.proto Endpoint Endpoints represent dynamically discovered address/ports where an upstream service is listening\n\u0026quot;upstreams\u0026quot;: []core.solo.io.ResourceRef \u0026quot;address\u0026quot;: string \u0026quot;port\u0026quot;: int \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata     Field Type Description Default     upstreams []core.solo.io.ResourceRef List of the upstreams the endpoint belongs to    address string Address of the endpoint (ip or hostname)    port int listening port for the endpoint    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/extensions.proto.sk/",
	"title": "extensions.proto",
	"tags": [],
	"description": "",
	"content": " Package: gloo.solo.io Types:  Extensions Extension   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/extensions.proto Extensions \u0026quot;configs\u0026quot;: map\u0026lt;string, .google.protobuf.Struct\u0026gt;     Field Type Description Default     configs map\u0026lt;string, .google.protobuf.Struct\u0026gt;      Extension \u0026quot;config\u0026quot;: .google.protobuf.Struct     Field Type Description Default     config .google.protobuf.Struct       "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/extensions.proto.sk/",
	"title": "extensions.proto",
	"tags": [],
	"description": "",
	"content": " Package: gloo.solo.io Types:  Extensions Extension   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/extensions.proto Extensions \u0026quot;configs\u0026quot;: map\u0026lt;string, .google.protobuf.Struct\u0026gt;     Field Type Description Default     configs map\u0026lt;string, .google.protobuf.Struct\u0026gt;      Extension \u0026quot;config\u0026quot;: .google.protobuf.Struct     Field Type Description Default     config .google.protobuf.Struct       "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/faultinjection/fault.proto.sk/",
	"title": "fault.proto",
	"tags": [],
	"description": "",
	"content": " Package: fault.plugins.gloo.solo.io TODO: this was copied form the transformation filter. TODO: instead of manually copying, we want to do it via script, similar to the java-control-plane TODO: to solo-kit/api/envoy\nTypes:  RouteAbort RouteDelay RouteFaults   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/faultinjection/fault.proto RouteAbort \u0026quot;percentage\u0026quot;: float \u0026quot;http_status\u0026quot;: int     Field Type Description Default     percentage float Percentage of requests that should be aborted, defaulting to 0. This should be a value between 0.0 and 100.0, with up to 6 significant digits.    http_status int This should be a standard HTTP status, i.e. 503. Defaults to 0.     RouteDelay \u0026quot;percentage\u0026quot;: float \u0026quot;fixed_delay\u0026quot;: .google.protobuf.Duration     Field Type Description Default     percentage float Percentage of requests that should be delayed, defaulting to 0. This should be a value between 0.0 and 100.0, with up to 6 significant digits.    fixed_delay .google.protobuf.Duration Fixed delay, defaulting to 0.     RouteFaults \u0026quot;abort\u0026quot;: .fault.plugins.gloo.solo.io.RouteAbort \u0026quot;delay\u0026quot;: .fault.plugins.gloo.solo.io.RouteDelay     Field Type Description Default     abort .fault.plugins.gloo.solo.io.RouteAbort     delay .fault.plugins.gloo.solo.io.RouteDelay       "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/faultinjection/fault.proto.sk/",
	"title": "fault.proto",
	"tags": [],
	"description": "",
	"content": " Package: fault.plugins.gloo.solo.io TODO: this was copied form the transformation filter. TODO: instead of manually copying, we want to do it via script, similar to the java-control-plane TODO: to solo-kit/api/envoy\nTypes:  RouteAbort RouteDelay RouteFaults   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/faultinjection/fault.proto RouteAbort \u0026quot;percentage\u0026quot;: float \u0026quot;http_status\u0026quot;: int     Field Type Description Default     percentage float Percentage of requests that should be aborted, defaulting to 0. This should be a value between 0.0 and 100.0, with up to 6 significant digits.    http_status int This should be a standard HTTP status, i.e. 503. Defaults to 0.     RouteDelay \u0026quot;percentage\u0026quot;: float \u0026quot;fixed_delay\u0026quot;: .google.protobuf.Duration     Field Type Description Default     percentage float Percentage of requests that should be delayed, defaulting to 0. This should be a value between 0.0 and 100.0, with up to 6 significant digits.    fixed_delay .google.protobuf.Duration Fixed delay, defaulting to 0.     RouteFaults \u0026quot;abort\u0026quot;: .fault.plugins.gloo.solo.io.RouteAbort \u0026quot;delay\u0026quot;: .fault.plugins.gloo.solo.io.RouteDelay     Field Type Description Default     abort .fault.plugins.gloo.solo.io.RouteAbort     delay .fault.plugins.gloo.solo.io.RouteDelay       "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/pkg/plugins/aws/filter.proto.sk/",
	"title": "filter.proto",
	"tags": [],
	"description": "",
	"content": " Package: envoy.config.filter.http.aws.v2 Types:  LambdaPerRoute LambdaProtocolExtension   Source File: github.com/solo-io/gloo/projects/gloo/pkg/plugins/aws/filter.proto LambdaPerRoute AWS Lambda contains the configuration necessary to perform transform regular http calls to AWS Lambda invocations.\n\u0026quot;name\u0026quot;: string \u0026quot;qualifier\u0026quot;: string \u0026quot;async\u0026quot;: bool     Field Type Description Default     name string The name of the function    qualifier string The qualifier of the function (defaults to $LATEST if not specified)    async bool Invocation type - async or regular.     LambdaProtocolExtension \u0026quot;host\u0026quot;: string \u0026quot;region\u0026quot;: string \u0026quot;access_key\u0026quot;: string \u0026quot;secret_key\u0026quot;: string     Field Type Description Default     host string The host header for AWS this cluster    region string The region for this cluster    access_key string The access_key for AWS this cluster    secret_key string The secret_key for AWS this cluster      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/pkg/plugins/aws/filter.proto.sk/",
	"title": "filter.proto",
	"tags": [],
	"description": "",
	"content": " Package: envoy.config.filter.http.aws.v2 Types:  LambdaPerRoute LambdaProtocolExtension   Source File: github.com/solo-io/gloo/projects/gloo/pkg/plugins/aws/filter.proto LambdaPerRoute AWS Lambda contains the configuration necessary to perform transform regular http calls to AWS Lambda invocations.\n\u0026quot;name\u0026quot;: string \u0026quot;qualifier\u0026quot;: string \u0026quot;async\u0026quot;: bool     Field Type Description Default     name string The name of the function    qualifier string The qualifier of the function (defaults to $LATEST if not specified)    async bool Invocation type - async or regular.     LambdaProtocolExtension \u0026quot;host\u0026quot;: string \u0026quot;region\u0026quot;: string \u0026quot;access_key\u0026quot;: string \u0026quot;secret_key\u0026quot;: string     Field Type Description Default     host string The host header for AWS this cluster    region string The region for this cluster    access_key string The access_key for AWS this cluster    secret_key string The secret_key for AWS this cluster      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gateway/api/v1/gateway.proto.sk/",
	"title": "gateway.proto",
	"tags": [],
	"description": "",
	"content": " Package: gateway.solo.io Types:  Gateway Top-Level Resource   Source File: github.com/solo-io/gloo/projects/gateway/api/v1/gateway.proto Gateway A gateway describes the routes to upstreams that are reachable via a specific port on the Gateway Proxy itself.\n\u0026quot;virtual_services\u0026quot;: []core.solo.io.ResourceRef \u0026quot;bind_address\u0026quot;: string \u0026quot;bind_port\u0026quot;: int \u0026quot;plugins\u0026quot;: .gloo.solo.io.ListenerPlugins \u0026quot;status\u0026quot;: .core.solo.io.Status \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata     Field Type Description Default     virtual_services []core.solo.io.ResourceRef names of the the virtual services, which contain the actual routes for the gateway if the list is empty, the gateway will apply all virtual services to this gateway    bind_address string the bind address the gateway should serve traffic on    bind_port int bind ports must not conflict across gateways in a namespace    plugins .gloo.solo.io.ListenerPlugins top level plugin configuration for all routes on the gateway    status .core.solo.io.Status Status indicates the validation status of this resource. Status is read-only by clients, and set by gloo during validation    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gateway/api/v1/gateway.proto.sk/",
	"title": "gateway.proto",
	"tags": [],
	"description": "",
	"content": " Package: gateway.solo.io Types:  Gateway Top-Level Resource   Source File: github.com/solo-io/gloo/projects/gateway/api/v1/gateway.proto Gateway A gateway describes the routes to upstreams that are reachable via a specific port on the Gateway Proxy itself.\n\u0026quot;virtual_services\u0026quot;: []core.solo.io.ResourceRef \u0026quot;bind_address\u0026quot;: string \u0026quot;bind_port\u0026quot;: int \u0026quot;plugins\u0026quot;: .gloo.solo.io.ListenerPlugins \u0026quot;status\u0026quot;: .core.solo.io.Status \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata     Field Type Description Default     virtual_services []core.solo.io.ResourceRef names of the the virtual services, which contain the actual routes for the gateway if the list is empty, the gateway will apply all virtual services to this gateway    bind_address string the bind address the gateway should serve traffic on    bind_port int bind ports must not conflict across gateways in a namespace    plugins .gloo.solo.io.ListenerPlugins top level plugin configuration for all routes on the gateway    status .core.solo.io.Status Status indicates the validation status of this resource. Status is read-only by clients, and set by gloo during validation    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/gateway.solo.io.project.sk/",
	"title": "gateway.solo.io.project",
	"tags": [],
	"description": "",
	"content": " API Reference for API Version: gateway.solo.io.v1\nAPI Resources:  Artifact ClusterIngress Endpoint Gateway Ingress KubeService Proxy Secret Settings Upstream VirtualService   "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/gateway.solo.io.project.sk/",
	"title": "gateway.solo.io.project",
	"tags": [],
	"description": "",
	"content": " API Reference for API Version: gateway.solo.io.v1\nAPI Resources:  Artifact ClusterIngress Endpoint Gateway Ingress KubeService Proxy Secret Settings Upstream VirtualService   "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/gloo.solo.io.project.sk/",
	"title": "gloo.solo.io.project",
	"tags": [],
	"description": "",
	"content": " API Reference for Gloo, The Hybrid Application Gateway API Version: gloo.solo.io.v1\nGloo is a high-performance, plugin-extendable, platform-agnostic API Gateway built on top of Envoy. Gloo is designed for microservice, monolithic, and serverless applications. By employing function-level routing, Gloo can completely decouple client APIs from upstream APIs at the routing level. Gloo serves as an abstraction layer between clients and upstream services, allowing front-end teams to work independently of teams developing the microservices their apps connect to.\nAPI Resources:  Artifact ClusterIngress Endpoint Gateway Ingress KubeService Proxy Secret Settings Upstream VirtualService   "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/gloo.solo.io.project.sk/",
	"title": "gloo.solo.io.project",
	"tags": [],
	"description": "",
	"content": " API Reference for Gloo, The Hybrid Application Gateway API Version: gloo.solo.io.v1\nGloo is a high-performance, plugin-extendable, platform-agnostic API Gateway built on top of Envoy. Gloo is designed for microservice, monolithic, and serverless applications. By employing function-level routing, Gloo can completely decouple client APIs from upstream APIs at the routing level. Gloo serves as an abstraction layer between clients and upstream services, allowing front-end teams to work independently of teams developing the microservices their apps connect to.\nAPI Resources:  Artifact ClusterIngress Endpoint Gateway Ingress KubeService Proxy Secret Settings Upstream VirtualService   "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl/",
	"title": "glooctl",
	"tags": [],
	"description": "",
	"content": " glooctl CLI for Gloo\nSynopsis glooctl is the unified CLI for Gloo. Find more information at https://solo.io\nOptions  -h, --help help for glooctl -i, --interactive use interactive mode  SEE ALSO  glooctl add - adds configuration to a top-level Gloo resource glooctl create - Create a Gloo resource glooctl delete - Delete a Gloo resource glooctl get - Display one or a list of Gloo resources glooctl install - install gloo on different platforms glooctl proxy - interact with proxy instances managed by Gloo glooctl remove - remove configuration items from a top-level Gloo resource glooctl route - subcommands for interacting with routes within virtual services glooctl uninstall - uninstall gloo glooctl upgrade - upgrade glooctl binary  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl/",
	"title": "glooctl",
	"tags": [],
	"description": "",
	"content": " glooctl CLI for Gloo\nSynopsis glooctl is the unified CLI for Gloo. Find more information at https://solo.io\nOptions  -h, --help help for glooctl -i, --interactive use interactive mode  SEE ALSO  glooctl add - adds configuration to a top-level Gloo resource glooctl create - Create a Gloo resource glooctl delete - Delete a Gloo resource glooctl get - Display one or a list of Gloo resources glooctl install - install gloo on different platforms glooctl proxy - interact with proxy instances managed by Gloo glooctl remove - remove configuration items from a top-level Gloo resource glooctl route - subcommands for interacting with routes within virtual services glooctl uninstall - uninstall gloo glooctl upgrade - upgrade glooctl binary  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_add/",
	"title": "glooctl add",
	"tags": [],
	"description": "",
	"content": " glooctl add adds configuration to a top-level Gloo resource\nSynopsis adds configuration to a top-level Gloo resource\nOptions  -h, --help help for add --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo glooctl add route - Add a Route to a Virtual Service  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_add/",
	"title": "glooctl add",
	"tags": [],
	"description": "",
	"content": " glooctl add adds configuration to a top-level Gloo resource\nSynopsis adds configuration to a top-level Gloo resource\nOptions  -h, --help help for add --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo glooctl add route - Add a Route to a Virtual Service  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_add_route/",
	"title": "glooctl add route",
	"tags": [],
	"description": "",
	"content": " glooctl add route Add a Route to a Virtual Service\nSynopsis Routes match patterns on requests and indicate the type of action to take when a proxy receives a matching request. Requests can be broken down into their Match and Action components. The order of routes within a Virtual Service matters. The first route in the virtual service that matches a given request will be selected for routing.\nIf no virtual service is specified for this command, glooctl add route will attempt to add it to a default virtualservice with domain \u0026lsquo;*\u0026lsquo;. if one does not exist, it will be created for you.\nUsage: glooctl add route [--name virtual-service-name] [--namespace namespace] [--index x] ...\nglooctl add route [flags]  Options  -a, --aws-function-name string logical name of the AWS lambda to invoke with this route. use if destination is an AWS upstream --aws-unescape unescape JSON returned by this lambda function (useful if the response is not intended to be JSON formatted, e.g. in the case of static content (images, HTML, etc.) being served by Lambda -u, --dest-name string name of the destination upstream for this route -s, --dest-namespace string namespace of the destination upstream for this route (default \u0026quot;gloo-system\u0026quot;) -d, --header strings headers to match on the request. values can be specified using regex strings -h, --help help for route -x, --index uint32 index in the virtual service route list where to insert this route. routes after it will be shifted back one -m, --method strings the HTTP methods (GET, POST, etc.) to match on the request. if empty, all methods will match -o, --output string output format: (yaml, json, table) -e, --path-exact string exact path to match route -p, --path-prefix string path prefix to match route -r, --path-regex string regex matcher for route. note: only one of path-exact, path-regex, or path-prefix should be set --prefix-rewrite string rewrite the matched portion of HTTP requests with this prefix. note that this will be overridden if your routes point to function destinations -f, --rest-function-name string name of the REST function to invoke with this route. use if destination has a REST service spec --rest-parameters strings Parameters for the rest function that are to be read off of incoming request headers. format specified as follows: 'header_name=extractor_string' where header_name is the HTTP2 equivalent header (':path' for HTTP 1 path). For example, to extract the variable 'id' from the following request path /users/1, where 1 is the id: --rest-parameters ':path='/users/{id}'  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  SEE ALSO  glooctl add - adds configuration to a top-level Gloo resource  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_add_route/",
	"title": "glooctl add route",
	"tags": [],
	"description": "",
	"content": " glooctl add route Add a Route to a Virtual Service\nSynopsis Routes match patterns on requests and indicate the type of action to take when a proxy receives a matching request. Requests can be broken down into their Match and Action components. The order of routes within a Virtual Service matters. The first route in the virtual service that matches a given request will be selected for routing.\nIf no virtual service is specified for this command, glooctl add route will attempt to add it to a default virtualservice with domain \u0026lsquo;*\u0026lsquo;. if one does not exist, it will be created for you.\nUsage: glooctl add route [--name virtual-service-name] [--namespace namespace] [--index x] ...\nglooctl add route [flags]  Options  -a, --aws-function-name string logical name of the AWS lambda to invoke with this route. use if destination is an AWS upstream --aws-unescape unescape JSON returned by this lambda function (useful if the response is not intended to be JSON formatted, e.g. in the case of static content (images, HTML, etc.) being served by Lambda -u, --dest-name string name of the destination upstream for this route -s, --dest-namespace string namespace of the destination upstream for this route (default \u0026quot;gloo-system\u0026quot;) -d, --header strings headers to match on the request. values can be specified using regex strings -h, --help help for route -x, --index uint32 index in the virtual service route list where to insert this route. routes after it will be shifted back one -m, --method strings the HTTP methods (GET, POST, etc.) to match on the request. if empty, all methods will match -o, --output string output format: (yaml, json, table) -e, --path-exact string exact path to match route -p, --path-prefix string path prefix to match route -r, --path-regex string regex matcher for route. note: only one of path-exact, path-regex, or path-prefix should be set --prefix-rewrite string rewrite the matched portion of HTTP requests with this prefix. note that this will be overridden if your routes point to function destinations -f, --rest-function-name string name of the REST function to invoke with this route. use if destination has a REST service spec --rest-parameters strings Parameters for the rest function that are to be read off of incoming request headers. format specified as follows: 'header_name=extractor_string' where header_name is the HTTP2 equivalent header (':path' for HTTP 1 path). For example, to extract the variable 'id' from the following request path /users/1, where 1 is the id: --rest-parameters ':path='/users/{id}'  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  SEE ALSO  glooctl add - adds configuration to a top-level Gloo resource  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_create/",
	"title": "glooctl create",
	"tags": [],
	"description": "",
	"content": " glooctl create Create a Gloo resource\nSynopsis Gloo resources be created from files (including stdin)\nglooctl create [flags]  Options  -f, --file string file to be read or written to -h, --help help for create -o, --output string output format: (yaml, json, table)  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo glooctl create secret - Create a secret glooctl create upstream - Create an Upstream Interactively glooctl create virtualservice - Create a Virtual Service  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_create/",
	"title": "glooctl create",
	"tags": [],
	"description": "",
	"content": " glooctl create Create a Gloo resource\nSynopsis Gloo resources be created from files (including stdin)\nglooctl create [flags]  Options  -f, --file string file to be read or written to -h, --help help for create -o, --output string output format: (yaml, json, table)  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo glooctl create secret - Create a secret glooctl create upstream - Create an Upstream Interactively glooctl create virtualservice - Create a Virtual Service  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_create_secret/",
	"title": "glooctl create secret",
	"tags": [],
	"description": "",
	"content": " glooctl create secret Create a secret\nSynopsis Create a secret\nglooctl create secret [flags]  Options  -h, --help help for secret  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create - Create a Gloo resource glooctl create secret aws - Create an AWS secret with the given name glooctl create secret azure - Create an Azure secret with the given name glooctl create secret tls - Create a secret with the given name  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_create_secret/",
	"title": "glooctl create secret",
	"tags": [],
	"description": "",
	"content": " glooctl create secret Create a secret\nSynopsis Create a secret\nglooctl create secret [flags]  Options  -h, --help help for secret  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create - Create a Gloo resource glooctl create secret aws - Create an AWS secret with the given name glooctl create secret azure - Create an Azure secret with the given name glooctl create secret tls - Create a secret with the given name  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_create_secret_aws/",
	"title": "glooctl create secret aws",
	"tags": [],
	"description": "",
	"content": " glooctl create secret aws Create an AWS secret with the given name\nSynopsis Create an AWS secret with the given name\nglooctl create secret aws [flags]  Options  --access-key string aws access key -h, --help help for aws --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) --secret-key string aws secret key  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create secret - Create a secret  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_create_secret_aws/",
	"title": "glooctl create secret aws",
	"tags": [],
	"description": "",
	"content": " glooctl create secret aws Create an AWS secret with the given name\nSynopsis Create an AWS secret with the given name\nglooctl create secret aws [flags]  Options  --access-key string aws access key -h, --help help for aws --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) --secret-key string aws secret key  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create secret - Create a secret  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_create_secret_azure/",
	"title": "glooctl create secret azure",
	"tags": [],
	"description": "",
	"content": " glooctl create secret azure Create an Azure secret with the given name\nSynopsis Create an Azure secret with the given name\nglooctl create secret azure [flags]  Options  --api-keys strings comma-separated list of azure api key=value entries -h, --help help for azure --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create secret - Create a secret  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_create_secret_azure/",
	"title": "glooctl create secret azure",
	"tags": [],
	"description": "",
	"content": " glooctl create secret azure Create an Azure secret with the given name\nSynopsis Create an Azure secret with the given name\nglooctl create secret azure [flags]  Options  --api-keys strings comma-separated list of azure api key=value entries -h, --help help for azure --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create secret - Create a secret  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_create_secret_tls/",
	"title": "glooctl create secret tls",
	"tags": [],
	"description": "",
	"content": " glooctl create secret tls Create a secret with the given name\nSynopsis Create a secret with the given name\nglooctl create secret tls [flags]  Options  --certchain string filename of certchain for secret -h, --help help for tls --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) --privatekey string filename of privatekey for secret --rootca string filename of rootca for secret  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create secret - Create a secret  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_create_secret_tls/",
	"title": "glooctl create secret tls",
	"tags": [],
	"description": "",
	"content": " glooctl create secret tls Create a secret with the given name\nSynopsis Create a secret with the given name\nglooctl create secret tls [flags]  Options  --certchain string filename of certchain for secret -h, --help help for tls --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) --privatekey string filename of privatekey for secret --rootca string filename of rootca for secret  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create secret - Create a secret  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_create_upstream/",
	"title": "glooctl create upstream",
	"tags": [],
	"description": "",
	"content": " glooctl create upstream Create an Upstream Interactively\nSynopsis Upstreams represent destination for routing HTTP requests. Upstreams can be compared to clusters in Envoy terminology. Each upstream in Gloo has a type. Supported types include static, kubernetes, aws, consul, and more. Each upstream type is handled by a corresponding Gloo plugin.\nglooctl create upstream [flags]  Options  -h, --help help for upstream  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create - Create a Gloo resource glooctl create upstream aws - Create an Aws Upstream glooctl create upstream azure - Create an Azure Upstream glooctl create upstream consul - Create a Consul Upstream glooctl create upstream kube - Create a Kubernetes Upstream glooctl create upstream static - Create a Static Upstream  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_create_upstream/",
	"title": "glooctl create upstream",
	"tags": [],
	"description": "",
	"content": " glooctl create upstream Create an Upstream Interactively\nSynopsis Upstreams represent destination for routing HTTP requests. Upstreams can be compared to clusters in Envoy terminology. Each upstream in Gloo has a type. Supported types include static, kubernetes, aws, consul, and more. Each upstream type is handled by a corresponding Gloo plugin.\nglooctl create upstream [flags]  Options  -h, --help help for upstream  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create - Create a Gloo resource glooctl create upstream aws - Create an Aws Upstream glooctl create upstream azure - Create an Azure Upstream glooctl create upstream consul - Create a Consul Upstream glooctl create upstream kube - Create a Kubernetes Upstream glooctl create upstream static - Create a Static Upstream  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_create_upstream_aws/",
	"title": "glooctl create upstream aws",
	"tags": [],
	"description": "",
	"content": " glooctl create upstream aws Create an Aws Upstream\nSynopsis AWS Upstreams represent a set of AWS Lambda Functions for a Region that can be routed to with Gloo. AWS Upstreams require a valid set of AWS Credentials to be provided. These should be uploaded to Gloo using glooctl create secret aws\nglooctl create upstream aws [flags]  Options  --aws-region string region for AWS services this upstream utilize (default \u0026quot;us-east-1\u0026quot;) --aws-secret-name glooctl create secret aws --help name of a secret containing AWS credentials created with glooctl. See glooctl create secret aws --help for help creating secrets --aws-secret-namespace glooctl create secret aws --help namespace where the AWS secret lives. See glooctl create secret aws --help for help creating secrets (default \u0026quot;gloo-system\u0026quot;) -h, --help help for aws --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create upstream - Create an Upstream Interactively  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_create_upstream_aws/",
	"title": "glooctl create upstream aws",
	"tags": [],
	"description": "",
	"content": " glooctl create upstream aws Create an Aws Upstream\nSynopsis AWS Upstreams represent a set of AWS Lambda Functions for a Region that can be routed to with Gloo. AWS Upstreams require a valid set of AWS Credentials to be provided. These should be uploaded to Gloo using glooctl create secret aws\nglooctl create upstream aws [flags]  Options  --aws-region string region for AWS services this upstream utilize (default \u0026quot;us-east-1\u0026quot;) --aws-secret-name glooctl create secret aws --help name of a secret containing AWS credentials created with glooctl. See glooctl create secret aws --help for help creating secrets --aws-secret-namespace glooctl create secret aws --help namespace where the AWS secret lives. See glooctl create secret aws --help for help creating secrets (default \u0026quot;gloo-system\u0026quot;) -h, --help help for aws --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create upstream - Create an Upstream Interactively  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_create_upstream_azure/",
	"title": "glooctl create upstream azure",
	"tags": [],
	"description": "",
	"content": " glooctl create upstream azure Create an Azure Upstream\nSynopsis Azure Upstreams represent a set of Azure Functions for a Function App that can be routed to with Gloo. Azure Upstreams require a valid set of Azure Credentials to be provided. These should be uploaded to Gloo using glooctl create secret azure\nglooctl create upstream azure [flags]  Options  --azure-app-name string name of the Azure Functions app to associate with this upstream --azure-secret-name glooctl create secret azure --help name of a secret containing Azure credentials created with glooctl. See glooctl create secret azure --help for help creating secrets --azure-secret-namespace glooctl create secret azure --help namespace where the Azure secret lives. See glooctl create secret azure --help for help creating secrets (default \u0026quot;gloo-system\u0026quot;) -h, --help help for azure --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create upstream - Create an Upstream Interactively  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_create_upstream_azure/",
	"title": "glooctl create upstream azure",
	"tags": [],
	"description": "",
	"content": " glooctl create upstream azure Create an Azure Upstream\nSynopsis Azure Upstreams represent a set of Azure Functions for a Function App that can be routed to with Gloo. Azure Upstreams require a valid set of Azure Credentials to be provided. These should be uploaded to Gloo using glooctl create secret azure\nglooctl create upstream azure [flags]  Options  --azure-app-name string name of the Azure Functions app to associate with this upstream --azure-secret-name glooctl create secret azure --help name of a secret containing Azure credentials created with glooctl. See glooctl create secret azure --help for help creating secrets --azure-secret-namespace glooctl create secret azure --help namespace where the Azure secret lives. See glooctl create secret azure --help for help creating secrets (default \u0026quot;gloo-system\u0026quot;) -h, --help help for azure --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create upstream - Create an Upstream Interactively  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_create_upstream_consul/",
	"title": "glooctl create upstream consul",
	"tags": [],
	"description": "",
	"content": " glooctl create upstream consul Create a Consul Upstream\nSynopsis Consul Upstreams represent a collection of endpoints for Services registered with Consul. Typically, Gloo will automatically discover these upstreams, meaning you don\u0026rsquo;t have to create them. However, if upstream discovery in Gloo is disabled, or ACL permissions have not been granted to Gloo to read from the registry, Consul services can be added to Gloo manually via the CLI.\nglooctl create upstream consul [flags]  Options  --consul-service string name of the service in the consul registry --consul-service-tags strings comma-separated list of tags for choosing a subset of the service in the consul registry -h, --help help for consul --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) --service-spec-type string if set, Gloo supports additional routing features to upstreams with a service spec. The service spec defines a set of features  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create upstream - Create an Upstream Interactively  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_create_upstream_consul/",
	"title": "glooctl create upstream consul",
	"tags": [],
	"description": "",
	"content": " glooctl create upstream consul Create a Consul Upstream\nSynopsis Consul Upstreams represent a collection of endpoints for Services registered with Consul. Typically, Gloo will automatically discover these upstreams, meaning you don\u0026rsquo;t have to create them. However, if upstream discovery in Gloo is disabled, or ACL permissions have not been granted to Gloo to read from the registry, Consul services can be added to Gloo manually via the CLI.\nglooctl create upstream consul [flags]  Options  --consul-service string name of the service in the consul registry --consul-service-tags strings comma-separated list of tags for choosing a subset of the service in the consul registry -h, --help help for consul --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) --service-spec-type string if set, Gloo supports additional routing features to upstreams with a service spec. The service spec defines a set of features  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create upstream - Create an Upstream Interactively  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_create_upstream_kube/",
	"title": "glooctl create upstream kube",
	"tags": [],
	"description": "",
	"content": " glooctl create upstream kube Create a Kubernetes Upstream\nSynopsis Kubernetes Upstreams represent a collection of endpoints for Services registered with Kubernetes. Typically, Gloo will automatically discover these upstreams, meaning you don\u0026rsquo;t have to create them. However, if upstream discovery in Gloo is disabled, or RBAC permissions have not been granted to Gloo to read from the registry, Kubernetes services can be added to Gloo manually via the CLI.\nglooctl create upstream kube [flags]  Options  -h, --help help for kube --kube-service string name of the kubernetes service --kube-service-labels strings comma-separated list of labels (key=value) to use for customized selection of pods for this upstream. can be used to select subsets of pods for a service e.g. for blue-green deployment --kube-service-namespace string namespace where the kubernetes service lives (default \u0026quot;default\u0026quot;) --kube-service-port uint32 the port exposed by the kubernetes service. for services with multiple ports, create an upstream for each port. (default 80) --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) --service-spec-type string if set, Gloo supports additional routing features to upstreams with a service spec. The service spec defines a set of features  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create upstream - Create an Upstream Interactively  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_create_upstream_kube/",
	"title": "glooctl create upstream kube",
	"tags": [],
	"description": "",
	"content": " glooctl create upstream kube Create a Kubernetes Upstream\nSynopsis Kubernetes Upstreams represent a collection of endpoints for Services registered with Kubernetes. Typically, Gloo will automatically discover these upstreams, meaning you don\u0026rsquo;t have to create them. However, if upstream discovery in Gloo is disabled, or RBAC permissions have not been granted to Gloo to read from the registry, Kubernetes services can be added to Gloo manually via the CLI.\nglooctl create upstream kube [flags]  Options  -h, --help help for kube --kube-service string name of the kubernetes service --kube-service-labels strings comma-separated list of labels (key=value) to use for customized selection of pods for this upstream. can be used to select subsets of pods for a service e.g. for blue-green deployment --kube-service-namespace string namespace where the kubernetes service lives (default \u0026quot;default\u0026quot;) --kube-service-port uint32 the port exposed by the kubernetes service. for services with multiple ports, create an upstream for each port. (default 80) --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) --service-spec-type string if set, Gloo supports additional routing features to upstreams with a service spec. The service spec defines a set of features  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create upstream - Create an Upstream Interactively  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_create_upstream_static/",
	"title": "glooctl create upstream static",
	"tags": [],
	"description": "",
	"content": " glooctl create upstream static Create a Static Upstream\nSynopsis Static upstreams are intended to connect Gloo to upstreams to services (often external or 3rd-party) running at a fixed IP address or hostname. Static upstreams require you to manually specify the hosts associated with a static upstream. Requests routed to a static upstream will be round-robin load balanced across each host.\nglooctl create upstream static [flags]  Options  -h, --help help for static --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) --service-spec-type string if set, Gloo supports additional routing features to upstreams with a service spec. The service spec defines a set of features --static-hosts strings comma-separated list of hosts for the static upstream. these are hostnames or ips provided in the format IP:PORT or HOSTNAME:PORT. if :PORT is missing, it will default to :80 --static-outbound-tls connections Gloo manages to this cluster will attempt to use TLS for outbound connections. Gloo will automatically set this to true for port 443  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create upstream - Create an Upstream Interactively  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_create_upstream_static/",
	"title": "glooctl create upstream static",
	"tags": [],
	"description": "",
	"content": " glooctl create upstream static Create a Static Upstream\nSynopsis Static upstreams are intended to connect Gloo to upstreams to services (often external or 3rd-party) running at a fixed IP address or hostname. Static upstreams require you to manually specify the hosts associated with a static upstream. Requests routed to a static upstream will be round-robin load balanced across each host.\nglooctl create upstream static [flags]  Options  -h, --help help for static --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) --service-spec-type string if set, Gloo supports additional routing features to upstreams with a service spec. The service spec defines a set of features --static-hosts strings comma-separated list of hosts for the static upstream. these are hostnames or ips provided in the format IP:PORT or HOSTNAME:PORT. if :PORT is missing, it will default to :80 --static-outbound-tls connections Gloo manages to this cluster will attempt to use TLS for outbound connections. Gloo will automatically set this to true for port 443  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create upstream - Create an Upstream Interactively  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_create_virtualservice/",
	"title": "glooctl create virtualservice",
	"tags": [],
	"description": "",
	"content": " glooctl create virtualservice Create a Virtual Service\nSynopsis A virtual service describes the set of routes to match for a set of domains. Virtual services are containers for routes assigned to a domain or set of domains. Virtual services must not have overlapping domains, as the virtual service to match a request is selected by the Host header (in HTTP1) or :authority header (in HTTP2). The routes within a virtual service\nglooctl create virtualservice [flags]  Options  --display-name string descriptive name of virtual service (defaults to resource name) --domains strings comma separated list of domains -h, --help help for virtualservice --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create - Create a Gloo resource  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_create_virtualservice/",
	"title": "glooctl create virtualservice",
	"tags": [],
	"description": "",
	"content": " glooctl create virtualservice Create a Virtual Service\nSynopsis A virtual service describes the set of routes to match for a set of domains. Virtual services are containers for routes assigned to a domain or set of domains. Virtual services must not have overlapping domains, as the virtual service to match a request is selected by the Host header (in HTTP1) or :authority header (in HTTP2). The routes within a virtual service\nglooctl create virtualservice [flags]  Options  --display-name string descriptive name of virtual service (defaults to resource name) --domains strings comma separated list of domains -h, --help help for virtualservice --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl create - Create a Gloo resource  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_delete/",
	"title": "glooctl delete",
	"tags": [],
	"description": "",
	"content": " glooctl delete Delete a Gloo resource\nSynopsis Delete a Gloo resource\nOptions  -h, --help help for delete --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo glooctl delete proxy - delete a proxy glooctl delete upstream - delete an upstream glooctl delete virtualservice - delete a virtualservice  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_delete/",
	"title": "glooctl delete",
	"tags": [],
	"description": "",
	"content": " glooctl delete Delete a Gloo resource\nSynopsis Delete a Gloo resource\nOptions  -h, --help help for delete --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo glooctl delete proxy - delete a proxy glooctl delete upstream - delete an upstream glooctl delete virtualservice - delete a virtualservice  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_delete_proxy/",
	"title": "glooctl delete proxy",
	"tags": [],
	"description": "",
	"content": " glooctl delete proxy delete a proxy\nSynopsis usage: glooctl delete proxy [NAME] [\u0026ndash;namespace=namespace]\nglooctl delete proxy [flags]  Options  -h, --help help for proxy  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  SEE ALSO  glooctl delete - Delete a Gloo resource  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_delete_proxy/",
	"title": "glooctl delete proxy",
	"tags": [],
	"description": "",
	"content": " glooctl delete proxy delete a proxy\nSynopsis usage: glooctl delete proxy [NAME] [\u0026ndash;namespace=namespace]\nglooctl delete proxy [flags]  Options  -h, --help help for proxy  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  SEE ALSO  glooctl delete - Delete a Gloo resource  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_delete_upstream/",
	"title": "glooctl delete upstream",
	"tags": [],
	"description": "",
	"content": " glooctl delete upstream delete an upstream\nSynopsis usage: glooctl get upstream [NAME] [\u0026ndash;namespace=namespace]\nglooctl delete upstream [flags]  Options  -h, --help help for upstream  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  SEE ALSO  glooctl delete - Delete a Gloo resource  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_delete_upstream/",
	"title": "glooctl delete upstream",
	"tags": [],
	"description": "",
	"content": " glooctl delete upstream delete an upstream\nSynopsis usage: glooctl get upstream [NAME] [\u0026ndash;namespace=namespace]\nglooctl delete upstream [flags]  Options  -h, --help help for upstream  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  SEE ALSO  glooctl delete - Delete a Gloo resource  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_delete_virtualservice/",
	"title": "glooctl delete virtualservice",
	"tags": [],
	"description": "",
	"content": " glooctl delete virtualservice delete a virtualservice\nSynopsis usage: glooctl delete virtualservice [NAME] [\u0026ndash;namespace=namespace]\nglooctl delete virtualservice [flags]  Options  -h, --help help for virtualservice  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  SEE ALSO  glooctl delete - Delete a Gloo resource  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_delete_virtualservice/",
	"title": "glooctl delete virtualservice",
	"tags": [],
	"description": "",
	"content": " glooctl delete virtualservice delete a virtualservice\nSynopsis usage: glooctl delete virtualservice [NAME] [\u0026ndash;namespace=namespace]\nglooctl delete virtualservice [flags]  Options  -h, --help help for virtualservice  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  SEE ALSO  glooctl delete - Delete a Gloo resource  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_get/",
	"title": "glooctl get",
	"tags": [],
	"description": "",
	"content": " glooctl get Display one or a list of Gloo resources\nSynopsis Display one or a list of Gloo resources\nOptions  -h, --help help for get --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) -o, --output string output format: (yaml, json, table)  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo glooctl get proxy - read a proxy or list proxies in a namespace glooctl get upstream - read an upstream or list upstreams in a namespace glooctl get virtualservice - read a virtualservice or list virtualservices in a namespace  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_get/",
	"title": "glooctl get",
	"tags": [],
	"description": "",
	"content": " glooctl get Display one or a list of Gloo resources\nSynopsis Display one or a list of Gloo resources\nOptions  -h, --help help for get --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) -o, --output string output format: (yaml, json, table)  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo glooctl get proxy - read a proxy or list proxies in a namespace glooctl get upstream - read an upstream or list upstreams in a namespace glooctl get virtualservice - read a virtualservice or list virtualservices in a namespace  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_get_proxy/",
	"title": "glooctl get proxy",
	"tags": [],
	"description": "",
	"content": " glooctl get proxy read a proxy or list proxies in a namespace\nSynopsis usage: glooctl get proxy\nglooctl get proxy [flags]  Options  -h, --help help for proxy  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl get - Display one or a list of Gloo resources  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_get_proxy/",
	"title": "glooctl get proxy",
	"tags": [],
	"description": "",
	"content": " glooctl get proxy read a proxy or list proxies in a namespace\nSynopsis usage: glooctl get proxy\nglooctl get proxy [flags]  Options  -h, --help help for proxy  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl get - Display one or a list of Gloo resources  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_get_upstream/",
	"title": "glooctl get upstream",
	"tags": [],
	"description": "",
	"content": " glooctl get upstream read an upstream or list upstreams in a namespace\nSynopsis usage: glooctl get upstream [NAME] [\u0026ndash;namespace=namespace] [-o FORMAT] [-o FORMAT]\nglooctl get upstream [flags]  Options  -h, --help help for upstream  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl get - Display one or a list of Gloo resources  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_get_upstream/",
	"title": "glooctl get upstream",
	"tags": [],
	"description": "",
	"content": " glooctl get upstream read an upstream or list upstreams in a namespace\nSynopsis usage: glooctl get upstream [NAME] [\u0026ndash;namespace=namespace] [-o FORMAT] [-o FORMAT]\nglooctl get upstream [flags]  Options  -h, --help help for upstream  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl get - Display one or a list of Gloo resources  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_get_virtualservice/",
	"title": "glooctl get virtualservice",
	"tags": [],
	"description": "",
	"content": " glooctl get virtualservice read a virtualservice or list virtualservices in a namespace\nSynopsis usage: glooctl get virtualservice [NAME] [\u0026ndash;namespace=namespace] [-o FORMAT]\nglooctl get virtualservice [flags]  Options  -h, --help help for virtualservice  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl get - Display one or a list of Gloo resources glooctl get virtualservice route - get a list of routes for a given virtual service  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_get_virtualservice/",
	"title": "glooctl get virtualservice",
	"tags": [],
	"description": "",
	"content": " glooctl get virtualservice read a virtualservice or list virtualservices in a namespace\nSynopsis usage: glooctl get virtualservice [NAME] [\u0026ndash;namespace=namespace] [-o FORMAT]\nglooctl get virtualservice [flags]  Options  -h, --help help for virtualservice  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl get - Display one or a list of Gloo resources glooctl get virtualservice route - get a list of routes for a given virtual service  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_get_virtualservice_route/",
	"title": "glooctl get virtualservice route",
	"tags": [],
	"description": "",
	"content": " glooctl get virtualservice route get a list of routes for a given virtual service\nSynopsis usage: glooctl get virtualservice route\nglooctl get virtualservice route [flags]  Options  -h, --help help for route  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl get virtualservice - read a virtualservice or list virtualservices in a namespace  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_get_virtualservice_route/",
	"title": "glooctl get virtualservice route",
	"tags": [],
	"description": "",
	"content": " glooctl get virtualservice route get a list of routes for a given virtual service\nSynopsis usage: glooctl get virtualservice route\nglooctl get virtualservice route [flags]  Options  -h, --help help for route  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;) -o, --output string output format: (yaml, json, table)  SEE ALSO  glooctl get virtualservice - read a virtualservice or list virtualservices in a namespace  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_install/",
	"title": "glooctl install",
	"tags": [],
	"description": "",
	"content": " glooctl install install gloo on different platforms\nSynopsis choose which version of Gloo to install.\nOptions  -h, --help help for install  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo glooctl install gateway - install the Gloo Gateway on kubernetes glooctl install ingress - install the Gloo Ingress Controller on kubernetes glooctl install knative - install Knative with Gloo on kubernetes  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_install/",
	"title": "glooctl install",
	"tags": [],
	"description": "",
	"content": " glooctl install install gloo on different platforms\nSynopsis choose which version of Gloo to install.\nOptions  -h, --help help for install  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo glooctl install gateway - install the Gloo Gateway on kubernetes glooctl install ingress - install the Gloo Ingress Controller on kubernetes glooctl install knative - install Knative with Gloo on kubernetes  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_install_gateway/",
	"title": "glooctl install gateway",
	"tags": [],
	"description": "",
	"content": " glooctl install gateway install the Gloo Gateway on kubernetes\nSynopsis requires kubectl to be installed\nglooctl install gateway [flags]  Options  -d, --dry-run Dump the raw installation yaml instead of applying it to kubernetes -f, --file string Install Gloo from this kubernetes manifest yaml file rather than from a release -h, --help help for gateway --release string install using this release version. defaults to the latest github release  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl install - install gloo on different platforms  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_install_gateway/",
	"title": "glooctl install gateway",
	"tags": [],
	"description": "",
	"content": " glooctl install gateway install the Gloo Gateway on kubernetes\nSynopsis requires kubectl to be installed\nglooctl install gateway [flags]  Options  -d, --dry-run Dump the raw installation yaml instead of applying it to kubernetes -f, --file string Install Gloo from this kubernetes manifest yaml file rather than from a release -h, --help help for gateway --release string install using this release version. defaults to the latest github release  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl install - install gloo on different platforms  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_install_ingress/",
	"title": "glooctl install ingress",
	"tags": [],
	"description": "",
	"content": " glooctl install ingress install the Gloo Ingress Controller on kubernetes\nSynopsis requires kubectl to be installed\nglooctl install ingress [flags]  Options  -d, --dry-run Dump the raw installation yaml instead of applying it to kubernetes -f, --file string Install Gloo from this kubernetes manifest yaml file rather than from a release -h, --help help for ingress --release string install using this release version. defaults to the latest github release  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl install - install gloo on different platforms  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_install_ingress/",
	"title": "glooctl install ingress",
	"tags": [],
	"description": "",
	"content": " glooctl install ingress install the Gloo Ingress Controller on kubernetes\nSynopsis requires kubectl to be installed\nglooctl install ingress [flags]  Options  -d, --dry-run Dump the raw installation yaml instead of applying it to kubernetes -f, --file string Install Gloo from this kubernetes manifest yaml file rather than from a release -h, --help help for ingress --release string install using this release version. defaults to the latest github release  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl install - install gloo on different platforms  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_install_knative/",
	"title": "glooctl install knative",
	"tags": [],
	"description": "",
	"content": " glooctl install knative install Knative with Gloo on kubernetes\nSynopsis requires kubectl to be installed\nglooctl install knative [flags]  Options  -d, --dry-run Dump the raw installation yaml instead of applying it to kubernetes -f, --file string Install Gloo from this kubernetes manifest yaml file rather than from a release -h, --help help for knative --knative-crds-manifest string Install Knative CRDs from this kubernetes manifest yaml file rather than from a release --knative-install-manifest string Install Knative Serving from this kubernetes manifest yaml file rather than from a release --release string install using this release version. defaults to the latest github release  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl install - install gloo on different platforms  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_install_knative/",
	"title": "glooctl install knative",
	"tags": [],
	"description": "",
	"content": " glooctl install knative install Knative with Gloo on kubernetes\nSynopsis requires kubectl to be installed\nglooctl install knative [flags]  Options  -d, --dry-run Dump the raw installation yaml instead of applying it to kubernetes -f, --file string Install Gloo from this kubernetes manifest yaml file rather than from a release -h, --help help for knative --knative-crds-manifest string Install Knative CRDs from this kubernetes manifest yaml file rather than from a release --knative-install-manifest string Install Knative Serving from this kubernetes manifest yaml file rather than from a release --release string install using this release version. defaults to the latest github release  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl install - install gloo on different platforms  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_proxy/",
	"title": "glooctl proxy",
	"tags": [],
	"description": "",
	"content": " glooctl proxy interact with proxy instances managed by Gloo\nSynopsis these commands can be used to interact directly with the Proxies Gloo is managing. They are useful for interacting with and debugging the proxies (Envoy instances) directly.\nOptions  -h, --help help for proxy -p, --name string the name of the proxy service/deployment to use (default \u0026quot;gateway-proxy\u0026quot;) --port string the name of the service port to connect to (default \u0026quot;http\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo glooctl proxy dump - dump Envoy config from one of the proxy instances glooctl proxy logs - dump Envoy logs from one of the proxy instancesNote: this will enable verbose logging on Envoy glooctl proxy stats - stats for one of the proxy instances glooctl proxy url - print the http endpoint for a proxy  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_proxy/",
	"title": "glooctl proxy",
	"tags": [],
	"description": "",
	"content": " glooctl proxy interact with proxy instances managed by Gloo\nSynopsis these commands can be used to interact directly with the Proxies Gloo is managing. They are useful for interacting with and debugging the proxies (Envoy instances) directly.\nOptions  -h, --help help for proxy -p, --name string the name of the proxy service/deployment to use (default \u0026quot;gateway-proxy\u0026quot;) --port string the name of the service port to connect to (default \u0026quot;http\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo glooctl proxy dump - dump Envoy config from one of the proxy instances glooctl proxy logs - dump Envoy logs from one of the proxy instancesNote: this will enable verbose logging on Envoy glooctl proxy stats - stats for one of the proxy instances glooctl proxy url - print the http endpoint for a proxy  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_proxy_dump/",
	"title": "glooctl proxy dump",
	"tags": [],
	"description": "",
	"content": " glooctl proxy dump dump Envoy config from one of the proxy instances\nSynopsis dump Envoy config from one of the proxy instances\nglooctl proxy dump [flags]  Options  -h, --help help for dump -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode -p, --name string the name of the proxy service/deployment to use (default \u0026quot;gateway-proxy\u0026quot;) --port string the name of the service port to connect to (default \u0026quot;http\u0026quot;)  SEE ALSO  glooctl proxy - interact with proxy instances managed by Gloo  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_proxy_dump/",
	"title": "glooctl proxy dump",
	"tags": [],
	"description": "",
	"content": " glooctl proxy dump dump Envoy config from one of the proxy instances\nSynopsis dump Envoy config from one of the proxy instances\nglooctl proxy dump [flags]  Options  -h, --help help for dump -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode -p, --name string the name of the proxy service/deployment to use (default \u0026quot;gateway-proxy\u0026quot;) --port string the name of the service port to connect to (default \u0026quot;http\u0026quot;)  SEE ALSO  glooctl proxy - interact with proxy instances managed by Gloo  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_proxy_logs/",
	"title": "glooctl proxy logs",
	"tags": [],
	"description": "",
	"content": " glooctl proxy logs dump Envoy logs from one of the proxy instancesNote: this will enable verbose logging on Envoy\nSynopsis dump Envoy logs from one of the proxy instancesNote: this will enable verbose logging on Envoy\nglooctl proxy logs [flags]  Options  -d, --debug enable debug logging on the proxy as part of this command (default true) -f, --follow enable debug logging on the proxy as part of this command -h, --help help for logs -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode -p, --name string the name of the proxy service/deployment to use (default \u0026quot;gateway-proxy\u0026quot;) --port string the name of the service port to connect to (default \u0026quot;http\u0026quot;)  SEE ALSO  glooctl proxy - interact with proxy instances managed by Gloo  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_proxy_logs/",
	"title": "glooctl proxy logs",
	"tags": [],
	"description": "",
	"content": " glooctl proxy logs dump Envoy logs from one of the proxy instancesNote: this will enable verbose logging on Envoy\nSynopsis dump Envoy logs from one of the proxy instancesNote: this will enable verbose logging on Envoy\nglooctl proxy logs [flags]  Options  -d, --debug enable debug logging on the proxy as part of this command (default true) -f, --follow enable debug logging on the proxy as part of this command -h, --help help for logs -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode -p, --name string the name of the proxy service/deployment to use (default \u0026quot;gateway-proxy\u0026quot;) --port string the name of the service port to connect to (default \u0026quot;http\u0026quot;)  SEE ALSO  glooctl proxy - interact with proxy instances managed by Gloo  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_proxy_stats/",
	"title": "glooctl proxy stats",
	"tags": [],
	"description": "",
	"content": " glooctl proxy stats stats for one of the proxy instances\nSynopsis stats for one of the proxy instances\nglooctl proxy stats [flags]  Options  -h, --help help for stats -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode -p, --name string the name of the proxy service/deployment to use (default \u0026quot;gateway-proxy\u0026quot;) --port string the name of the service port to connect to (default \u0026quot;http\u0026quot;)  SEE ALSO  glooctl proxy - interact with proxy instances managed by Gloo  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_proxy_stats/",
	"title": "glooctl proxy stats",
	"tags": [],
	"description": "",
	"content": " glooctl proxy stats stats for one of the proxy instances\nSynopsis stats for one of the proxy instances\nglooctl proxy stats [flags]  Options  -h, --help help for stats -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode -p, --name string the name of the proxy service/deployment to use (default \u0026quot;gateway-proxy\u0026quot;) --port string the name of the service port to connect to (default \u0026quot;http\u0026quot;)  SEE ALSO  glooctl proxy - interact with proxy instances managed by Gloo  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_proxy_url/",
	"title": "glooctl proxy url",
	"tags": [],
	"description": "",
	"content": " glooctl proxy url print the http endpoint for a proxy\nSynopsis Use this command to view the HTTP URL of a Proxy reachable from outside the cluster. You can connect to this address from a host on the same network (such as the host machine, in the case of minikube/minishift).\nglooctl proxy url [flags]  Options  -h, --help help for url -l, --local-cluster use when the target kubernetes cluster is running locally, e.g. in minikube or minishift. this will default to true if LoadBalanced services are not assigned external IPs by your cluster -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode -p, --name string the name of the proxy service/deployment to use (default \u0026quot;gateway-proxy\u0026quot;) --port string the name of the service port to connect to (default \u0026quot;http\u0026quot;)  SEE ALSO  glooctl proxy - interact with proxy instances managed by Gloo  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_proxy_url/",
	"title": "glooctl proxy url",
	"tags": [],
	"description": "",
	"content": " glooctl proxy url print the http endpoint for a proxy\nSynopsis Use this command to view the HTTP URL of a Proxy reachable from outside the cluster. You can connect to this address from a host on the same network (such as the host machine, in the case of minikube/minishift).\nglooctl proxy url [flags]  Options  -h, --help help for url -l, --local-cluster use when the target kubernetes cluster is running locally, e.g. in minikube or minishift. this will default to true if LoadBalanced services are not assigned external IPs by your cluster -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode -p, --name string the name of the proxy service/deployment to use (default \u0026quot;gateway-proxy\u0026quot;) --port string the name of the service port to connect to (default \u0026quot;http\u0026quot;)  SEE ALSO  glooctl proxy - interact with proxy instances managed by Gloo  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_remove/",
	"title": "glooctl remove",
	"tags": [],
	"description": "",
	"content": " glooctl remove remove configuration items from a top-level Gloo resource\nSynopsis remove configuration items from a top-level Gloo resource\nOptions  -h, --help help for remove --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo glooctl remove route - Remove a Route from a Virtual Service  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_remove/",
	"title": "glooctl remove",
	"tags": [],
	"description": "",
	"content": " glooctl remove remove configuration items from a top-level Gloo resource\nSynopsis remove configuration items from a top-level Gloo resource\nOptions  -h, --help help for remove --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo glooctl remove route - Remove a Route from a Virtual Service  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_remove_route/",
	"title": "glooctl remove route",
	"tags": [],
	"description": "",
	"content": " glooctl remove route Remove a Route from a Virtual Service\nSynopsis Routes match patterns on requests and indicate the type of action to take when a proxy receives a matching request. Requests can be broken down into their Match and Action components. The order of routes within a Virtual Service matters. The first route in the virtual service that matches a given request will be selected for routing.\nIf no virtual service is specified for this command, glooctl add route will attempt to add it to a default virtualservice with domain \u0026lsquo;*\u0026lsquo;. if one does not exist, it will be created for you.\nUsage: glooctl rm route [--name virtual-service-name] [--namespace namespace] [--index x]\nglooctl remove route [flags]  Options  -h, --help help for route -x, --index uint32 remove the route with this index in the virtual service route list -o, --output string output format: (yaml, json, table)  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  SEE ALSO  glooctl remove - remove configuration items from a top-level Gloo resource  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_remove_route/",
	"title": "glooctl remove route",
	"tags": [],
	"description": "",
	"content": " glooctl remove route Remove a Route from a Virtual Service\nSynopsis Routes match patterns on requests and indicate the type of action to take when a proxy receives a matching request. Requests can be broken down into their Match and Action components. The order of routes within a Virtual Service matters. The first route in the virtual service that matches a given request will be selected for routing.\nIf no virtual service is specified for this command, glooctl add route will attempt to add it to a default virtualservice with domain \u0026lsquo;*\u0026lsquo;. if one does not exist, it will be created for you.\nUsage: glooctl rm route [--name virtual-service-name] [--namespace namespace] [--index x]\nglooctl remove route [flags]  Options  -h, --help help for route -x, --index uint32 remove the route with this index in the virtual service route list -o, --output string output format: (yaml, json, table)  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  SEE ALSO  glooctl remove - remove configuration items from a top-level Gloo resource  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_route/",
	"title": "glooctl route",
	"tags": [],
	"description": "",
	"content": " glooctl route subcommands for interacting with routes within virtual services\nSynopsis subcommands for interacting with routes within virtual services\nOptions  -h, --help help for route --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo glooctl route sort - sort routes on an existing virtual service  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_route/",
	"title": "glooctl route",
	"tags": [],
	"description": "",
	"content": " glooctl route subcommands for interacting with routes within virtual services\nSynopsis subcommands for interacting with routes within virtual services\nOptions  -h, --help help for route --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo glooctl route sort - sort routes on an existing virtual service  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_route_sort/",
	"title": "glooctl route sort",
	"tags": [],
	"description": "",
	"content": " glooctl route sort sort routes on an existing virtual service\nSynopsis The order of routes matters. A route is selected for a request based on the first matching route matcher in the virtual serivce\u0026rsquo;s list. sort automatically sorts the routes in the virtual service\nUsage: glooctl route sort [--name virtual-service-name] [--namespace virtual-service-namespace]\nglooctl route sort [flags]  Options  -h, --help help for sort -o, --output string output format: (yaml, json, table)  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  SEE ALSO  glooctl route - subcommands for interacting with routes within virtual services  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_route_sort/",
	"title": "glooctl route sort",
	"tags": [],
	"description": "",
	"content": " glooctl route sort sort routes on an existing virtual service\nSynopsis The order of routes matters. A route is selected for a request based on the first matching route matcher in the virtual serivce\u0026rsquo;s list. sort automatically sorts the routes in the virtual service\nUsage: glooctl route sort [--name virtual-service-name] [--namespace virtual-service-namespace]\nglooctl route sort [flags]  Options  -h, --help help for sort -o, --output string output format: (yaml, json, table)  Options inherited from parent commands  -i, --interactive use interactive mode --name string name of the resource to read or write -n, --namespace string namespace for reading or writing resources (default \u0026quot;gloo-system\u0026quot;)  SEE ALSO  glooctl route - subcommands for interacting with routes within virtual services  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_uninstall/",
	"title": "glooctl uninstall",
	"tags": [],
	"description": "",
	"content": " glooctl uninstall uninstall gloo\nSynopsis uninstall gloo\nglooctl uninstall [flags]  Options  -h, --help help for uninstall  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_uninstall/",
	"title": "glooctl uninstall",
	"tags": [],
	"description": "",
	"content": " glooctl uninstall uninstall gloo\nSynopsis uninstall gloo\nglooctl uninstall [flags]  Options  -h, --help help for uninstall  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo  "
},
{
	"uri": "https://gloo.solo.io/0.7/cli/glooctl_upgrade/",
	"title": "glooctl upgrade",
	"tags": [],
	"description": "",
	"content": " glooctl upgrade upgrade glooctl binary\nSynopsis upgrade glooctl binary\nglooctl upgrade [flags]  Options  -h, --help help for upgrade --path string Desired path for your upgraded glooctl binary. Defaults to the location of your currently executing binary. --release string Which glooctl release to download. Specify a git tag corresponding to the desired version of glooctl. (default \u0026quot;latest\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo  "
},
{
	"uri": "https://gloo.solo.io/0.8/cli/glooctl_upgrade/",
	"title": "glooctl upgrade",
	"tags": [],
	"description": "",
	"content": " glooctl upgrade upgrade glooctl binary\nSynopsis upgrade glooctl binary\nglooctl upgrade [flags]  Options  -h, --help help for upgrade --path string Desired path for your upgraded glooctl binary. Defaults to the location of your currently executing binary. --release string Which glooctl release to download. Specify a git tag corresponding to the desired version of glooctl. (default \u0026quot;latest\u0026quot;)  Options inherited from parent commands  -i, --interactive use interactive mode  SEE ALSO  glooctl - CLI for Gloo  "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/gogoproto/gogo.proto.sk/",
	"title": "gogo.proto",
	"tags": [],
	"description": "",
	"content": " Package: gogoproto Protocol Buffers for Go with Gadgets\nCopyright \u0026copy; 2013, The GoGo Authors. All rights reserved. http://github.com/gogo/protobuf\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n* Redistributions of source code must retain the above copyright  notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026ldquo;AS IS\u0026rdquo; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nSource File: gogoproto/gogo.proto  "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/gogoproto/gogo.proto.sk/",
	"title": "gogo.proto",
	"tags": [],
	"description": "",
	"content": " Package: gogoproto Protocol Buffers for Go with Gadgets\nCopyright \u0026copy; 2013, The GoGo Authors. All rights reserved. http://github.com/gogo/protobuf\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n* Redistributions of source code must retain the above copyright  notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026ldquo;AS IS\u0026rdquo; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nSource File: gogoproto/gogo.proto  "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/grpc/grpc.proto.sk/",
	"title": "grpc.proto",
	"tags": [],
	"description": "",
	"content": " Package: grpc.plugins.gloo.solo.io Types:  ServiceSpec GrpcService DestinationSpec   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/grpc/grpc.proto ServiceSpec Service spec describing GRPC upstreams. This will usually be filled automatically via function discovery (if the upstream supports reflection). If your upstream service is a GRPC service, use this service spec (an empty spec is fine), to make sure that traffic to it is routed with http2.\n\u0026quot;descriptors\u0026quot;: bytes \u0026quot;grpc_services\u0026quot;: []grpc.plugins.gloo.solo.io.ServiceSpec.GrpcService     Field Type Description Default     descriptors bytes Descriptors that contain information of the services listed below. this is a serialized google.protobuf.FileDescriptorSet    grpc_services []grpc.plugins.gloo.solo.io.ServiceSpec.GrpcService List of services used by this upstream. For a grpc upstream where you don\u0026rsquo;t need to use Gloo\u0026rsquo;s function routing, this can be an empty list. These services must be present in the descriptors.     GrpcService Describes a grpc service\n\u0026quot;package_name\u0026quot;: string \u0026quot;service_name\u0026quot;: string \u0026quot;function_names\u0026quot;: []string     Field Type Description Default     package_name string The package of this service.    service_name string The service name of this service.    function_names []string The functions available in this service.     DestinationSpec This is only for upstream with Grpc service spec.\n\u0026quot;package\u0026quot;: string \u0026quot;service\u0026quot;: string \u0026quot;function\u0026quot;: string \u0026quot;parameters\u0026quot;: .transformation.plugins.gloo.solo.io.Parameters     Field Type Description Default     package string The proto package of the function.    service string The name of the service of the function.    function string The name of the function.    parameters .transformation.plugins.gloo.solo.io.Parameters Parameters describe how to extract the function parameters from the request.      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/grpc/grpc.proto.sk/",
	"title": "grpc.proto",
	"tags": [],
	"description": "",
	"content": " Package: grpc.plugins.gloo.solo.io Types:  ServiceSpec GrpcService DestinationSpec   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/grpc/grpc.proto ServiceSpec Service spec describing GRPC upstreams. This will usually be filled automatically via function discovery (if the upstream supports reflection). If your upstream service is a GRPC service, use this service spec (an empty spec is fine), to make sure that traffic to it is routed with http2.\n\u0026quot;descriptors\u0026quot;: bytes \u0026quot;grpc_services\u0026quot;: []grpc.plugins.gloo.solo.io.ServiceSpec.GrpcService     Field Type Description Default     descriptors bytes Descriptors that contain information of the services listed below. this is a serialized google.protobuf.FileDescriptorSet    grpc_services []grpc.plugins.gloo.solo.io.ServiceSpec.GrpcService List of services used by this upstream. For a grpc upstream where you don\u0026rsquo;t need to use Gloo\u0026rsquo;s function routing, this can be an empty list. These services must be present in the descriptors.     GrpcService Describes a grpc service\n\u0026quot;package_name\u0026quot;: string \u0026quot;service_name\u0026quot;: string \u0026quot;function_names\u0026quot;: []string     Field Type Description Default     package_name string The package of this service.    service_name string The service name of this service.    function_names []string The functions available in this service.     DestinationSpec This is only for upstream with Grpc service spec.\n\u0026quot;package\u0026quot;: string \u0026quot;service\u0026quot;: string \u0026quot;function\u0026quot;: string \u0026quot;parameters\u0026quot;: .transformation.plugins.gloo.solo.io.Parameters     Field Type Description Default     package string The proto package of the function.    service string The name of the service of the function.    function string The name of the function.    parameters .transformation.plugins.gloo.solo.io.Parameters Parameters describe how to extract the function parameters from the request.      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/ingress/api/v1/ingress.proto.sk/",
	"title": "ingress.proto",
	"tags": [],
	"description": "",
	"content": " Package: ingress.solo.io Types:  Ingress Top-Level Resource   Source File: github.com/solo-io/gloo/projects/ingress/api/v1/ingress.proto Ingress A simple wrapper for a Kubernetes Ingress Object.\n\u0026quot;kube_ingress_spec\u0026quot;: .google.protobuf.Any \u0026quot;kube_ingress_status\u0026quot;: .google.protobuf.Any \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata     Field Type Description Default     kube_ingress_spec .google.protobuf.Any a raw byte representation of the kubernetes ingress this resource wraps    kube_ingress_status .google.protobuf.Any a raw byte representation of the ingress status of the kubernetes ingress object    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/ingress/api/v1/ingress.proto.sk/",
	"title": "ingress.proto",
	"tags": [],
	"description": "",
	"content": " Package: ingress.solo.io Types:  Ingress Top-Level Resource   Source File: github.com/solo-io/gloo/projects/ingress/api/v1/ingress.proto Ingress A simple wrapper for a Kubernetes Ingress Object.\n\u0026quot;kube_ingress_spec\u0026quot;: .google.protobuf.Any \u0026quot;kube_ingress_status\u0026quot;: .google.protobuf.Any \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata     Field Type Description Default     kube_ingress_spec .google.protobuf.Any a raw byte representation of the kubernetes ingress this resource wraps    kube_ingress_status .google.protobuf.Any a raw byte representation of the ingress status of the kubernetes ingress object    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/kubernetes/kubernetes.proto.sk/",
	"title": "kubernetes.proto",
	"tags": [],
	"description": "",
	"content": " Package: kubernetes.plugins.gloo.solo.io Types:  UpstreamSpec   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/kubernetes/kubernetes.proto UpstreamSpec Upstream Spec for Kubernetes Upstreams Kubernetes Upstreams represent a set of one or more addressable pods for a Kubernetes Service the Gloo Kubernetes Upstream maps to a single service port. Because Kubernetes Services support multiple ports, Gloo requires that a different upstream be created for each port Kubernetes Upstreams are typically generated automatically by Gloo from the Kubernetes API\n\u0026quot;service_name\u0026quot;: string \u0026quot;service_namespace\u0026quot;: string \u0026quot;service_port\u0026quot;: int \u0026quot;selector\u0026quot;: map\u0026lt;string, string\u0026gt; \u0026quot;service_spec\u0026quot;: .plugins.gloo.solo.io.ServiceSpec     Field Type Description Default     service_name string The name of the Kubernetes Service    service_namespace string The namespace where the Service lives    service_port int The access port port of the kubernetes service is listening. This port is used by Gloo to look up the corresponding port on the pod for routing.    selector map\u0026lt;string, string\u0026gt; Allows finer-grained filtering of pods for the Upstream. Gloo will select pods based on their labels if any are provided here. (see Kubernetes labels and selectors    service_spec .plugins.gloo.solo.io.ServiceSpec An optional Service Spec describing the service listening at this address      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/kubernetes/kubernetes.proto.sk/",
	"title": "kubernetes.proto",
	"tags": [],
	"description": "",
	"content": " Package: kubernetes.plugins.gloo.solo.io Types:  UpstreamSpec   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/kubernetes/kubernetes.proto UpstreamSpec Upstream Spec for Kubernetes Upstreams Kubernetes Upstreams represent a set of one or more addressable pods for a Kubernetes Service the Gloo Kubernetes Upstream maps to a single service port. Because Kubernetes Services support multiple ports, Gloo requires that a different upstream be created for each port Kubernetes Upstreams are typically generated automatically by Gloo from the Kubernetes API\n\u0026quot;service_name\u0026quot;: string \u0026quot;service_namespace\u0026quot;: string \u0026quot;service_port\u0026quot;: int \u0026quot;selector\u0026quot;: map\u0026lt;string, string\u0026gt; \u0026quot;service_spec\u0026quot;: .plugins.gloo.solo.io.ServiceSpec     Field Type Description Default     service_name string The name of the Kubernetes Service    service_namespace string The namespace where the Service lives    service_port int The access port port of the kubernetes service is listening. This port is used by Gloo to look up the corresponding port on the pod for routing.    selector map\u0026lt;string, string\u0026gt; Allows finer-grained filtering of pods for the Upstream. Gloo will select pods based on their labels if any are provided here. (see Kubernetes labels and selectors    service_spec .plugins.gloo.solo.io.ServiceSpec An optional Service Spec describing the service listening at this address      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/solo-kit/api/v1/metadata.proto.sk/",
	"title": "metadata.proto",
	"tags": [],
	"description": "",
	"content": " Package: core.solo.io Types:  Metadata   Source File: github.com/solo-io/solo-kit/api/v1/metadata.proto Metadata * Metadata contains general properties of resources for purposes of versioning, annotating, and namespacing.\n\u0026quot;name\u0026quot;: string \u0026quot;namespace\u0026quot;: string \u0026quot;resource_version\u0026quot;: string \u0026quot;labels\u0026quot;: map\u0026lt;string, string\u0026gt; \u0026quot;annotations\u0026quot;: map\u0026lt;string, string\u0026gt;     Field Type Description Default     name string Name of the resource. Names must be unique and follow the following syntax rules: One or more lowercase rfc1035/rfc1123 labels separated by \u0026lsquo;.\u0026rsquo; with a maximum length of 253 characters.    namespace string Namespace is used for the namespacing of resources.    resource_version string An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed.    labels map\u0026lt;string, string\u0026gt; Map of string keys and values that can be used to organize and categorize (scope and select) objects. Some resources contain selectors which can be linked with other resources by their labels    annotations map\u0026lt;string, string\u0026gt; Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata.      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/solo-kit/api/v1/metadata.proto.sk/",
	"title": "metadata.proto",
	"tags": [],
	"description": "",
	"content": " Package: core.solo.io Types:  Metadata   Source File: github.com/solo-io/solo-kit/api/v1/metadata.proto Metadata * Metadata contains general properties of resources for purposes of versioning, annotating, and namespacing.\n\u0026quot;name\u0026quot;: string \u0026quot;namespace\u0026quot;: string \u0026quot;resource_version\u0026quot;: string \u0026quot;labels\u0026quot;: map\u0026lt;string, string\u0026gt; \u0026quot;annotations\u0026quot;: map\u0026lt;string, string\u0026gt;     Field Type Description Default     name string Name of the resource. Names must be unique and follow the following syntax rules: One or more lowercase rfc1035/rfc1123 labels separated by \u0026lsquo;.\u0026rsquo; with a maximum length of 253 characters.    namespace string Namespace is used for the namespacing of resources.    resource_version string An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed.    labels map\u0026lt;string, string\u0026gt; Map of string keys and values that can be used to organize and categorize (scope and select) objects. Some resources contain selectors which can be linked with other resources by their labels    annotations map\u0026lt;string, string\u0026gt; Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata.      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/transformation/parameters.proto.sk/",
	"title": "parameters.proto",
	"tags": [],
	"description": "",
	"content": " Package: transformation.plugins.gloo.solo.io Types:  Parameters   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/transformation/parameters.proto Parameters \u0026quot;headers\u0026quot;: map\u0026lt;string, string\u0026gt; \u0026quot;path\u0026quot;: .google.protobuf.StringValue     Field Type Description Default     headers map\u0026lt;string, string\u0026gt; headers that will be used to extract data for processing output templates Gloo will search for parameters by their name in header value strings, enclosed in single curly braces Example: extensions: parameters: headers: x-user-id: { userId }    path .google.protobuf.StringValue part of the (or the entire) path that will be used extract data for processing output templates Gloo will search for parameters by their name in header value strings, enclosed in single curly braces Example: extensions: parameters: path: /users/{ userId }      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/transformation/parameters.proto.sk/",
	"title": "parameters.proto",
	"tags": [],
	"description": "",
	"content": " Package: transformation.plugins.gloo.solo.io Types:  Parameters   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/transformation/parameters.proto Parameters \u0026quot;headers\u0026quot;: map\u0026lt;string, string\u0026gt; \u0026quot;path\u0026quot;: .google.protobuf.StringValue     Field Type Description Default     headers map\u0026lt;string, string\u0026gt; headers that will be used to extract data for processing output templates Gloo will search for parameters by their name in header value strings, enclosed in single curly braces Example: extensions: parameters: headers: x-user-id: { userId }    path .google.protobuf.StringValue part of the (or the entire) path that will be used extract data for processing output templates Gloo will search for parameters by their name in header value strings, enclosed in single curly braces Example: extensions: parameters: path: /users/{ userId }      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins.proto.sk/",
	"title": "plugins.proto",
	"tags": [],
	"description": "",
	"content": " Package: gloo.solo.io Types:  ListenerPlugins VirtualHostPlugins RoutePlugins DestinationSpec UpstreamSpec   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins.proto ListenerPlugins Plugin-specific configuration that lives on listeners Each ListenerPlugin object contains configuration for a specific plugin Note to developers: new Listener Plugins must be added to this struct to be usable by Gloo.\n    Field Type Description Default      VirtualHostPlugins Plugin-specific configuration that lives on virtual hosts Each VirtualHostPlugin object contains configuration for a specific plugin Note to developers: new Virtual Host Plugins must be added to this struct to be usable by Gloo.\n\u0026quot;extensions\u0026quot;: .gloo.solo.io.Extensions     Field Type Description Default     extensions .gloo.solo.io.Extensions      RoutePlugins Plugin-specific configuration that lives on routes Each RoutePlugin object contains configuration for a specific plugin Note to developers: new Route Plugins must be added to this struct to be usable by Gloo.\n\u0026quot;transformations\u0026quot;: .transformation.plugins.gloo.solo.io.RouteTransformations \u0026quot;faults\u0026quot;: .fault.plugins.gloo.solo.io.RouteFaults \u0026quot;prefix_rewrite\u0026quot;: .transformation.plugins.gloo.solo.io.PrefixRewrite \u0026quot;timeout\u0026quot;: .google.protobuf.Duration \u0026quot;retries\u0026quot;: .retries.plugins.gloo.solo.io.RetryPolicy \u0026quot;extensions\u0026quot;: .gloo.solo.io.Extensions     Field Type Description Default     transformations .transformation.plugins.gloo.solo.io.RouteTransformations     faults .fault.plugins.gloo.solo.io.RouteFaults     prefix_rewrite .transformation.plugins.gloo.solo.io.PrefixRewrite     timeout .google.protobuf.Duration     retries .retries.plugins.gloo.solo.io.RetryPolicy     extensions .gloo.solo.io.Extensions      DestinationSpec Configuration for Destinations that are tied to the UpstreamSpec or ServiceSpec on that destination\n\u0026quot;aws\u0026quot;: .aws.plugins.gloo.solo.io.DestinationSpec \u0026quot;azure\u0026quot;: .azure.plugins.gloo.solo.io.DestinationSpec \u0026quot;rest\u0026quot;: .rest.plugins.gloo.solo.io.DestinationSpec \u0026quot;grpc\u0026quot;: .grpc.plugins.gloo.solo.io.DestinationSpec     Field Type Description Default     aws .aws.plugins.gloo.solo.io.DestinationSpec     azure .azure.plugins.gloo.solo.io.DestinationSpec     rest .rest.plugins.gloo.solo.io.DestinationSpec     grpc .grpc.plugins.gloo.solo.io.DestinationSpec      UpstreamSpec Each upstream in Gloo has a type. Supported types include static, kubernetes, aws, consul, and more. Each upstream type is handled by a corresponding Gloo plugin.\n\u0026quot;kube\u0026quot;: .kubernetes.plugins.gloo.solo.io.UpstreamSpec \u0026quot;static\u0026quot;: .static.plugins.gloo.solo.io.UpstreamSpec \u0026quot;aws\u0026quot;: .aws.plugins.gloo.solo.io.UpstreamSpec \u0026quot;azure\u0026quot;: .azure.plugins.gloo.solo.io.UpstreamSpec \u0026quot;consul\u0026quot;: .consul.plugins.gloo.solo.io.UpstreamSpec     Field Type Description Default     kube .kubernetes.plugins.gloo.solo.io.UpstreamSpec     static .static.plugins.gloo.solo.io.UpstreamSpec     aws .aws.plugins.gloo.solo.io.UpstreamSpec     azure .azure.plugins.gloo.solo.io.UpstreamSpec     consul .consul.plugins.gloo.solo.io.UpstreamSpec       "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins.proto.sk/",
	"title": "plugins.proto",
	"tags": [],
	"description": "",
	"content": " Package: gloo.solo.io Types:  ListenerPlugins VirtualHostPlugins RoutePlugins DestinationSpec UpstreamSpec   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins.proto ListenerPlugins Plugin-specific configuration that lives on listeners Each ListenerPlugin object contains configuration for a specific plugin Note to developers: new Listener Plugins must be added to this struct to be usable by Gloo.\n    Field Type Description Default      VirtualHostPlugins Plugin-specific configuration that lives on virtual hosts Each VirtualHostPlugin object contains configuration for a specific plugin Note to developers: new Virtual Host Plugins must be added to this struct to be usable by Gloo.\n\u0026quot;extensions\u0026quot;: .gloo.solo.io.Extensions     Field Type Description Default     extensions .gloo.solo.io.Extensions      RoutePlugins Plugin-specific configuration that lives on routes Each RoutePlugin object contains configuration for a specific plugin Note to developers: new Route Plugins must be added to this struct to be usable by Gloo.\n\u0026quot;transformations\u0026quot;: .transformation.plugins.gloo.solo.io.RouteTransformations \u0026quot;faults\u0026quot;: .fault.plugins.gloo.solo.io.RouteFaults \u0026quot;prefix_rewrite\u0026quot;: .transformation.plugins.gloo.solo.io.PrefixRewrite \u0026quot;timeout\u0026quot;: .google.protobuf.Duration \u0026quot;retries\u0026quot;: .retries.plugins.gloo.solo.io.RetryPolicy \u0026quot;extensions\u0026quot;: .gloo.solo.io.Extensions     Field Type Description Default     transformations .transformation.plugins.gloo.solo.io.RouteTransformations     faults .fault.plugins.gloo.solo.io.RouteFaults     prefix_rewrite .transformation.plugins.gloo.solo.io.PrefixRewrite     timeout .google.protobuf.Duration     retries .retries.plugins.gloo.solo.io.RetryPolicy     extensions .gloo.solo.io.Extensions      DestinationSpec Configuration for Destinations that are tied to the UpstreamSpec or ServiceSpec on that destination\n\u0026quot;aws\u0026quot;: .aws.plugins.gloo.solo.io.DestinationSpec \u0026quot;azure\u0026quot;: .azure.plugins.gloo.solo.io.DestinationSpec \u0026quot;rest\u0026quot;: .rest.plugins.gloo.solo.io.DestinationSpec \u0026quot;grpc\u0026quot;: .grpc.plugins.gloo.solo.io.DestinationSpec     Field Type Description Default     aws .aws.plugins.gloo.solo.io.DestinationSpec     azure .azure.plugins.gloo.solo.io.DestinationSpec     rest .rest.plugins.gloo.solo.io.DestinationSpec     grpc .grpc.plugins.gloo.solo.io.DestinationSpec      UpstreamSpec Each upstream in Gloo has a type. Supported types include static, kubernetes, aws, consul, and more. Each upstream type is handled by a corresponding Gloo plugin.\n\u0026quot;kube\u0026quot;: .kubernetes.plugins.gloo.solo.io.UpstreamSpec \u0026quot;static\u0026quot;: .static.plugins.gloo.solo.io.UpstreamSpec \u0026quot;aws\u0026quot;: .aws.plugins.gloo.solo.io.UpstreamSpec \u0026quot;azure\u0026quot;: .azure.plugins.gloo.solo.io.UpstreamSpec \u0026quot;consul\u0026quot;: .consul.plugins.gloo.solo.io.UpstreamSpec     Field Type Description Default     kube .kubernetes.plugins.gloo.solo.io.UpstreamSpec     static .static.plugins.gloo.solo.io.UpstreamSpec     aws .aws.plugins.gloo.solo.io.UpstreamSpec     azure .azure.plugins.gloo.solo.io.UpstreamSpec     consul .consul.plugins.gloo.solo.io.UpstreamSpec       "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/transformation/prefix_rewrite.proto.sk/",
	"title": "prefix_rewrite.proto",
	"tags": [],
	"description": "",
	"content": " Package: transformation.plugins.gloo.solo.io TODO: this was copied form the transformation filter. TODO: instead of manually copying, we want to do it via script, similar to the java-control-plane TODO: to solo-kit/api/envoy\nTypes:  PrefixRewrite   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/transformation/prefix_rewrite.proto PrefixRewrite if set, prefix_rewrite will be used to rewrite the matched HTTP Path prefix on requests to this value.\n\u0026quot;prefix_rewrite\u0026quot;: string     Field Type Description Default     prefix_rewrite string Set to an empty string to remove the matched HTTP Path prefix      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/transformation/prefix_rewrite.proto.sk/",
	"title": "prefix_rewrite.proto",
	"tags": [],
	"description": "",
	"content": " Package: transformation.plugins.gloo.solo.io TODO: this was copied form the transformation filter. TODO: instead of manually copying, we want to do it via script, similar to the java-control-plane TODO: to solo-kit/api/envoy\nTypes:  PrefixRewrite   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/transformation/prefix_rewrite.proto PrefixRewrite if set, prefix_rewrite will be used to rewrite the matched HTTP Path prefix on requests to this value.\n\u0026quot;prefix_rewrite\u0026quot;: string     Field Type Description Default     prefix_rewrite string Set to an empty string to remove the matched HTTP Path prefix      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/proxy.proto.sk/",
	"title": "proxy.proto",
	"tags": [],
	"description": "",
	"content": " Package: gloo.solo.io Types:  Proxy Top-Level Resource Listener HttpListener VirtualHost Route Matcher HeaderMatcher QueryParameterMatcher RouteAction Destination MultiDestination WeightedDestination RedirectAction RedirectResponseCode DirectResponseAction SslConfig SSLFiles   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/proxy.proto Proxy A Proxy is a container for the entire set of configuration that will to be applied to one or more Proxy instances. Proxies can be understood as a set of listeners, represents a different bind address/port where the proxy will listen for connections. Each listener has its own set of configuration.\nIf any of the sub-resources within a listener is declared invalid (e.g. due to invalid user configuration), the proxy will be marked invalid by Gloo.\nProxy instances that register with Gloo are assigned the proxy configuration corresponding with a proxy-specific identifier. In the case of Envoy, proxy instances are identified by their Node ID. Node IDs must match a existing Proxy Node ID can be specified in Envoy with the --service-node flag, or in the Envoy instance\u0026rsquo;s bootstrap config.\n\u0026quot;listeners\u0026quot;: []gloo.solo.io.Listener \u0026quot;status\u0026quot;: .core.solo.io.Status \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata     Field Type Description Default     listeners []gloo.solo.io.Listener Define here each listener the proxy should create. Listeners define the a set of behaviors for a single bind address/port where the proxy will listen If no listeners are specified, the instances configured with the proxy resource will not accept connections.    status .core.solo.io.Status Status indicates the validation status of this resource. Status is read-only by clients, and set by gloo during validation    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource     Listener Listeners define the address:port where the proxy will listen for incoming connections A Listener accepts connections (currently only HTTP is supported) and apply user-defined behavior for those connections, e.g. performing SSL termination, HTTP retries, and rate limiting.\n\u0026quot;name\u0026quot;: string \u0026quot;bind_address\u0026quot;: string \u0026quot;bind_port\u0026quot;: int \u0026quot;http_listener\u0026quot;: .gloo.solo.io.HttpListener \u0026quot;ssl_configuations\u0026quot;: []gloo.solo.io.SslConfig     Field Type Description Default     name string the name of the listener. names must be unique for each listener within a proxy    bind_address string the bind address for the listener. both ipv4 and ipv6 formats are supported    bind_port int the port to bind on ports numbers must be unique for listeners within a proxy    http_listener .gloo.solo.io.HttpListener The HTTP Listener is currently the only supported listener type. It contains configuration options for GLoo\u0026rsquo;s HTTP-level features including request-based routing    ssl_configuations []gloo.solo.io.SslConfig SSL Config is optional for the listener. If provided, the listener will serve TLS for connections on this port Multiple SslConfigs are supported for the pupose of SNI. Be aware that the SNI domain provided in the SSL Config must match a domain in virtual host TODO(ilackarms): ensure that ssl configs without a matching virtual host are errored     HttpListener Use this listener to configure proxy behavior for any HTTP-level features including defining routes (via virtualservices). HttpListeners also contain plugin configuration that applies globally across all virtaul hosts on the listener. Some plugins can be configured to work both on the listener and virtual host level (such as the rate limit plugin)\n\u0026quot;virtual_hosts\u0026quot;: []gloo.solo.io.VirtualHost \u0026quot;listener_plugins\u0026quot;: .gloo.solo.io.ListenerPlugins     Field Type Description Default     virtual_hosts []gloo.solo.io.VirtualHost the set of virtual hosts that will be accessible by clients connecting to this listener. at least one virtual host must be specified for this listener to be active (else connections will be refused) the set of domains for each virtual host must be unique, or the config will be considered invalid    listener_plugins .gloo.solo.io.ListenerPlugins Plugins contains top-level plugin configuration to be applied to a listener Listener config is applied to all HTTP traffic that connects to this listener. Some configuration here can be overridden in Virtual Host Plugin configuration or Route Plugin configuration Plugins should be specified here in the form of \u0026quot;plugin_name\u0026quot;: {..//plugin_config...} to allow specifying multiple plugins.     VirtualHost Virtual Hosts group an ordered list of routes under one or more domains. Each Virtual Host has a logical name, which must be unique for the listener. An HTTP request is first matched to a virtual host based on its host header, then to a route within the virtual host. If a request is not matched to any virtual host or a route therein, the target proxy will reply with a 404.\n\u0026quot;name\u0026quot;: string \u0026quot;domains\u0026quot;: []string \u0026quot;routes\u0026quot;: []gloo.solo.io.Route \u0026quot;virtual_host_plugins\u0026quot;: .gloo.solo.io.VirtualHostPlugins     Field Type Description Default     name string the logical name of the virtual host. names must be unique for each virtual host within a listener    domains []string The list of domains (i.e.: matching the Host header of a request) that belong to this virtual host. Note that the wildcard will not match the empty string. e.g. “*-bar.foo.com” will match “baz-bar.foo.com” but not “-bar.foo.com”. Additionally, a special entry “*” is allowed which will match any host/authority header. Only a single virtual host in the entire route configuration can match on “*”. A domain must be unique across all virtual hosts or the config will be invalidated by Gloo Domains on virtual hosts obey the same rules as Envoy Virtual Hosts    routes []gloo.solo.io.Route The list of HTTP routes define routing actions to be taken for incoming HTTP requests whose host header matches this virtual host. If the request matches more than one route in the list, the first route matched will be selected. If the list of routes is empty, the virtual host will be ignored by Gloo.    virtual_host_plugins .gloo.solo.io.VirtualHostPlugins Plugins contains top-level plugin configuration to be applied to a listener Listener config is applied to all HTTP traffic that connects to this listener. Some configuration here can be overridden in Virtual Host Plugin configuration or Route Plugin configuration Plugins should be specified here in the form of \u0026quot;plugin_name\u0026quot;: {..//plugin_config...} to allow specifying multiple plugins.     Route * Routes declare the entrypoints on virtual hosts and the action to take for matched requests.\n\u0026quot;matcher\u0026quot;: .gloo.solo.io.Matcher \u0026quot;route_action\u0026quot;: .gloo.solo.io.RouteAction \u0026quot;redirect_action\u0026quot;: .gloo.solo.io.RedirectAction \u0026quot;direct_response_action\u0026quot;: .gloo.solo.io.DirectResponseAction \u0026quot;route_plugins\u0026quot;: .gloo.solo.io.RoutePlugins     Field Type Description Default     matcher .gloo.solo.io.Matcher The matcher contains parameters for matching requests (i.e.: based on HTTP path, headers, etc.)    route_action .gloo.solo.io.RouteAction This action is the primary action to be selected for most routes. The RouteAction tells the proxy to route requests to an upstream.    redirect_action .gloo.solo.io.RedirectAction Redirect actions tell the proxy to return a redirect response to the downstream client    direct_response_action .gloo.solo.io.DirectResponseAction Return an arbitrary HTTP response directly, without proxying.    route_plugins .gloo.solo.io.RoutePlugins Route Plugins extend the behavior of routes. Route plugins include configuration such as retries, rate limiting, and request/resonse transformation. Plugins should be specified here in the form of \u0026quot;plugin_name\u0026quot;: {..//plugin_config...} to allow specifying multiple plugins.     Matcher Parameters for matching routes to requests received by a Gloo-managed proxy\n\u0026quot;prefix\u0026quot;: string \u0026quot;exact\u0026quot;: string \u0026quot;regex\u0026quot;: string \u0026quot;headers\u0026quot;: []gloo.solo.io.HeaderMatcher \u0026quot;query_parameters\u0026quot;: []gloo.solo.io.QueryParameterMatcher \u0026quot;methods\u0026quot;: []string     Field Type Description Default     prefix string If specified, the route is a prefix rule meaning that the prefix must match the beginning of the :path header.    exact string If specified, the route is an exact path rule meaning that the path must exactly match the :path header once the query string is removed.    regex string If specified, the route is a regular expression rule meaning that the regex must match the :path header once the query string is removed. The entire path (without the query string) must match the regex. The rule will not match if only a subsequence of the :path header matches the regex. The regex grammar is defined here \u0026lt;http://en.cppreference.com/w/cpp/regex/ecmascript\u0026gt;_. Examples: * The regex /b[io]t matches the path /bit * The regex /b[io]t matches the path /bot * The regex /b[io]t does not match the path /bite * The regex /b[io]t does not match the path /bit/bot    headers []gloo.solo.io.HeaderMatcher Specifies a set of headers that the route should match on. The router will check the request’s headers against all the specified headers in the route config. A match will happen if all the headers in the route are present in the request with the same values (or based on presence if the value field is not in the config).    query_parameters []gloo.solo.io.QueryParameterMatcher Specifies a set of URL query parameters on which the route should match. The router will check the query string from the path header against all the specified query parameters. If the number of specified query parameters is nonzero, they all must match the path header\u0026rsquo;s query string for a match to occur.    methods []string HTTP Method/Verb(s) to match on. If none specified, the matcher will ignore the HTTP Method     HeaderMatcher Internally, Gloo always uses the HTTP/2 :authority header to represent the HTTP/1 Host header. Thus, if attempting to match on Host, match on :authority instead.\nIn the absence of any header match specifier, match will default to present_match i.e, a request that has the name header will match, regardless of the header\u0026rsquo;s value.\n\u0026quot;name\u0026quot;: string \u0026quot;value\u0026quot;: string \u0026quot;regex\u0026quot;: bool     Field Type Description Default     name string Specifies the name of the header in the request.    value string Specifies the value of the header. If the value is absent a request that has the name header will match, regardless of the header’s value.    regex bool Specifies whether the header value should be treated as regex or not.     QueryParameterMatcher Query parameter matching treats the query string of a request\u0026rsquo;s :path header as an ampersand-separated list of keys and/or key=value elements.\n\u0026quot;name\u0026quot;: string \u0026quot;value\u0026quot;: string \u0026quot;regex\u0026quot;: bool     Field Type Description Default     name string Specifies the name of a key that must be present in the requested path\u0026rsquo;s query string.    value string Specifies the value of the key. If the value is absent, a request that contains the key in its query string will match, whether the key appears with a value (e.g., \u0026ldquo;?debug=true\u0026rdquo;) or not (e.g., \u0026ldquo;?debug\u0026rdquo;)    regex bool Specifies whether the query parameter value is a regular expression. Defaults to false. The entire query parameter value (i.e., the part to the right of the equals sign in \u0026ldquo;key=value\u0026rdquo;) must match the regex. E.g., the regex \u0026ldquo;\\d+$\u0026rdquo; will match \u0026ldquo;123\u0026rdquo; but not \u0026ldquo;a123\u0026rdquo; or \u0026ldquo;123a\u0026rdquo;.     RouteAction RouteActions are used to route matched requests to upstreams.\n\u0026quot;single\u0026quot;: .gloo.solo.io.Destination \u0026quot;multi\u0026quot;: .gloo.solo.io.MultiDestination     Field Type Description Default     single .gloo.solo.io.Destination Use SingleDestination to route to a single upstream    multi .gloo.solo.io.MultiDestination Use MultiDestination to load balance requests between multiple upstreams (by weight)     Destination Destinations define routable destinations for proxied requests\n\u0026quot;upstream\u0026quot;: .core.solo.io.ResourceRef \u0026quot;destination_spec\u0026quot;: .gloo.solo.io.DestinationSpec     Field Type Description Default     upstream .core.solo.io.ResourceRef The upstream to route requests to    destination_spec .gloo.solo.io.DestinationSpec Some upstreams utilize plugins which require or permit additional configuration on routes targeting them. gRPC upstreams, for example, allow specifying REST-style parameters for JSON-to-gRPC transcoding in the destination config. If the destination config is required for the upstream and not provided by the user, Gloo will invalidate the destination and its parent resources.     MultiDestination MultiDestination is a container for a set of weighted destinations. Gloo will load balance traffic for a single route across multiple destinations according to their specified weights.\n\u0026quot;destinations\u0026quot;: []gloo.solo.io.WeightedDestination     Field Type Description Default     destinations []gloo.solo.io.WeightedDestination This list must contain at least one destination or the listener housing this route will be invalid, causing Gloo to error the parent proxy resource.     WeightedDestination WeightedDestination attaches a weight to a single destination.\n\u0026quot;destination\u0026quot;: .gloo.solo.io.Destination \u0026quot;weight\u0026quot;: int     Field Type Description Default     destination .gloo.solo.io.Destination     weight int Weight must be greater than zero Routing to each destination will be balanced by the ratio of the destination\u0026rsquo;s weight to the total weight on a route     RedirectAction TODO(ilackarms): evaluate how much to differentiate (or if even to include) RedirectAction Notice: RedirectAction is copioed directly from https://github.com/envoyproxy/envoy/blob/master/api/envoy/api/v2/route/route.proto\n\u0026quot;host_redirect\u0026quot;: string \u0026quot;path_redirect\u0026quot;: string \u0026quot;prefix_rewrite\u0026quot;: string \u0026quot;response_code\u0026quot;: .gloo.solo.io.RedirectAction.RedirectResponseCode \u0026quot;https_redirect\u0026quot;: bool \u0026quot;strip_query\u0026quot;: bool     Field Type Description Default     host_redirect string The host portion of the URL will be swapped with this value.    path_redirect string The path portion of the URL will be swapped with this value.    prefix_rewrite string Indicates that during redirection, the matched prefix (or path) should be swapped with this value. This option allows redirect URLs be dynamically created based on the request. Pay attention to the use of trailing slashes as mentioned in RouteAction\u0026rsquo;s prefix_rewrite.    response_code .gloo.solo.io.RedirectAction.RedirectResponseCode The HTTP status code to use in the redirect response. The default response code is MOVED_PERMANENTLY (301).    https_redirect bool The scheme portion of the URL will be swapped with \u0026ldquo;https\u0026rdquo;.    strip_query bool Indicates that during redirection, the query portion of the URL will be removed. Default value is false.     RedirectResponseCode    Name Description     MOVED_PERMANENTLY Moved Permanently HTTP Status Code - 301.   FOUND Found HTTP Status Code - 302.   SEE_OTHER See Other HTTP Status Code - 303.   TEMPORARY_REDIRECT Temporary Redirect HTTP Status Code - 307.   PERMANENT_REDIRECT Permanent Redirect HTTP Status Code - 308.    DirectResponseAction TODO(ilackarms): evaluate how much to differentiate (or if even to include) DirectResponseAction DirectResponseAction is copied directly from https://github.com/envoyproxy/envoy/blob/master/api/envoy/api/v2/route/route.proto\n\u0026quot;status\u0026quot;: int \u0026quot;body\u0026quot;: string     Field Type Description Default     status int Specifies the HTTP response status to be returned.    body string Specifies the content of the response body. If this setting is omitted, no body is included in the generated response. Note: Headers can be specified using the Header Modification plugin in the enclosing Route, Virtual Host, or Listener.     SslConfig SslConfig contains the options necessary to configure a virtual host or listener to use TLS\n\u0026quot;secret_ref\u0026quot;: .core.solo.io.ResourceRef \u0026quot;ssl_files\u0026quot;: .gloo.solo.io.SSLFiles \u0026quot;sni_domains\u0026quot;: []string     Field Type Description Default     secret_ref .core.solo.io.ResourceRef * SecretRef contains the secret ref to a gloo secret containing the following structure: { \u0026ldquo;tls.crt\u0026rdquo;: , \u0026ldquo;tls.key\u0026rdquo;: }    ssl_files .gloo.solo.io.SSLFiles SSLFiles reference paths to certificates which are local to the proxy    sni_domains []string optional. the SNI domains that should be considered for TLS connections     SSLFiles SSLFiles reference paths to certificates which can be read by the proxy off of its local filesystem\n\u0026quot;tls_cert\u0026quot;: string \u0026quot;tls_key\u0026quot;: string \u0026quot;root_ca\u0026quot;: string     Field Type Description Default     tls_cert string     tls_key string     root_ca string for client cert validation. optional      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/proxy.proto.sk/",
	"title": "proxy.proto",
	"tags": [],
	"description": "",
	"content": " Package: gloo.solo.io Types:  Proxy Top-Level Resource Listener HttpListener VirtualHost Route Matcher HeaderMatcher QueryParameterMatcher RouteAction Destination MultiDestination WeightedDestination RedirectAction RedirectResponseCode DirectResponseAction SslConfig SSLFiles   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/proxy.proto Proxy A Proxy is a container for the entire set of configuration that will to be applied to one or more Proxy instances. Proxies can be understood as a set of listeners, represents a different bind address/port where the proxy will listen for connections. Each listener has its own set of configuration.\nIf any of the sub-resources within a listener is declared invalid (e.g. due to invalid user configuration), the proxy will be marked invalid by Gloo.\nProxy instances that register with Gloo are assigned the proxy configuration corresponding with a proxy-specific identifier. In the case of Envoy, proxy instances are identified by their Node ID. Node IDs must match a existing Proxy Node ID can be specified in Envoy with the --service-node flag, or in the Envoy instance\u0026rsquo;s bootstrap config.\n\u0026quot;listeners\u0026quot;: []gloo.solo.io.Listener \u0026quot;status\u0026quot;: .core.solo.io.Status \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata     Field Type Description Default     listeners []gloo.solo.io.Listener Define here each listener the proxy should create. Listeners define the a set of behaviors for a single bind address/port where the proxy will listen If no listeners are specified, the instances configured with the proxy resource will not accept connections.    status .core.solo.io.Status Status indicates the validation status of this resource. Status is read-only by clients, and set by gloo during validation    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource     Listener Listeners define the address:port where the proxy will listen for incoming connections A Listener accepts connections (currently only HTTP is supported) and apply user-defined behavior for those connections, e.g. performing SSL termination, HTTP retries, and rate limiting.\n\u0026quot;name\u0026quot;: string \u0026quot;bind_address\u0026quot;: string \u0026quot;bind_port\u0026quot;: int \u0026quot;http_listener\u0026quot;: .gloo.solo.io.HttpListener \u0026quot;ssl_configuations\u0026quot;: []gloo.solo.io.SslConfig     Field Type Description Default     name string the name of the listener. names must be unique for each listener within a proxy    bind_address string the bind address for the listener. both ipv4 and ipv6 formats are supported    bind_port int the port to bind on ports numbers must be unique for listeners within a proxy    http_listener .gloo.solo.io.HttpListener The HTTP Listener is currently the only supported listener type. It contains configuration options for GLoo\u0026rsquo;s HTTP-level features including request-based routing    ssl_configuations []gloo.solo.io.SslConfig SSL Config is optional for the listener. If provided, the listener will serve TLS for connections on this port Multiple SslConfigs are supported for the pupose of SNI. Be aware that the SNI domain provided in the SSL Config must match a domain in virtual host TODO(ilackarms): ensure that ssl configs without a matching virtual host are errored     HttpListener Use this listener to configure proxy behavior for any HTTP-level features including defining routes (via virtualservices). HttpListeners also contain plugin configuration that applies globally across all virtaul hosts on the listener. Some plugins can be configured to work both on the listener and virtual host level (such as the rate limit plugin)\n\u0026quot;virtual_hosts\u0026quot;: []gloo.solo.io.VirtualHost \u0026quot;listener_plugins\u0026quot;: .gloo.solo.io.ListenerPlugins     Field Type Description Default     virtual_hosts []gloo.solo.io.VirtualHost the set of virtual hosts that will be accessible by clients connecting to this listener. at least one virtual host must be specified for this listener to be active (else connections will be refused) the set of domains for each virtual host must be unique, or the config will be considered invalid    listener_plugins .gloo.solo.io.ListenerPlugins Plugins contains top-level plugin configuration to be applied to a listener Listener config is applied to all HTTP traffic that connects to this listener. Some configuration here can be overridden in Virtual Host Plugin configuration or Route Plugin configuration Plugins should be specified here in the form of \u0026quot;plugin_name\u0026quot;: {..//plugin_config...} to allow specifying multiple plugins.     VirtualHost Virtual Hosts group an ordered list of routes under one or more domains. Each Virtual Host has a logical name, which must be unique for the listener. An HTTP request is first matched to a virtual host based on its host header, then to a route within the virtual host. If a request is not matched to any virtual host or a route therein, the target proxy will reply with a 404.\n\u0026quot;name\u0026quot;: string \u0026quot;domains\u0026quot;: []string \u0026quot;routes\u0026quot;: []gloo.solo.io.Route \u0026quot;virtual_host_plugins\u0026quot;: .gloo.solo.io.VirtualHostPlugins     Field Type Description Default     name string the logical name of the virtual host. names must be unique for each virtual host within a listener    domains []string The list of domains (i.e.: matching the Host header of a request) that belong to this virtual host. Note that the wildcard will not match the empty string. e.g. “*-bar.foo.com” will match “baz-bar.foo.com” but not “-bar.foo.com”. Additionally, a special entry “*” is allowed which will match any host/authority header. Only a single virtual host in the entire route configuration can match on “*”. A domain must be unique across all virtual hosts or the config will be invalidated by Gloo Domains on virtual hosts obey the same rules as Envoy Virtual Hosts    routes []gloo.solo.io.Route The list of HTTP routes define routing actions to be taken for incoming HTTP requests whose host header matches this virtual host. If the request matches more than one route in the list, the first route matched will be selected. If the list of routes is empty, the virtual host will be ignored by Gloo.    virtual_host_plugins .gloo.solo.io.VirtualHostPlugins Plugins contains top-level plugin configuration to be applied to a listener Listener config is applied to all HTTP traffic that connects to this listener. Some configuration here can be overridden in Virtual Host Plugin configuration or Route Plugin configuration Plugins should be specified here in the form of \u0026quot;plugin_name\u0026quot;: {..//plugin_config...} to allow specifying multiple plugins.     Route * Routes declare the entrypoints on virtual hosts and the action to take for matched requests.\n\u0026quot;matcher\u0026quot;: .gloo.solo.io.Matcher \u0026quot;route_action\u0026quot;: .gloo.solo.io.RouteAction \u0026quot;redirect_action\u0026quot;: .gloo.solo.io.RedirectAction \u0026quot;direct_response_action\u0026quot;: .gloo.solo.io.DirectResponseAction \u0026quot;route_plugins\u0026quot;: .gloo.solo.io.RoutePlugins     Field Type Description Default     matcher .gloo.solo.io.Matcher The matcher contains parameters for matching requests (i.e.: based on HTTP path, headers, etc.)    route_action .gloo.solo.io.RouteAction This action is the primary action to be selected for most routes. The RouteAction tells the proxy to route requests to an upstream.    redirect_action .gloo.solo.io.RedirectAction Redirect actions tell the proxy to return a redirect response to the downstream client    direct_response_action .gloo.solo.io.DirectResponseAction Return an arbitrary HTTP response directly, without proxying.    route_plugins .gloo.solo.io.RoutePlugins Route Plugins extend the behavior of routes. Route plugins include configuration such as retries, rate limiting, and request/resonse transformation. Plugins should be specified here in the form of \u0026quot;plugin_name\u0026quot;: {..//plugin_config...} to allow specifying multiple plugins.     Matcher Parameters for matching routes to requests received by a Gloo-managed proxy\n\u0026quot;prefix\u0026quot;: string \u0026quot;exact\u0026quot;: string \u0026quot;regex\u0026quot;: string \u0026quot;headers\u0026quot;: []gloo.solo.io.HeaderMatcher \u0026quot;query_parameters\u0026quot;: []gloo.solo.io.QueryParameterMatcher \u0026quot;methods\u0026quot;: []string     Field Type Description Default     prefix string If specified, the route is a prefix rule meaning that the prefix must match the beginning of the :path header.    exact string If specified, the route is an exact path rule meaning that the path must exactly match the :path header once the query string is removed.    regex string If specified, the route is a regular expression rule meaning that the regex must match the :path header once the query string is removed. The entire path (without the query string) must match the regex. The rule will not match if only a subsequence of the :path header matches the regex. The regex grammar is defined here \u0026lt;http://en.cppreference.com/w/cpp/regex/ecmascript\u0026gt;_. Examples: * The regex /b[io]t matches the path /bit * The regex /b[io]t matches the path /bot * The regex /b[io]t does not match the path /bite * The regex /b[io]t does not match the path /bit/bot    headers []gloo.solo.io.HeaderMatcher Specifies a set of headers that the route should match on. The router will check the request’s headers against all the specified headers in the route config. A match will happen if all the headers in the route are present in the request with the same values (or based on presence if the value field is not in the config).    query_parameters []gloo.solo.io.QueryParameterMatcher Specifies a set of URL query parameters on which the route should match. The router will check the query string from the path header against all the specified query parameters. If the number of specified query parameters is nonzero, they all must match the path header\u0026rsquo;s query string for a match to occur.    methods []string HTTP Method/Verb(s) to match on. If none specified, the matcher will ignore the HTTP Method     HeaderMatcher Internally, Gloo always uses the HTTP/2 :authority header to represent the HTTP/1 Host header. Thus, if attempting to match on Host, match on :authority instead.\nIn the absence of any header match specifier, match will default to present_match i.e, a request that has the name header will match, regardless of the header\u0026rsquo;s value.\n\u0026quot;name\u0026quot;: string \u0026quot;value\u0026quot;: string \u0026quot;regex\u0026quot;: bool     Field Type Description Default     name string Specifies the name of the header in the request.    value string Specifies the value of the header. If the value is absent a request that has the name header will match, regardless of the header’s value.    regex bool Specifies whether the header value should be treated as regex or not.     QueryParameterMatcher Query parameter matching treats the query string of a request\u0026rsquo;s :path header as an ampersand-separated list of keys and/or key=value elements.\n\u0026quot;name\u0026quot;: string \u0026quot;value\u0026quot;: string \u0026quot;regex\u0026quot;: bool     Field Type Description Default     name string Specifies the name of a key that must be present in the requested path\u0026rsquo;s query string.    value string Specifies the value of the key. If the value is absent, a request that contains the key in its query string will match, whether the key appears with a value (e.g., \u0026ldquo;?debug=true\u0026rdquo;) or not (e.g., \u0026ldquo;?debug\u0026rdquo;)    regex bool Specifies whether the query parameter value is a regular expression. Defaults to false. The entire query parameter value (i.e., the part to the right of the equals sign in \u0026ldquo;key=value\u0026rdquo;) must match the regex. E.g., the regex \u0026ldquo;\\d+$\u0026rdquo; will match \u0026ldquo;123\u0026rdquo; but not \u0026ldquo;a123\u0026rdquo; or \u0026ldquo;123a\u0026rdquo;.     RouteAction RouteActions are used to route matched requests to upstreams.\n\u0026quot;single\u0026quot;: .gloo.solo.io.Destination \u0026quot;multi\u0026quot;: .gloo.solo.io.MultiDestination     Field Type Description Default     single .gloo.solo.io.Destination Use SingleDestination to route to a single upstream    multi .gloo.solo.io.MultiDestination Use MultiDestination to load balance requests between multiple upstreams (by weight)     Destination Destinations define routable destinations for proxied requests\n\u0026quot;upstream\u0026quot;: .core.solo.io.ResourceRef \u0026quot;destination_spec\u0026quot;: .gloo.solo.io.DestinationSpec     Field Type Description Default     upstream .core.solo.io.ResourceRef The upstream to route requests to    destination_spec .gloo.solo.io.DestinationSpec Some upstreams utilize plugins which require or permit additional configuration on routes targeting them. gRPC upstreams, for example, allow specifying REST-style parameters for JSON-to-gRPC transcoding in the destination config. If the destination config is required for the upstream and not provided by the user, Gloo will invalidate the destination and its parent resources.     MultiDestination MultiDestination is a container for a set of weighted destinations. Gloo will load balance traffic for a single route across multiple destinations according to their specified weights.\n\u0026quot;destinations\u0026quot;: []gloo.solo.io.WeightedDestination     Field Type Description Default     destinations []gloo.solo.io.WeightedDestination This list must contain at least one destination or the listener housing this route will be invalid, causing Gloo to error the parent proxy resource.     WeightedDestination WeightedDestination attaches a weight to a single destination.\n\u0026quot;destination\u0026quot;: .gloo.solo.io.Destination \u0026quot;weight\u0026quot;: int     Field Type Description Default     destination .gloo.solo.io.Destination     weight int Weight must be greater than zero Routing to each destination will be balanced by the ratio of the destination\u0026rsquo;s weight to the total weight on a route     RedirectAction TODO(ilackarms): evaluate how much to differentiate (or if even to include) RedirectAction Notice: RedirectAction is copioed directly from https://github.com/envoyproxy/envoy/blob/master/api/envoy/api/v2/route/route.proto\n\u0026quot;host_redirect\u0026quot;: string \u0026quot;path_redirect\u0026quot;: string \u0026quot;prefix_rewrite\u0026quot;: string \u0026quot;response_code\u0026quot;: .gloo.solo.io.RedirectAction.RedirectResponseCode \u0026quot;https_redirect\u0026quot;: bool \u0026quot;strip_query\u0026quot;: bool     Field Type Description Default     host_redirect string The host portion of the URL will be swapped with this value.    path_redirect string The path portion of the URL will be swapped with this value.    prefix_rewrite string Indicates that during redirection, the matched prefix (or path) should be swapped with this value. This option allows redirect URLs be dynamically created based on the request. Pay attention to the use of trailing slashes as mentioned in RouteAction\u0026rsquo;s prefix_rewrite.    response_code .gloo.solo.io.RedirectAction.RedirectResponseCode The HTTP status code to use in the redirect response. The default response code is MOVED_PERMANENTLY (301).    https_redirect bool The scheme portion of the URL will be swapped with \u0026ldquo;https\u0026rdquo;.    strip_query bool Indicates that during redirection, the query portion of the URL will be removed. Default value is false.     RedirectResponseCode    Name Description     MOVED_PERMANENTLY Moved Permanently HTTP Status Code - 301.   FOUND Found HTTP Status Code - 302.   SEE_OTHER See Other HTTP Status Code - 303.   TEMPORARY_REDIRECT Temporary Redirect HTTP Status Code - 307.   PERMANENT_REDIRECT Permanent Redirect HTTP Status Code - 308.    DirectResponseAction TODO(ilackarms): evaluate how much to differentiate (or if even to include) DirectResponseAction DirectResponseAction is copied directly from https://github.com/envoyproxy/envoy/blob/master/api/envoy/api/v2/route/route.proto\n\u0026quot;status\u0026quot;: int \u0026quot;body\u0026quot;: string     Field Type Description Default     status int Specifies the HTTP response status to be returned.    body string Specifies the content of the response body. If this setting is omitted, no body is included in the generated response. Note: Headers can be specified using the Header Modification plugin in the enclosing Route, Virtual Host, or Listener.     SslConfig SslConfig contains the options necessary to configure a virtual host or listener to use TLS\n\u0026quot;secret_ref\u0026quot;: .core.solo.io.ResourceRef \u0026quot;ssl_files\u0026quot;: .gloo.solo.io.SSLFiles \u0026quot;sni_domains\u0026quot;: []string     Field Type Description Default     secret_ref .core.solo.io.ResourceRef * SecretRef contains the secret ref to a gloo secret containing the following structure: { \u0026ldquo;tls.crt\u0026rdquo;: , \u0026ldquo;tls.key\u0026rdquo;: }    ssl_files .gloo.solo.io.SSLFiles SSLFiles reference paths to certificates which are local to the proxy    sni_domains []string optional. the SNI domains that should be considered for TLS connections     SSLFiles SSLFiles reference paths to certificates which can be read by the proxy off of its local filesystem\n\u0026quot;tls_cert\u0026quot;: string \u0026quot;tls_key\u0026quot;: string \u0026quot;root_ca\u0026quot;: string     Field Type Description Default     tls_cert string     tls_key string     root_ca string for client cert validation. optional      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/solo-kit/api/v1/ref.proto.sk/",
	"title": "ref.proto",
	"tags": [],
	"description": "",
	"content": " Package: core.solo.io Types:  ResourceRef   Source File: github.com/solo-io/solo-kit/api/v1/ref.proto ResourceRef A way to reference resources across namespaces TODO(ilackarms): make upstreamname and secretref into ResourceRefs\n\u0026quot;name\u0026quot;: string \u0026quot;namespace\u0026quot;: string     Field Type Description Default     name string     namespace string       "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/solo-kit/api/v1/ref.proto.sk/",
	"title": "ref.proto",
	"tags": [],
	"description": "",
	"content": " Package: core.solo.io Types:  ResourceRef   Source File: github.com/solo-io/solo-kit/api/v1/ref.proto ResourceRef A way to reference resources across namespaces TODO(ilackarms): make upstreamname and secretref into ResourceRefs\n\u0026quot;name\u0026quot;: string \u0026quot;namespace\u0026quot;: string     Field Type Description Default     name string     namespace string       "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/rest/rest.proto.sk/",
	"title": "rest.proto",
	"tags": [],
	"description": "",
	"content": " Package: rest.plugins.gloo.solo.io Types:  ServiceSpec SwaggerInfo DestinationSpec   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/rest/rest.proto ServiceSpec \u0026quot;transformations\u0026quot;: map\u0026lt;string, .transformation.plugins.gloo.solo.io.TransformationTemplate\u0026gt; \u0026quot;swagger_info\u0026quot;: .rest.plugins.gloo.solo.io.ServiceSpec.SwaggerInfo     Field Type Description Default     transformations map\u0026lt;string, .transformation.plugins.gloo.solo.io.TransformationTemplate\u0026gt;     swagger_info .rest.plugins.gloo.solo.io.ServiceSpec.SwaggerInfo      SwaggerInfo \u0026quot;url\u0026quot;: string \u0026quot;inline\u0026quot;: string     Field Type Description Default     url string     inline string      DestinationSpec This is only for upstream with REST service spec\n\u0026quot;function_name\u0026quot;: string \u0026quot;parameters\u0026quot;: .transformation.plugins.gloo.solo.io.Parameters \u0026quot;response_transformation\u0026quot;: .transformation.plugins.gloo.solo.io.TransformationTemplate     Field Type Description Default     function_name string     parameters .transformation.plugins.gloo.solo.io.Parameters     response_transformation .transformation.plugins.gloo.solo.io.TransformationTemplate       "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/rest/rest.proto.sk/",
	"title": "rest.proto",
	"tags": [],
	"description": "",
	"content": " Package: rest.plugins.gloo.solo.io Types:  ServiceSpec SwaggerInfo DestinationSpec   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/rest/rest.proto ServiceSpec \u0026quot;transformations\u0026quot;: map\u0026lt;string, .transformation.plugins.gloo.solo.io.TransformationTemplate\u0026gt; \u0026quot;swagger_info\u0026quot;: .rest.plugins.gloo.solo.io.ServiceSpec.SwaggerInfo     Field Type Description Default     transformations map\u0026lt;string, .transformation.plugins.gloo.solo.io.TransformationTemplate\u0026gt;     swagger_info .rest.plugins.gloo.solo.io.ServiceSpec.SwaggerInfo      SwaggerInfo \u0026quot;url\u0026quot;: string \u0026quot;inline\u0026quot;: string     Field Type Description Default     url string     inline string      DestinationSpec This is only for upstream with REST service spec\n\u0026quot;function_name\u0026quot;: string \u0026quot;parameters\u0026quot;: .transformation.plugins.gloo.solo.io.Parameters \u0026quot;response_transformation\u0026quot;: .transformation.plugins.gloo.solo.io.TransformationTemplate     Field Type Description Default     function_name string     parameters .transformation.plugins.gloo.solo.io.Parameters     response_transformation .transformation.plugins.gloo.solo.io.TransformationTemplate       "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/retries/retries.proto.sk/",
	"title": "retries.proto",
	"tags": [],
	"description": "",
	"content": " Package: retries.plugins.gloo.solo.io TODO: this was copied form the transformation filter. TODO: instead of manually copying, we want to do it via script, similar to the java-control-plane TODO: to solo-kit/api/envoy\nTypes:  RetryPolicy   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/retries/retries.proto RetryPolicy Retry Policy applied to a route\n\u0026quot;retry_on\u0026quot;: string \u0026quot;num_retries\u0026quot;: int \u0026quot;per_try_timeout\u0026quot;: .google.protobuf.Duration     Field Type Description Default     retry_on string Specifies the conditions under which retry takes place. These are the same conditions documented for Envoy    num_retries int Specifies the allowed number of retries. This parameter is optional and defaults to 1. These are the same conditions documented for Envoy    per_try_timeout .google.protobuf.Duration Specifies a non-zero upstream timeout per retry attempt. This parameter is optional.      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/retries/retries.proto.sk/",
	"title": "retries.proto",
	"tags": [],
	"description": "",
	"content": " Package: retries.plugins.gloo.solo.io TODO: this was copied form the transformation filter. TODO: instead of manually copying, we want to do it via script, similar to the java-control-plane TODO: to solo-kit/api/envoy\nTypes:  RetryPolicy   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/retries/retries.proto RetryPolicy Retry Policy applied to a route\n\u0026quot;retry_on\u0026quot;: string \u0026quot;num_retries\u0026quot;: int \u0026quot;per_try_timeout\u0026quot;: .google.protobuf.Duration     Field Type Description Default     retry_on string Specifies the conditions under which retry takes place. These are the same conditions documented for Envoy    num_retries int Specifies the allowed number of retries. This parameter is optional and defaults to 1. These are the same conditions documented for Envoy    per_try_timeout .google.protobuf.Duration Specifies a non-zero upstream timeout per retry attempt. This parameter is optional.      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/secret.proto.sk/",
	"title": "secret.proto",
	"tags": [],
	"description": "",
	"content": " Package: gloo.solo.io Types:  Secret Top-Level Resource AwsSecret AzureSecret TlsSecret   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/secret.proto Secret Certain plugins such as the AWS Lambda Plugin require the use of secrets for authentication, configuration of SSL Certificates, and other data that should not be stored in plaintext configuration.\nGloo runs an independent (goroutine) controller to monitor secrets. Secrets are stored in their own secret storage layer. Gloo can monitor secrets stored in the following secret storage services:\nKubernetes Secrets Hashicorp Vault Plaintext files (recommended only for testing) Secrets must adhere to a structure, specified by the plugin that requires them.\nGloo\u0026rsquo;s secret backend can be configured in Gloo\u0026rsquo;s bootstrap options\n\u0026quot;aws\u0026quot;: .gloo.solo.io.AwsSecret \u0026quot;azure\u0026quot;: .gloo.solo.io.AzureSecret \u0026quot;tls\u0026quot;: .gloo.solo.io.TlsSecret \u0026quot;extension\u0026quot;: .gloo.solo.io.Extension \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata     Field Type Description Default     aws .gloo.solo.io.AwsSecret     azure .gloo.solo.io.AzureSecret     tls .gloo.solo.io.TlsSecret     extension .gloo.solo.io.Extension     metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource     AwsSecret \u0026quot;access_key\u0026quot;: string \u0026quot;secret_key\u0026quot;: string     Field Type Description Default     access_key string     secret_key string      AzureSecret \u0026quot;api_keys\u0026quot;: map\u0026lt;string, string\u0026gt;     Field Type Description Default     api_keys map\u0026lt;string, string\u0026gt;      TlsSecret \u0026quot;cert_chain\u0026quot;: string \u0026quot;private_key\u0026quot;: string \u0026quot;root_ca\u0026quot;: string     Field Type Description Default     cert_chain string     private_key string     root_ca string       "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/secret.proto.sk/",
	"title": "secret.proto",
	"tags": [],
	"description": "",
	"content": " Package: gloo.solo.io Types:  Secret Top-Level Resource AwsSecret AzureSecret TlsSecret   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/secret.proto Secret Certain plugins such as the AWS Lambda Plugin require the use of secrets for authentication, configuration of SSL Certificates, and other data that should not be stored in plaintext configuration.\nGloo runs an independent (goroutine) controller to monitor secrets. Secrets are stored in their own secret storage layer. Gloo can monitor secrets stored in the following secret storage services:\nKubernetes Secrets Hashicorp Vault Plaintext files (recommended only for testing) Secrets must adhere to a structure, specified by the plugin that requires them.\nGloo\u0026rsquo;s secret backend can be configured in Gloo\u0026rsquo;s bootstrap options\n\u0026quot;aws\u0026quot;: .gloo.solo.io.AwsSecret \u0026quot;azure\u0026quot;: .gloo.solo.io.AzureSecret \u0026quot;tls\u0026quot;: .gloo.solo.io.TlsSecret \u0026quot;extension\u0026quot;: .gloo.solo.io.Extension \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata     Field Type Description Default     aws .gloo.solo.io.AwsSecret     azure .gloo.solo.io.AzureSecret     tls .gloo.solo.io.TlsSecret     extension .gloo.solo.io.Extension     metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource     AwsSecret \u0026quot;access_key\u0026quot;: string \u0026quot;secret_key\u0026quot;: string     Field Type Description Default     access_key string     secret_key string      AzureSecret \u0026quot;api_keys\u0026quot;: map\u0026lt;string, string\u0026gt;     Field Type Description Default     api_keys map\u0026lt;string, string\u0026gt;      TlsSecret \u0026quot;cert_chain\u0026quot;: string \u0026quot;private_key\u0026quot;: string \u0026quot;root_ca\u0026quot;: string     Field Type Description Default     cert_chain string     private_key string     root_ca string       "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/ingress/api/v1/service.proto.sk/",
	"title": "service.proto",
	"tags": [],
	"description": "",
	"content": " Package: ingress.solo.io Types:  KubeService Top-Level Resource   Source File: github.com/solo-io/gloo/projects/ingress/api/v1/service.proto KubeService A simple wrapper for a Kubernetes Service Object.\n\u0026quot;kube_service_spec\u0026quot;: .google.protobuf.Any \u0026quot;kube_service_status\u0026quot;: .google.protobuf.Any \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata     Field Type Description Default     kube_service_spec .google.protobuf.Any a raw byte representation of the kubernetes service this resource wraps    kube_service_status .google.protobuf.Any a raw byte representation of the service status of the kubernetes service object    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/ingress/api/v1/service.proto.sk/",
	"title": "service.proto",
	"tags": [],
	"description": "",
	"content": " Package: ingress.solo.io Types:  KubeService Top-Level Resource   Source File: github.com/solo-io/gloo/projects/ingress/api/v1/service.proto KubeService A simple wrapper for a Kubernetes Service Object.\n\u0026quot;kube_service_spec\u0026quot;: .google.protobuf.Any \u0026quot;kube_service_status\u0026quot;: .google.protobuf.Any \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata     Field Type Description Default     kube_service_spec .google.protobuf.Any a raw byte representation of the kubernetes service this resource wraps    kube_service_status .google.protobuf.Any a raw byte representation of the service status of the kubernetes service object    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/service_spec.proto.sk/",
	"title": "service_spec.proto",
	"tags": [],
	"description": "",
	"content": " Package: plugins.gloo.solo.io Types:  ServiceSpec   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/service_spec.proto ServiceSpec Describes APIs and application-level information for services Gloo routes to. ServiceSpec is contained within the UpstreamSpec for certain types of upstreams, including Kubernetes, Consul, and Static. ServiceSpec configuration is opaque to Gloo and handled by Service Plugins.\n\u0026quot;rest\u0026quot;: .rest.plugins.gloo.solo.io.ServiceSpec \u0026quot;grpc\u0026quot;: .grpc.plugins.gloo.solo.io.ServiceSpec     Field Type Description Default     rest .rest.plugins.gloo.solo.io.ServiceSpec     grpc .grpc.plugins.gloo.solo.io.ServiceSpec       "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/service_spec.proto.sk/",
	"title": "service_spec.proto",
	"tags": [],
	"description": "",
	"content": " Package: plugins.gloo.solo.io Types:  ServiceSpec   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/service_spec.proto ServiceSpec Describes APIs and application-level information for services Gloo routes to. ServiceSpec is contained within the UpstreamSpec for certain types of upstreams, including Kubernetes, Consul, and Static. ServiceSpec configuration is opaque to Gloo and handled by Service Plugins.\n\u0026quot;rest\u0026quot;: .rest.plugins.gloo.solo.io.ServiceSpec \u0026quot;grpc\u0026quot;: .grpc.plugins.gloo.solo.io.ServiceSpec     Field Type Description Default     rest .rest.plugins.gloo.solo.io.ServiceSpec     grpc .grpc.plugins.gloo.solo.io.ServiceSpec       "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/settings.proto.sk/",
	"title": "settings.proto",
	"tags": [],
	"description": "",
	"content": " Package: gloo.solo.io Types:  Settings Top-Level Resource KubernetesCrds KubernetesSecrets VaultSecrets KubernetesConfigmaps Directory   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/settings.proto Settings \u0026quot;discovery_namespace\u0026quot;: string \u0026quot;watch_namespaces\u0026quot;: []string \u0026quot;kubernetes_config_source\u0026quot;: .gloo.solo.io.Settings.KubernetesCrds \u0026quot;directory_config_source\u0026quot;: .gloo.solo.io.Settings.Directory \u0026quot;kubernetes_secret_source\u0026quot;: .gloo.solo.io.Settings.KubernetesSecrets \u0026quot;vault_secret_source\u0026quot;: .gloo.solo.io.Settings.VaultSecrets \u0026quot;directory_secret_source\u0026quot;: .gloo.solo.io.Settings.Directory \u0026quot;kubernetes_artifact_source\u0026quot;: .gloo.solo.io.Settings.KubernetesConfigmaps \u0026quot;directory_artifact_source\u0026quot;: .gloo.solo.io.Settings.Directory \u0026quot;bind_addr\u0026quot;: string \u0026quot;refresh_rate\u0026quot;: .google.protobuf.Duration \u0026quot;dev_mode\u0026quot;: bool \u0026quot;extensions\u0026quot;: .gloo.solo.io.Extensions \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata \u0026quot;status\u0026quot;: .core.solo.io.Status     Field Type Description Default     discovery_namespace string namespace to write discovered data    watch_namespaces []string namespaces to watch for user config as well as services TODO(ilackarms): split out watch_namespaces and service_discovery_namespaces\u0026hellip;    kubernetes_config_source .gloo.solo.io.Settings.KubernetesCrds     directory_config_source .gloo.solo.io.Settings.Directory     kubernetes_secret_source .gloo.solo.io.Settings.KubernetesSecrets     vault_secret_source .gloo.solo.io.Settings.VaultSecrets     directory_secret_source .gloo.solo.io.Settings.Directory     kubernetes_artifact_source .gloo.solo.io.Settings.KubernetesConfigmaps     directory_artifact_source .gloo.solo.io.Settings.Directory     bind_addr string where the gloo xds server should bind (should not need configuration by user)    refresh_rate .google.protobuf.Duration how frequently to resync watches, etc    dev_mode bool enable serving debug data on port 9090    extensions .gloo.solo.io.Extensions Settings for extensions    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource    status .core.solo.io.Status Status indicates the validation status of this resource. Status is read-only by clients, and set by gloo during validation     KubernetesCrds ilackarms(todo: make sure these are configurable)\n    Field Type Description Default      KubernetesSecrets     Field Type Description Default      VaultSecrets     Field Type Description Default      KubernetesConfigmaps     Field Type Description Default      Directory \u0026quot;directory\u0026quot;: string     Field Type Description Default     directory string       "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/settings.proto.sk/",
	"title": "settings.proto",
	"tags": [],
	"description": "",
	"content": " Package: gloo.solo.io Types:  Settings Top-Level Resource KubernetesCrds KubernetesSecrets VaultSecrets KubernetesConfigmaps Directory   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/settings.proto Settings \u0026quot;discovery_namespace\u0026quot;: string \u0026quot;watch_namespaces\u0026quot;: []string \u0026quot;kubernetes_config_source\u0026quot;: .gloo.solo.io.Settings.KubernetesCrds \u0026quot;directory_config_source\u0026quot;: .gloo.solo.io.Settings.Directory \u0026quot;kubernetes_secret_source\u0026quot;: .gloo.solo.io.Settings.KubernetesSecrets \u0026quot;vault_secret_source\u0026quot;: .gloo.solo.io.Settings.VaultSecrets \u0026quot;directory_secret_source\u0026quot;: .gloo.solo.io.Settings.Directory \u0026quot;kubernetes_artifact_source\u0026quot;: .gloo.solo.io.Settings.KubernetesConfigmaps \u0026quot;directory_artifact_source\u0026quot;: .gloo.solo.io.Settings.Directory \u0026quot;bind_addr\u0026quot;: string \u0026quot;refresh_rate\u0026quot;: .google.protobuf.Duration \u0026quot;dev_mode\u0026quot;: bool \u0026quot;extensions\u0026quot;: .gloo.solo.io.Extensions \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata \u0026quot;status\u0026quot;: .core.solo.io.Status     Field Type Description Default     discovery_namespace string namespace to write discovered data    watch_namespaces []string namespaces to watch for user config as well as services TODO(ilackarms): split out watch_namespaces and service_discovery_namespaces\u0026hellip;    kubernetes_config_source .gloo.solo.io.Settings.KubernetesCrds     directory_config_source .gloo.solo.io.Settings.Directory     kubernetes_secret_source .gloo.solo.io.Settings.KubernetesSecrets     vault_secret_source .gloo.solo.io.Settings.VaultSecrets     directory_secret_source .gloo.solo.io.Settings.Directory     kubernetes_artifact_source .gloo.solo.io.Settings.KubernetesConfigmaps     directory_artifact_source .gloo.solo.io.Settings.Directory     bind_addr string where the gloo xds server should bind (should not need configuration by user)    refresh_rate .google.protobuf.Duration how frequently to resync watches, etc    dev_mode bool enable serving debug data on port 9090    extensions .gloo.solo.io.Extensions Settings for extensions    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource    status .core.solo.io.Status Status indicates the validation status of this resource. Status is read-only by clients, and set by gloo during validation     KubernetesCrds ilackarms(todo: make sure these are configurable)\n    Field Type Description Default      KubernetesSecrets     Field Type Description Default      VaultSecrets     Field Type Description Default      KubernetesConfigmaps     Field Type Description Default      Directory \u0026quot;directory\u0026quot;: string     Field Type Description Default     directory string       "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/solo-kit/api/v1/solo-kit.proto.sk/",
	"title": "solo-kit.proto",
	"tags": [],
	"description": "",
	"content": " Package: core.solo.io Types:  Resource   Source File: github.com/solo-io/solo-kit/api/v1/solo-kit.proto Resource \u0026quot;short_name\u0026quot;: string \u0026quot;plural_name\u0026quot;: string \u0026quot;cluster_scoped\u0026quot;: bool \u0026quot;skip_docs_gen\u0026quot;: bool     Field Type Description Default     short_name string becomes the kubernetes short name for the generated crd    plural_name string becomes the kubernetes plural name for the generated crd    cluster_scoped bool the resource lives at the cluster level, namespace is ignored by the server    skip_docs_gen bool indicates whether documentation generation has to be skipped for the given resource, defaults to false      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/solo-kit/api/v1/solo-kit.proto.sk/",
	"title": "solo-kit.proto",
	"tags": [],
	"description": "",
	"content": " Package: core.solo.io Types:  Resource   Source File: github.com/solo-io/solo-kit/api/v1/solo-kit.proto Resource \u0026quot;short_name\u0026quot;: string \u0026quot;plural_name\u0026quot;: string \u0026quot;cluster_scoped\u0026quot;: bool \u0026quot;skip_docs_gen\u0026quot;: bool     Field Type Description Default     short_name string becomes the kubernetes short name for the generated crd    plural_name string becomes the kubernetes plural name for the generated crd    cluster_scoped bool the resource lives at the cluster level, namespace is ignored by the server    skip_docs_gen bool indicates whether documentation generation has to be skipped for the given resource, defaults to false      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/static/static.proto.sk/",
	"title": "static.proto",
	"tags": [],
	"description": "",
	"content": " Package: static.plugins.gloo.solo.io Types:  UpstreamSpec Host   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/static/static.proto UpstreamSpec Static upstreams are used to route request to services listening at fixed IP/Addresses. Static upstreams can be used to proxy any kind of service, and therefore contain a ServiceSpec for additional service-specific configuration. Unlike upstreams created by service discovery, Static Upstreams must be created manually by users\n\u0026quot;hosts\u0026quot;: []static.plugins.gloo.solo.io.Host \u0026quot;use_tls\u0026quot;: bool \u0026quot;service_spec\u0026quot;: .plugins.gloo.solo.io.ServiceSpec \u0026quot;use_http2\u0026quot;: bool     Field Type Description Default     hosts []static.plugins.gloo.solo.io.Host A list of addresses and ports at least one must be specified    use_tls bool Attempt to use outbound TLS Gloo will automatically set this to true for port 443    service_spec .plugins.gloo.solo.io.ServiceSpec An optional Service Spec describing the service listening at this address    use_http2 bool Use http2 when communicating with this upstream     Host Represents a single instance of an upstream\n\u0026quot;addr\u0026quot;: string \u0026quot;port\u0026quot;: int     Field Type Description Default     addr string Address (hostname or IP)    port int Port the instance is listening on      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/static/static.proto.sk/",
	"title": "static.proto",
	"tags": [],
	"description": "",
	"content": " Package: static.plugins.gloo.solo.io Types:  UpstreamSpec Host   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/static/static.proto UpstreamSpec Static upstreams are used to route request to services listening at fixed IP/Addresses. Static upstreams can be used to proxy any kind of service, and therefore contain a ServiceSpec for additional service-specific configuration. Unlike upstreams created by service discovery, Static Upstreams must be created manually by users\n\u0026quot;hosts\u0026quot;: []static.plugins.gloo.solo.io.Host \u0026quot;use_tls\u0026quot;: bool \u0026quot;service_spec\u0026quot;: .plugins.gloo.solo.io.ServiceSpec \u0026quot;use_http2\u0026quot;: bool     Field Type Description Default     hosts []static.plugins.gloo.solo.io.Host A list of addresses and ports at least one must be specified    use_tls bool Attempt to use outbound TLS Gloo will automatically set this to true for port 443    service_spec .plugins.gloo.solo.io.ServiceSpec An optional Service Spec describing the service listening at this address    use_http2 bool Use http2 when communicating with this upstream     Host Represents a single instance of an upstream\n\u0026quot;addr\u0026quot;: string \u0026quot;port\u0026quot;: int     Field Type Description Default     addr string Address (hostname or IP)    port int Port the instance is listening on      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/solo-kit/api/v1/status.proto.sk/",
	"title": "status.proto",
	"tags": [],
	"description": "",
	"content": " Package: core.solo.io Types:  Status State   Source File: github.com/solo-io/solo-kit/api/v1/status.proto Status * Status indicates whether a resource has been (in)validated by a reporter in the system. Statuses are meant to be read-only by users\n\u0026quot;state\u0026quot;: .core.solo.io.Status.State \u0026quot;reason\u0026quot;: string \u0026quot;reported_by\u0026quot;: string \u0026quot;subresource_statuses\u0026quot;: map\u0026lt;string, .core.solo.io.Status\u0026gt;     Field Type Description Default     state .core.solo.io.Status.State State is the enum indicating the state of the resource    reason string Reason is a description of the error for Rejected resources. If the resource is pending or accepted, this field will be empty    reported_by string Reference to the reporter who wrote this status    subresource_statuses map\u0026lt;string, .core.solo.io.Status\u0026gt; Reference to statuses (by resource-ref string: \u0026ldquo;Kind.Namespace.Name\u0026rdquo;) of subresources of the parent resource     State    Name Description     Pending Pending status indicates the resource has not yet been validated   Accepted Accepted indicates the resource has been validated   Rejected Rejected indicates an invalid configuration by the user Rejected resources may be propagated to the xDS server depending on their severity     "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/solo-kit/api/v1/status.proto.sk/",
	"title": "status.proto",
	"tags": [],
	"description": "",
	"content": " Package: core.solo.io Types:  Status State   Source File: github.com/solo-io/solo-kit/api/v1/status.proto Status * Status indicates whether a resource has been (in)validated by a reporter in the system. Statuses are meant to be read-only by users\n\u0026quot;state\u0026quot;: .core.solo.io.Status.State \u0026quot;reason\u0026quot;: string \u0026quot;reported_by\u0026quot;: string \u0026quot;subresource_statuses\u0026quot;: map\u0026lt;string, .core.solo.io.Status\u0026gt;     Field Type Description Default     state .core.solo.io.Status.State State is the enum indicating the state of the resource    reason string Reason is a description of the error for Rejected resources. If the resource is pending or accepted, this field will be empty    reported_by string Reference to the reporter who wrote this status    subresource_statuses map\u0026lt;string, .core.solo.io.Status\u0026gt; Reference to statuses (by resource-ref string: \u0026ldquo;Kind.Namespace.Name\u0026rdquo;) of subresources of the parent resource     State    Name Description     Pending Pending status indicates the resource has not yet been validated   Accepted Accepted indicates the resource has been validated   Rejected Rejected indicates an invalid configuration by the user Rejected resources may be propagated to the xDS server depending on their severity     "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/google/protobuf/struct.proto.sk/",
	"title": "struct.proto",
	"tags": [],
	"description": "",
	"content": " Package: google.protobuf Protocol Buffers - Google\u0026rsquo;s data interchange format Copyright 2008 Google Inc. All rights reserved. https://developers.google.com/protocol-buffers/\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n* Redistributions of source code must retain the above copyright  notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026ldquo;AS IS\u0026rdquo; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nTypes:  Struct Value ListValue   Enums: - [NullValue](#NullValue)  Source File: google/protobuf/struct.proto Struct Struct represents a structured data value, consisting of fields which map to dynamically typed values. In some languages, Struct might be supported by a native representation. For example, in scripting languages like JS a struct is represented as an object. The details of that representation are described together with the proto support for the language.\nThe JSON representation for Struct is JSON object.\n\u0026quot;fields\u0026quot;: map\u0026lt;string, .google.protobuf.Value\u0026gt;     Field Type Description Default     fields map\u0026lt;string, .google.protobuf.Value\u0026gt; Unordered map of dynamically typed values.     Value Value represents a dynamically typed value which can be either null, a number, a string, a boolean, a recursive struct value, or a list of values. A producer of value is expected to set one of that variants, absence of any variant indicates an error.\nThe JSON representation for Value is JSON value.\n\u0026quot;null_value\u0026quot;: .google.protobuf.NullValue \u0026quot;number_value\u0026quot;: float \u0026quot;string_value\u0026quot;: string \u0026quot;bool_value\u0026quot;: bool \u0026quot;struct_value\u0026quot;: .google.protobuf.Struct \u0026quot;list_value\u0026quot;: .google.protobuf.ListValue     Field Type Description Default     null_value .google.protobuf.NullValue Represents a null value.    number_value float Represents a double value.    string_value string Represents a string value.    bool_value bool Represents a boolean value.    struct_value .google.protobuf.Struct Represents a structured value.    list_value .google.protobuf.ListValue Represents a repeated Value.     ListValue ListValue is a wrapper around a repeated field of values.\nThe JSON representation for ListValue is JSON array.\n\u0026quot;values\u0026quot;: []google.protobuf.Value     Field Type Description Default     values []google.protobuf.Value Repeated field of dynamically typed values.     NullValue Description: NullValue is a singleton enumeration to represent the null value for the Value type union.\nThe JSON representation for NullValue is JSON null.\n   Name Description     NULL_VALUE Null value.     "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/google/protobuf/struct.proto.sk/",
	"title": "struct.proto",
	"tags": [],
	"description": "",
	"content": " Package: google.protobuf Protocol Buffers - Google\u0026rsquo;s data interchange format Copyright 2008 Google Inc. All rights reserved. https://developers.google.com/protocol-buffers/\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n* Redistributions of source code must retain the above copyright  notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026ldquo;AS IS\u0026rdquo; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nTypes:  Struct Value ListValue   Enums: - [NullValue](#NullValue)  Source File: google/protobuf/struct.proto Struct Struct represents a structured data value, consisting of fields which map to dynamically typed values. In some languages, Struct might be supported by a native representation. For example, in scripting languages like JS a struct is represented as an object. The details of that representation are described together with the proto support for the language.\nThe JSON representation for Struct is JSON object.\n\u0026quot;fields\u0026quot;: map\u0026lt;string, .google.protobuf.Value\u0026gt;     Field Type Description Default     fields map\u0026lt;string, .google.protobuf.Value\u0026gt; Unordered map of dynamically typed values.     Value Value represents a dynamically typed value which can be either null, a number, a string, a boolean, a recursive struct value, or a list of values. A producer of value is expected to set one of that variants, absence of any variant indicates an error.\nThe JSON representation for Value is JSON value.\n\u0026quot;null_value\u0026quot;: .google.protobuf.NullValue \u0026quot;number_value\u0026quot;: float \u0026quot;string_value\u0026quot;: string \u0026quot;bool_value\u0026quot;: bool \u0026quot;struct_value\u0026quot;: .google.protobuf.Struct \u0026quot;list_value\u0026quot;: .google.protobuf.ListValue     Field Type Description Default     null_value .google.protobuf.NullValue Represents a null value.    number_value float Represents a double value.    string_value string Represents a string value.    bool_value bool Represents a boolean value.    struct_value .google.protobuf.Struct Represents a structured value.    list_value .google.protobuf.ListValue Represents a repeated Value.     ListValue ListValue is a wrapper around a repeated field of values.\nThe JSON representation for ListValue is JSON array.\n\u0026quot;values\u0026quot;: []google.protobuf.Value     Field Type Description Default     values []google.protobuf.Value Repeated field of dynamically typed values.     NullValue Description: NullValue is a singleton enumeration to represent the null value for the Value type union.\nThe JSON representation for NullValue is JSON null.\n   Name Description     NULL_VALUE Null value.     "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/google/protobuf/timestamp.proto.sk/",
	"title": "timestamp.proto",
	"tags": [],
	"description": "",
	"content": " Package: google.protobuf Protocol Buffers - Google\u0026rsquo;s data interchange format Copyright 2008 Google Inc. All rights reserved. https://developers.google.com/protocol-buffers/\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n* Redistributions of source code must retain the above copyright  notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026ldquo;AS IS\u0026rdquo; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nTypes:  Timestamp   Source File: google/protobuf/timestamp.proto Timestamp A Timestamp represents a point in time independent of any time zone or calendar, represented as seconds and fractions of seconds at nanosecond resolution in UTC Epoch time. It is encoded using the Proleptic Gregorian Calendar which extends the Gregorian calendar backwards to year one. It is encoded assuming all minutes are 60 seconds long, i.e. leap seconds are \u0026ldquo;smeared\u0026rdquo; so that no leap second table is needed for interpretation. Range is from 0001-01-01T00:00:00Z to 9999-12-31T23:59:59.999999999Z. By restricting to that range, we ensure that we can convert to and from RFC 3339 date strings. See https://www.ietf.org/rfc/rfc3339.txt.\nExamples Example 1: Compute Timestamp from POSIX time().\nTimestamp timestamp; timestamp.set_seconds(time(NULL)); timestamp.set_nanos(0);  Example 2: Compute Timestamp from POSIX gettimeofday().\nstruct timeval tv; gettimeofday(\u0026amp;tv, NULL); Timestamp timestamp; timestamp.set_seconds(tv.tv_sec); timestamp.set_nanos(tv.tv_usec * 1000);  Example 3: Compute Timestamp from Win32 GetSystemTimeAsFileTime().\nFILETIME ft; GetSystemTimeAsFileTime(\u0026amp;ft); UINT64 ticks = (((UINT64)ft.dwHighDateTime) \u0026lt;\u0026lt; 32) | ft.dwLowDateTime; // A Windows tick is 100 nanoseconds. Windows epoch 1601-01-01T00:00:00Z // is 11644473600 seconds before Unix epoch 1970-01-01T00:00:00Z. Timestamp timestamp; timestamp.set_seconds((INT64) ((ticks / 10000000) - 11644473600LL)); timestamp.set_nanos((INT32) ((ticks % 10000000) * 100));  Example 4: Compute Timestamp from Java System.currentTimeMillis().\nlong millis = System.currentTimeMillis(); Timestamp timestamp = Timestamp.newBuilder().setSeconds(millis / 1000) .setNanos((int) ((millis % 1000) * 1000000)).build();  Example 5: Compute Timestamp from current time in Python.\ntimestamp = Timestamp() timestamp.GetCurrentTime()  JSON Mapping In JSON format, the Timestamp type is encoded as a string in the RFC 3339 format. That is, the format is \u0026ldquo;{year}-{month}-{day}T{hour}:{min}:{sec}[.{frac_sec}]Z\u0026rdquo; where {year} is always expressed using four digits while {month}, {day}, {hour}, {min}, and {sec} are zero-padded to two digits each. The fractional seconds, which can go up to 9 digits (i.e. up to 1 nanosecond resolution), are optional. The \u0026ldquo;Z\u0026rdquo; suffix indicates the timezone (\u0026ldquo;UTC\u0026rdquo;); the timezone is required, though only UTC (as indicated by \u0026ldquo;Z\u0026rdquo;) is presently supported.\nFor example, \u0026ldquo;2017-01-15T01:30:15.01Z\u0026rdquo; encodes 15.01 seconds past 01:30 UTC on January 15, 2017.\nIn JavaScript, one can convert a Date object to this format using the standard toISOString()`]( http://joda-time.sourceforge.net/apidocs/org/joda/time/format/ISODateTimeFormat.html#dateTime()) to obtain a formatter capable of generating timestamps in this format.\n\u0026quot;seconds\u0026quot;: int \u0026quot;nanos\u0026quot;: int     Field Type Description Default     seconds int Represents seconds of UTC time since Unix epoch 1970-01-01T00:00:00Z. Must be from 0001-01-01T00:00:00Z to 9999-12-31T23:59:59Z inclusive.    nanos int Non-negative fractions of a second at nanosecond resolution. Negative second values with fractions must still have non-negative nanos values that count forward in time. Must be from 0 to 999,999,999 inclusive.      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/google/protobuf/timestamp.proto.sk/",
	"title": "timestamp.proto",
	"tags": [],
	"description": "",
	"content": " Package: google.protobuf Protocol Buffers - Google\u0026rsquo;s data interchange format Copyright 2008 Google Inc. All rights reserved. https://developers.google.com/protocol-buffers/\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n* Redistributions of source code must retain the above copyright  notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026ldquo;AS IS\u0026rdquo; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nTypes:  Timestamp   Source File: google/protobuf/timestamp.proto Timestamp A Timestamp represents a point in time independent of any time zone or calendar, represented as seconds and fractions of seconds at nanosecond resolution in UTC Epoch time. It is encoded using the Proleptic Gregorian Calendar which extends the Gregorian calendar backwards to year one. It is encoded assuming all minutes are 60 seconds long, i.e. leap seconds are \u0026ldquo;smeared\u0026rdquo; so that no leap second table is needed for interpretation. Range is from 0001-01-01T00:00:00Z to 9999-12-31T23:59:59.999999999Z. By restricting to that range, we ensure that we can convert to and from RFC 3339 date strings. See https://www.ietf.org/rfc/rfc3339.txt.\nExamples Example 1: Compute Timestamp from POSIX time().\nTimestamp timestamp; timestamp.set_seconds(time(NULL)); timestamp.set_nanos(0);  Example 2: Compute Timestamp from POSIX gettimeofday().\nstruct timeval tv; gettimeofday(\u0026amp;tv, NULL); Timestamp timestamp; timestamp.set_seconds(tv.tv_sec); timestamp.set_nanos(tv.tv_usec * 1000);  Example 3: Compute Timestamp from Win32 GetSystemTimeAsFileTime().\nFILETIME ft; GetSystemTimeAsFileTime(\u0026amp;ft); UINT64 ticks = (((UINT64)ft.dwHighDateTime) \u0026lt;\u0026lt; 32) | ft.dwLowDateTime; // A Windows tick is 100 nanoseconds. Windows epoch 1601-01-01T00:00:00Z // is 11644473600 seconds before Unix epoch 1970-01-01T00:00:00Z. Timestamp timestamp; timestamp.set_seconds((INT64) ((ticks / 10000000) - 11644473600LL)); timestamp.set_nanos((INT32) ((ticks % 10000000) * 100));  Example 4: Compute Timestamp from Java System.currentTimeMillis().\nlong millis = System.currentTimeMillis(); Timestamp timestamp = Timestamp.newBuilder().setSeconds(millis / 1000) .setNanos((int) ((millis % 1000) * 1000000)).build();  Example 5: Compute Timestamp from current time in Python.\ntimestamp = Timestamp() timestamp.GetCurrentTime()  JSON Mapping In JSON format, the Timestamp type is encoded as a string in the RFC 3339 format. That is, the format is \u0026ldquo;{year}-{month}-{day}T{hour}:{min}:{sec}[.{frac_sec}]Z\u0026rdquo; where {year} is always expressed using four digits while {month}, {day}, {hour}, {min}, and {sec} are zero-padded to two digits each. The fractional seconds, which can go up to 9 digits (i.e. up to 1 nanosecond resolution), are optional. The \u0026ldquo;Z\u0026rdquo; suffix indicates the timezone (\u0026ldquo;UTC\u0026rdquo;); the timezone is required, though only UTC (as indicated by \u0026ldquo;Z\u0026rdquo;) is presently supported.\nFor example, \u0026ldquo;2017-01-15T01:30:15.01Z\u0026rdquo; encodes 15.01 seconds past 01:30 UTC on January 15, 2017.\nIn JavaScript, one can convert a Date object to this format using the standard toISOString()`]( http://joda-time.sourceforge.net/apidocs/org/joda/time/format/ISODateTimeFormat.html#dateTime()) to obtain a formatter capable of generating timestamps in this format.\n\u0026quot;seconds\u0026quot;: int \u0026quot;nanos\u0026quot;: int     Field Type Description Default     seconds int Represents seconds of UTC time since Unix epoch 1970-01-01T00:00:00Z. Must be from 0001-01-01T00:00:00Z to 9999-12-31T23:59:59Z inclusive.    nanos int Non-negative fractions of a second at nanosecond resolution. Negative second values with fractions must still have non-negative nanos values that count forward in time. Must be from 0 to 999,999,999 inclusive.      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/transformation/transformation.proto.sk/",
	"title": "transformation.proto",
	"tags": [],
	"description": "",
	"content": " Package: transformation.plugins.gloo.solo.io TODO: this was copied form the transformation filter. TODO: instead of manually copying, we want to do it via script, similar to the java-control-plane TODO: to solo-kit/api/envoy\nTypes:  RouteTransformations Transformation Extraction TransformationTemplate InjaTemplate Passthrough MergeExtractorsToBody HeaderBodyTransform   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/transformation/transformation.proto RouteTransformations \u0026quot;request_transformation\u0026quot;: .transformation.plugins.gloo.solo.io.Transformation \u0026quot;response_transformation\u0026quot;: .transformation.plugins.gloo.solo.io.Transformation     Field Type Description Default     request_transformation .transformation.plugins.gloo.solo.io.Transformation     response_transformation .transformation.plugins.gloo.solo.io.Transformation      Transformation [#proto-status: experimental]\n\u0026quot;transformation_template\u0026quot;: .transformation.plugins.gloo.solo.io.TransformationTemplate \u0026quot;header_body_transform\u0026quot;: .transformation.plugins.gloo.solo.io.HeaderBodyTransform     Field Type Description Default     transformation_template .transformation.plugins.gloo.solo.io.TransformationTemplate     header_body_transform .transformation.plugins.gloo.solo.io.HeaderBodyTransform      Extraction \u0026quot;header\u0026quot;: string \u0026quot;regex\u0026quot;: string \u0026quot;subgroup\u0026quot;: int     Field Type Description Default     header string     regex string what information to extract. if extraction fails the result is an empty value.    subgroup int      TransformationTemplate \u0026quot;advanced_templates\u0026quot;: bool \u0026quot;extractors\u0026quot;: map\u0026lt;string, .transformation.plugins.gloo.solo.io.Extraction\u0026gt; \u0026quot;headers\u0026quot;: map\u0026lt;string, string\u0026gt; \u0026quot;body\u0026quot;: .transformation.plugins.gloo.solo.io.InjaTemplate \u0026quot;passthrough\u0026quot;: .transformation.plugins.gloo.solo.io.Passthrough \u0026quot;merge_extractors_to_body\u0026quot;: .transformation.plugins.gloo.solo.io.MergeExtractorsToBody     Field Type Description Default     advanced_templates bool     extractors map\u0026lt;string, .transformation.plugins.gloo.solo.io.Extraction\u0026gt; Extractors are in the origin request language domain    headers map\u0026lt;string, string\u0026gt;     body .transformation.plugins.gloo.solo.io.InjaTemplate     passthrough .transformation.plugins.gloo.solo.io.Passthrough     merge_extractors_to_body .transformation.plugins.gloo.solo.io.MergeExtractorsToBody      InjaTemplate custom functions: header_value(name) -\u0026gt; from the original headers extracted_value(name, index) -\u0026gt; from the extracted values\n\u0026quot;text\u0026quot;: string     Field Type Description Default     text string      Passthrough     Field Type Description Default      MergeExtractorsToBody     Field Type Description Default      HeaderBodyTransform     Field Type Description Default       "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/plugins/transformation/transformation.proto.sk/",
	"title": "transformation.proto",
	"tags": [],
	"description": "",
	"content": " Package: transformation.plugins.gloo.solo.io TODO: this was copied form the transformation filter. TODO: instead of manually copying, we want to do it via script, similar to the java-control-plane TODO: to solo-kit/api/envoy\nTypes:  RouteTransformations Transformation Extraction TransformationTemplate InjaTemplate Passthrough MergeExtractorsToBody HeaderBodyTransform   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/plugins/transformation/transformation.proto RouteTransformations \u0026quot;request_transformation\u0026quot;: .transformation.plugins.gloo.solo.io.Transformation \u0026quot;response_transformation\u0026quot;: .transformation.plugins.gloo.solo.io.Transformation     Field Type Description Default     request_transformation .transformation.plugins.gloo.solo.io.Transformation     response_transformation .transformation.plugins.gloo.solo.io.Transformation      Transformation [#proto-status: experimental]\n\u0026quot;transformation_template\u0026quot;: .transformation.plugins.gloo.solo.io.TransformationTemplate \u0026quot;header_body_transform\u0026quot;: .transformation.plugins.gloo.solo.io.HeaderBodyTransform     Field Type Description Default     transformation_template .transformation.plugins.gloo.solo.io.TransformationTemplate     header_body_transform .transformation.plugins.gloo.solo.io.HeaderBodyTransform      Extraction \u0026quot;header\u0026quot;: string \u0026quot;regex\u0026quot;: string \u0026quot;subgroup\u0026quot;: int     Field Type Description Default     header string     regex string what information to extract. if extraction fails the result is an empty value.    subgroup int      TransformationTemplate \u0026quot;advanced_templates\u0026quot;: bool \u0026quot;extractors\u0026quot;: map\u0026lt;string, .transformation.plugins.gloo.solo.io.Extraction\u0026gt; \u0026quot;headers\u0026quot;: map\u0026lt;string, string\u0026gt; \u0026quot;body\u0026quot;: .transformation.plugins.gloo.solo.io.InjaTemplate \u0026quot;passthrough\u0026quot;: .transformation.plugins.gloo.solo.io.Passthrough \u0026quot;merge_extractors_to_body\u0026quot;: .transformation.plugins.gloo.solo.io.MergeExtractorsToBody     Field Type Description Default     advanced_templates bool     extractors map\u0026lt;string, .transformation.plugins.gloo.solo.io.Extraction\u0026gt; Extractors are in the origin request language domain    headers map\u0026lt;string, string\u0026gt;     body .transformation.plugins.gloo.solo.io.InjaTemplate     passthrough .transformation.plugins.gloo.solo.io.Passthrough     merge_extractors_to_body .transformation.plugins.gloo.solo.io.MergeExtractorsToBody      InjaTemplate custom functions: header_value(name) -\u0026gt; from the original headers extracted_value(name, index) -\u0026gt; from the extracted values\n\u0026quot;text\u0026quot;: string     Field Type Description Default     text string      Passthrough     Field Type Description Default      MergeExtractorsToBody     Field Type Description Default      HeaderBodyTransform     Field Type Description Default       "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gloo/api/v1/upstream.proto.sk/",
	"title": "upstream.proto",
	"tags": [],
	"description": "",
	"content": " Package: gloo.solo.io Types:  Upstream Top-Level Resource DiscoveryMetadata   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/upstream.proto Upstream Upstreams represent destination for routing HTTP requests. Upstreams can be compared to clusters in Envoy terminology. Each upstream in Gloo has a type. Supported types include static, kubernetes, aws, consul, and more. Each upstream type is handled by a corresponding Gloo plugin.\n\u0026quot;upstream_spec\u0026quot;: .gloo.solo.io.UpstreamSpec \u0026quot;status\u0026quot;: .core.solo.io.Status \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata \u0026quot;discovery_metadata\u0026quot;: .gloo.solo.io.DiscoveryMetadata     Field Type Description Default     upstream_spec .gloo.solo.io.UpstreamSpec Type-specific configuration. Examples include static, kubernetes, and aws. The type-specific config for the upstream is called a spec.    status .core.solo.io.Status Status indicates the validation status of the resource. Status is read-only by clients, and set by gloo during validation    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource    discovery_metadata .gloo.solo.io.DiscoveryMetadata Upstreams and their configuration can be automatically by Gloo Discovery if this upstream is created or modified by Discovery, metadata about the operation will be placed here.     DiscoveryMetadata created by discovery services\n    Field Type Description Default       "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gloo/api/v1/upstream.proto.sk/",
	"title": "upstream.proto",
	"tags": [],
	"description": "",
	"content": " Package: gloo.solo.io Types:  Upstream Top-Level Resource DiscoveryMetadata   Source File: github.com/solo-io/gloo/projects/gloo/api/v1/upstream.proto Upstream Upstreams represent destination for routing HTTP requests. Upstreams can be compared to clusters in Envoy terminology. Each upstream in Gloo has a type. Supported types include static, kubernetes, aws, consul, and more. Each upstream type is handled by a corresponding Gloo plugin.\n\u0026quot;upstream_spec\u0026quot;: .gloo.solo.io.UpstreamSpec \u0026quot;status\u0026quot;: .core.solo.io.Status \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata \u0026quot;discovery_metadata\u0026quot;: .gloo.solo.io.DiscoveryMetadata     Field Type Description Default     upstream_spec .gloo.solo.io.UpstreamSpec Type-specific configuration. Examples include static, kubernetes, and aws. The type-specific config for the upstream is called a spec.    status .core.solo.io.Status Status indicates the validation status of the resource. Status is read-only by clients, and set by gloo during validation    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource    discovery_metadata .gloo.solo.io.DiscoveryMetadata Upstreams and their configuration can be automatically by Gloo Discovery if this upstream is created or modified by Discovery, metadata about the operation will be placed here.     DiscoveryMetadata created by discovery services\n    Field Type Description Default       "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/github.com/solo-io/gloo/projects/gateway/api/v1/virtual_service.proto.sk/",
	"title": "virtual_service.proto",
	"tags": [],
	"description": "",
	"content": " Package: gateway.solo.io Types:  VirtualService Top-Level Resource   Source File: github.com/solo-io/gloo/projects/gateway/api/v1/virtual_service.proto VirtualService A virtual service describes the set of routes to match for a set of domains. Domains must be unique across all virtual services within a gateway (i.e. no overlap between sets).\n\u0026quot;virtual_host\u0026quot;: .gloo.solo.io.VirtualHost \u0026quot;ssl_config\u0026quot;: .gloo.solo.io.SslConfig \u0026quot;display_name\u0026quot;: string \u0026quot;status\u0026quot;: .core.solo.io.Status \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata     Field Type Description Default     virtual_host .gloo.solo.io.VirtualHost     ssl_config .gloo.solo.io.SslConfig If provided, the Gateway will serve TLS/SSL traffic for this set of routes    display_name string Display only, optional descriptive name. Unlike metadata.name, DisplayName can be changed without deleting the resource.    status .core.solo.io.Status Status indicates the validation status of this resource. Status is read-only by clients, and set by gloo during validation    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/github.com/solo-io/gloo/projects/gateway/api/v1/virtual_service.proto.sk/",
	"title": "virtual_service.proto",
	"tags": [],
	"description": "",
	"content": " Package: gateway.solo.io Types:  VirtualService Top-Level Resource   Source File: github.com/solo-io/gloo/projects/gateway/api/v1/virtual_service.proto VirtualService A virtual service describes the set of routes to match for a set of domains. Domains must be unique across all virtual services within a gateway (i.e. no overlap between sets).\n\u0026quot;virtual_host\u0026quot;: .gloo.solo.io.VirtualHost \u0026quot;ssl_config\u0026quot;: .gloo.solo.io.SslConfig \u0026quot;display_name\u0026quot;: string \u0026quot;status\u0026quot;: .core.solo.io.Status \u0026quot;metadata\u0026quot;: .core.solo.io.Metadata     Field Type Description Default     virtual_host .gloo.solo.io.VirtualHost     ssl_config .gloo.solo.io.SslConfig If provided, the Gateway will serve TLS/SSL traffic for this set of routes    display_name string Display only, optional descriptive name. Unlike metadata.name, DisplayName can be changed without deleting the resource.    status .core.solo.io.Status Status indicates the validation status of this resource. Status is read-only by clients, and set by gloo during validation    metadata .core.solo.io.Metadata Metadata contains the object metadata for this resource      "
},
{
	"uri": "https://gloo.solo.io/0.7/v1/google/protobuf/wrappers.proto.sk/",
	"title": "wrappers.proto",
	"tags": [],
	"description": "",
	"content": " Package: google.protobuf Protocol Buffers - Google\u0026rsquo;s data interchange format Copyright 2008 Google Inc. All rights reserved. https://developers.google.com/protocol-buffers/\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n* Redistributions of source code must retain the above copyright  notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026ldquo;AS IS\u0026rdquo; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nWrappers for primitive (non-message) types. These types are useful for embedding primitives in the google.protobuf.Any type and for places where we need to distinguish between the absence of a primitive typed field and its default value.\nTypes:  DoubleValue FloatValue Int64Value UInt64Value Int32Value UInt32Value BoolValue StringValue BytesValue   Source File: google/protobuf/wrappers.proto DoubleValue Wrapper message for double.\nThe JSON representation for DoubleValue is JSON number.\n\u0026quot;value\u0026quot;: float     Field Type Description Default     value float The double value.     FloatValue Wrapper message for float.\nThe JSON representation for FloatValue is JSON number.\n\u0026quot;value\u0026quot;: float     Field Type Description Default     value float The float value.     Int64Value Wrapper message for int64.\nThe JSON representation for Int64Value is JSON string.\n\u0026quot;value\u0026quot;: int     Field Type Description Default     value int The int64 value.     UInt64Value Wrapper message for uint64.\nThe JSON representation for UInt64Value is JSON string.\n\u0026quot;value\u0026quot;: int     Field Type Description Default     value int The uint64 value.     Int32Value Wrapper message for int32.\nThe JSON representation for Int32Value is JSON number.\n\u0026quot;value\u0026quot;: int     Field Type Description Default     value int The int32 value.     UInt32Value Wrapper message for uint32.\nThe JSON representation for UInt32Value is JSON number.\n\u0026quot;value\u0026quot;: int     Field Type Description Default     value int The uint32 value.     BoolValue Wrapper message for bool.\nThe JSON representation for BoolValue is JSON true and false.\n\u0026quot;value\u0026quot;: bool     Field Type Description Default     value bool The bool value.     StringValue Wrapper message for string.\nThe JSON representation for StringValue is JSON string.\n\u0026quot;value\u0026quot;: string     Field Type Description Default     value string The string value.     BytesValue Wrapper message for bytes.\nThe JSON representation for BytesValue is JSON string.\n\u0026quot;value\u0026quot;: bytes     Field Type Description Default     value bytes The bytes value.      "
},
{
	"uri": "https://gloo.solo.io/0.8/v1/google/protobuf/wrappers.proto.sk/",
	"title": "wrappers.proto",
	"tags": [],
	"description": "",
	"content": " Package: google.protobuf Protocol Buffers - Google\u0026rsquo;s data interchange format Copyright 2008 Google Inc. All rights reserved. https://developers.google.com/protocol-buffers/\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n* Redistributions of source code must retain the above copyright  notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \u0026ldquo;AS IS\u0026rdquo; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nWrappers for primitive (non-message) types. These types are useful for embedding primitives in the google.protobuf.Any type and for places where we need to distinguish between the absence of a primitive typed field and its default value.\nTypes:  DoubleValue FloatValue Int64Value UInt64Value Int32Value UInt32Value BoolValue StringValue BytesValue   Source File: google/protobuf/wrappers.proto DoubleValue Wrapper message for double.\nThe JSON representation for DoubleValue is JSON number.\n\u0026quot;value\u0026quot;: float     Field Type Description Default     value float The double value.     FloatValue Wrapper message for float.\nThe JSON representation for FloatValue is JSON number.\n\u0026quot;value\u0026quot;: float     Field Type Description Default     value float The float value.     Int64Value Wrapper message for int64.\nThe JSON representation for Int64Value is JSON string.\n\u0026quot;value\u0026quot;: int     Field Type Description Default     value int The int64 value.     UInt64Value Wrapper message for uint64.\nThe JSON representation for UInt64Value is JSON string.\n\u0026quot;value\u0026quot;: int     Field Type Description Default     value int The uint64 value.     Int32Value Wrapper message for int32.\nThe JSON representation for Int32Value is JSON number.\n\u0026quot;value\u0026quot;: int     Field Type Description Default     value int The int32 value.     UInt32Value Wrapper message for uint32.\nThe JSON representation for UInt32Value is JSON number.\n\u0026quot;value\u0026quot;: int     Field Type Description Default     value int The uint32 value.     BoolValue Wrapper message for bool.\nThe JSON representation for BoolValue is JSON true and false.\n\u0026quot;value\u0026quot;: bool     Field Type Description Default     value bool The bool value.     StringValue Wrapper message for string.\nThe JSON representation for StringValue is JSON string.\n\u0026quot;value\u0026quot;: string     Field Type Description Default     value string The string value.     BytesValue Wrapper message for bytes.\nThe JSON representation for BytesValue is JSON string.\n\u0026quot;value\u0026quot;: bytes     Field Type Description Default     value bytes The bytes value.      "
},
{
	"uri": "https://gloo.solo.io/0.7/dev/",
	"title": "Developer Guide",
	"tags": [],
	"description": "",
	"content": "Developing on Gloo can be a fun and rewarding experience.\nGloo is designed to be highly pluggable and easily extendable in each of the following domains:\n Routing Controllers (e.g. defining new APIs, automatic config in response to events, etc.) Service Discovery backends Configuring custom or upstream Envoy Filters  The reason Gloo is extendable in so many directions is due in part to its Kubernetes Operator-style design. By interacting with two CRDs, it is possible to customize Gloo to virtually any environment and use case:\n v1.Proxies provide the routing configuration which Gloo will translate and apply to Envoy. v1.Upstreams describe routable destinations for Gloo.\n Proxies represent a unified configuration to be applied to one or more instances of a proxy. You can think of the proxy of as tree like such:\nproxy ├─ bind-address │ ├── domain-set │ │ ├── /route │ │ ├── /route │ │ ├── /route │ │ └── tls-config │ └── domain-set │ ├── /route │ ├── /route │ ├── /route │ └── tls-config └─ bind-address ├── domain-set │ ├── /route │ ├── /route │ ├── /route │ └── tls-config └── domain-set ├── /route ├── /route ├── /route └── tls-config   A single proxy CRD contains all the configuration necessary to be applied to an instance of Envoy. In the Gloo system, Proxies are treated as an intermediary representation of config, while user-facing config is imported from simpler, more opinionated resources such as the gateway.VirtualService or Kubernetes Ingress objects.\nFor this reason, a standard Gloo deployment contains one or more controllers which programatically generate and write these CRDs to provide simpler, use-case specific APIs such as API Gateway and Ingress. Sqoop is an advanced controller which creates routing configuration for Gloo from GraphQL Schemas.\nClick here for a tutorial providing a simple example utilizing this lower-level Proxy API. This tutorial will walk you through building a Kubernetes controller to automatically configure Gloo without any user interaction](example-proxy-controller.go).\n Upstreams represent destinations for routing requests in Gloo. Routes in Gloo specify one or more Upstreams (by name) as their destination. Upstreams have a type which is provided in their upstreamSpec field. Each type of upstream corresponds to an Upstream Plugin, which tells Gloo how to translate upstreams of that type to Envoy clusters. When a route is declared for an upstream, Gloo invokes the corresponding plugin for that type  More tutorials and design documentation are coming soon!\n"
},
{
	"uri": "https://gloo.solo.io/0.8/dev/",
	"title": "Developer Guide",
	"tags": [],
	"description": "",
	"content": "Developing on Gloo can be a fun and rewarding experience.\nGloo is designed to be highly pluggable and easily extendable in each of the following domains:\n Routing Controllers (e.g. defining new APIs, automatic config in response to events, etc.) Service Discovery backends Configuring custom or upstream Envoy Filters  The reason Gloo is extendable in so many directions is due in part to its Kubernetes Operator-style design. By interacting with two CRDs, it is possible to customize Gloo to virtually any environment and use case:\n v1.Proxies provide the routing configuration which Gloo will translate and apply to Envoy. v1.Upstreams describe routable destinations for Gloo.\n Proxies represent a unified configuration to be applied to one or more instances of a proxy. You can think of the proxy of as tree like such:\nproxy ├─ bind-address │ ├── domain-set │ │ ├── /route │ │ ├── /route │ │ ├── /route │ │ └── tls-config │ └── domain-set │ ├── /route │ ├── /route │ ├── /route │ └── tls-config └─ bind-address ├── domain-set │ ├── /route │ ├── /route │ ├── /route │ └── tls-config └── domain-set ├── /route ├── /route ├── /route └── tls-config   A single proxy CRD contains all the configuration necessary to be applied to an instance of Envoy. In the Gloo system, Proxies are treated as an intermediary representation of config, while user-facing config is imported from simpler, more opinionated resources such as the gateway.VirtualService or Kubernetes Ingress objects.\nFor this reason, a standard Gloo deployment contains one or more controllers which programatically generate and write these CRDs to provide simpler, use-case specific APIs such as API Gateway and Ingress. Sqoop is an advanced controller which creates routing configuration for Gloo from GraphQL Schemas.\nClick here for a tutorial providing a simple example utilizing this lower-level Proxy API. This tutorial will walk you through building a Kubernetes controller to automatically configure Gloo without any user interaction](example-proxy-controller.go).\n Upstreams represent destinations for routing requests in Gloo. Routes in Gloo specify one or more Upstreams (by name) as their destination. Upstreams have a type which is provided in their upstreamSpec field. Each type of upstream corresponds to an Upstream Plugin, which tells Gloo how to translate upstreams of that type to Envoy clusters. When a route is declared for an upstream, Gloo invokes the corresponding plugin for that type  More tutorials and design documentation are coming soon!\n"
},
{
	"uri": "https://gloo.solo.io/0.7/installation/node_port/",
	"title": "Production Deployment Using NodePort",
	"tags": [],
	"description": "",
	"content": " Motivation By default, micro-services deployed in kubernetes have an internal flat network that is not accessible from the outside of the cluster. This is true even if you use kuberentes on a public cloud (like Amazon AWs or Google Cloud).\nA NodePort is a way to make kubernetes services available from outside the cluster (and potentially allow access from the internet).\nIn this document we will review how to expose Gloo via a NodePort.\nWhat is NodePort Service? A kuberenetes cluster is composed of one or more nodes. A node VM is a (most likely) linux machine (can be a virtual machine or bare-metal) that actually runs the kuberenetes pods.\nWhen a kubernetes service is created with NodePort type, kubernetes chooses a port number and assigns it to the service. In addition, every node in the cluster is configured to forward traffic from this port to the pods belonging service.\nThis allows you to access the service simply by connecting to a \u0026lsquo;node-ip:node-port\u0026rsquo; where node-ip is the ip of any node in the cluster, and node-port is the NodePort assigned by kuberentes.\nOne advantage of using a NodePort is that it allows relatively easy deployment on bare metal, as it does not depend on any load balancing component outside the cluster.\nHow to use Gloo with NodePort? In Gloo, the service that\u0026rsquo;s responsible for ingress traffic is called \u0026ldquo;gateway-proxy\u0026rdquo;. To use Gloo with NodePort we simply need to configure this service to NodePort. For example, when installing with helm, use the following command:\nhelm install gloo/gloo --namespace gloo-system --set gatewayProxy.service.type=NodePort  Once installed, check what port was allocated:\nkubectl get svc -n gloo-system gateway-proxy -o yaml apiVersion: v1 kind: Service metadata: labels: app: gloo gloo: gateway-proxy name: gateway-proxy namespace: gloo-system spec: clusterIP: 10.106.198.61 externalTrafficPolicy: Cluster ports: - name: http nodePort: 30348 port: 8080 protocol: TCP targetPort: 8080 selector: gloo: gateway-proxy sessionAffinity: None type: NodePort status: loadBalancer: {}  In our example, port 30348 was allocated. You can now use http://NODE-IP:30348 to make requests to your Gloo virtual services.\n"
},
{
	"uri": "https://gloo.solo.io/0.8/installation/node_port/",
	"title": "Production Deployment Using NodePort",
	"tags": [],
	"description": "",
	"content": " Motivation By default, micro-services deployed in kubernetes have an internal flat network that is not accessible from the outside of the cluster. This is true even if you use kuberentes on a public cloud (like Amazon AWs or Google Cloud).\nA NodePort is a way to make kubernetes services available from outside the cluster (and potentially allow access from the internet).\nIn this document we will review how to expose Gloo via a NodePort.\nWhat is NodePort Service? A kuberenetes cluster is composed of one or more nodes. A node VM is a (most likely) linux machine (can be a virtual machine or bare-metal) that actually runs the kuberenetes pods.\nWhen a kubernetes service is created with NodePort type, kubernetes chooses a port number and assigns it to the service. In addition, every node in the cluster is configured to forward traffic from this port to the pods belonging service.\nThis allows you to access the service simply by connecting to a \u0026lsquo;node-ip:node-port\u0026rsquo; where node-ip is the ip of any node in the cluster, and node-port is the NodePort assigned by kuberentes.\nOne advantage of using a NodePort is that it allows relatively easy deployment on bare metal, as it does not depend on any load balancing component outside the cluster.\nHow to use Gloo with NodePort? In Gloo, the service that\u0026rsquo;s responsible for ingress traffic is called \u0026ldquo;gateway-proxy\u0026rdquo;. To use Gloo with NodePort we simply need to configure this service to NodePort. For example, when installing with helm, use the following command:\nhelm install gloo/gloo --namespace gloo-system --set gatewayProxy.service.type=NodePort  Once installed, check what port was allocated:\nkubectl get svc -n gloo-system gateway-proxy -o yaml apiVersion: v1 kind: Service metadata: labels: app: gloo gloo: gateway-proxy name: gateway-proxy namespace: gloo-system spec: clusterIP: 10.106.198.61 externalTrafficPolicy: Cluster ports: - name: http nodePort: 30348 port: 8080 protocol: TCP targetPort: 8080 selector: gloo: gateway-proxy sessionAffinity: None type: NodePort status: loadBalancer: {}  In our example, port 30348 was allocated. You can now use http://NODE-IP:30348 to make requests to your Gloo virtual services.\n"
},
{
	"uri": "https://gloo.solo.io/0.7/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " An Envoy-Powered API Gateway  Gloo is a feature-rich, Kubernetes-native ingress controller, and next-generation API gateway. Gloo is exceptional in its function-level routing; its support for legacy apps, microservices and serverless; its discovery capabilities; its numerous features; and its tight integration with leading open-source projects. Gloo is uniquely designed to support hybrid applications, in which multiple technologies, architectures, protocols, and clouds can coexist.\nInstallation \u0026nbsp; | \u0026nbsp; Developers \u0026nbsp; | \u0026nbsp; Blog \u0026nbsp; | \u0026nbsp; Slack \u0026nbsp; | \u0026nbsp; Twitter\n\nBlogs \u0026amp; Demos  Announcement Blog Building hybrid app demo  Community  Join us on our Slack channel: https://slack.solo.io/ Follow us on Twitter: https://twitter.com/soloio_inc  Thanks Gloo would not be possible without the valuable open-source work of projects in the community. We would like to extend a special thank-you to Envoy.\n"
},
{
	"uri": "https://gloo.solo.io/0.8/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " An Envoy-Powered API Gateway  Gloo is a feature-rich, Kubernetes-native ingress controller, and next-generation API gateway. Gloo is exceptional in its function-level routing; its support for legacy apps, microservices and serverless; its discovery capabilities; its numerous features; and its tight integration with leading open-source projects. Gloo is uniquely designed to support hybrid applications, in which multiple technologies, architectures, protocols, and clouds can coexist.\nInstallation \u0026nbsp; | \u0026nbsp; Developers \u0026nbsp; | \u0026nbsp; Blog \u0026nbsp; | \u0026nbsp; Slack \u0026nbsp; | \u0026nbsp; Twitter\n\nBlogs \u0026amp; Demos  Announcement Blog Building hybrid app demo  Community  Join us on our Slack channel: https://slack.solo.io/ Follow us on Twitter: https://twitter.com/soloio_inc  Thanks Gloo would not be possible without the valuable open-source work of projects in the community. We would like to extend a special thank-you to Envoy.\n"
},
{
	"uri": "https://gloo.solo.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gloo.solo.io/",
	"title": "Gloo Docs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gloo.solo.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]